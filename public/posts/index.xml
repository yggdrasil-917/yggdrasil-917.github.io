<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
	<channel>
		<title>Posts on Tempest Engine Dev</title>
		<link>https://yggdrasil-917.github.io/posts/</link>
		<description>Recent content in Posts on Tempest Engine Dev</description>
		<generator>Hugo -- gohugo.io</generator>
		<language>en-us</language>
		<lastBuildDate>Tue, 22 Oct 2024 12:12:21 -0700</lastBuildDate>
		<atom:link href="https://yggdrasil-917.github.io/posts/index.xml" rel="self" type="application/rss+xml" />
		
		<item>
			<title>Choosing A Game AI System - Utility AI</title>
			<link>https://yggdrasil-917.github.io/posts/utility-ai/utility-ai/</link>
			<pubDate>Tue, 22 Oct 2024 12:12:21 -0700</pubDate>
			
			<guid>https://yggdrasil-917.github.io/posts/utility-ai/utility-ai/</guid>
			<description><![CDATA[%!s(<nil>)]]></description>
			<content type="html"><![CDATA[<ul>
<li><a href="#where-to-start">Where To Start</a></li>
<li><a href="#response-curves">Response Curves</a></li>
<li><a href="#consistent-utility-scores">Consistent Utility Scores</a></li>
<li><a href="#practical-usage-of-scores">Practical Usage Of Scores</a></li>
<li><a href="#inertia">Inertia</a></li>
<li><a href="#closing-thoughts">Closing Thoughts</a></li>
</ul>
<p>In a <a href="https://yggdrasil-917.github.io/posts/behavior-trees/behavior-trees/">previous post</a> I talked about my experience implementing behavior trees in Tempest and evaluating their results. As stated in that post, I did not feel behavior trees are the right solution for the kind of game I&rsquo;m making so I set out to look for another alternative. Here I will cover one of the two alternatives I decided to look deeper into and that is <strong>Utility AI</strong> or sometimes refered to as <strong><a href="https://www.gameaipro.com/GameAIPro/GameAIPro_Chapter09_An_Introduction_to_Utility_Theory.pdf">Utility Theory</a></strong>.</p>
<p>Generally speaking, behavior trees evaluate their results one node at a time and try to answer the question <strong>&ldquo;should I execute this node?&rdquo;</strong>. Simulating the AI this way can mean that their decision making process does not look at the whole picture and given their static nature can lead to sub-optimal decisions and at times predictable. The latter can be a desired property depending on the type of game being made but I would like my AI to be a bit less predictable and possibly produce emergent behaviors to hopefully surprise players. In contrast, utility AI has to process all of its actions and assign scores to them prior to making a decision. Essentially it tries to answer <strong>&ldquo;what is the best action to take?&rdquo;</strong> given the state of the world. In a way, this probabilistic model can feel more natural as it sort of mimics how humans reason about problems.</p>
<h2 id="where-to-start">Where To Start</h2>
<p>So first things first, developers have to figure out the set of actions AI agents are allowed to make. In a game that has combat, these actions can be things like <strong>move to location</strong>, <strong>attack</strong>, <strong>heal</strong>, <strong>run away</strong>, etc. To be clear, not all actions have to be decided from the start as it is fairly easy to add new actions. In my case, I started with actions that allowed enemies to move around the map with a goal in mind such as attacking or running away. I feel like that is a good starting point to build your custom AI system around, especially when you are trying to evaluate the effectiveness of the AI system before fully committing to it.</p>
<p>Once you have your actions it is time to figure out the set of scorers to add to each action. In a utility AI system, a scorer is as simple as a mathemathical function to evaluate a specific factor that you can later combine with other scorers under a single action in order to give that action a rating. The higher the rating the more optimal that action is relative to the other possible actions the agent may take.</p>
<p>To give a concrete example of a scorer, lets use the <strong>heal</strong> action. An important thing for the agent to consider before taking that action is how low their health is. It makes no sense for them to heal if they have most of their health. You could use a linear curve to express the urgency to heal in which the closer its health is to 0 then the more likely it will want to heal. It is rare for an action to only have one scorer contributing to its evaluation and in this case just looking at the agent&rsquo;s health would not be enough to evaluate the heal action. It should also consider whether it has a healing item, an ability to heal, or if a teammate close by may need healing more. You can combine all these scorers and create a sophisticated process to decide if the agent should heal. This same process carries over to any other action implemented in the game.</p>
<p>In Tempest, actions and scorers follow a C-like API as I felt an OOP design for this didn&rsquo;t fit that well. Scorers are simple enums and actions are POD structs where they know what scorers matter to them by keeping an enum array. The data needed to configure this is stored in scriptable objects making this whole AI system data-driven. Combine that with asset hot-reloading and we get fast iteration when tweaking values all in the middle of gameplay.</p>
<h2 id="response-curves">Response Curves</h2>
<p>Now we can dive into world of response curves. These are responsible for providing tunable ways to configure your scoring functions and it is safe to say that there is a ton of material to read on this subject. Creating easy to adjust performant curves is a challenging task on its own and it is something that many areas of mathemathics and engineering desire. I&rsquo;ll only cover a handful here but know that there&rsquo;s a lot more to learn for anyone curious about it. There&rsquo;s going to be plenty of screenshots of different curve functions and all of them made with <a href="https://www.desmos.com/calculator">Desmos</a>. I can&rsquo;t stress enough how valuable Desmos can be when coming up with new functions and visually seeing their output instantly.</p>
<h3 id="linear-curve">Linear Curve</h3>
<p>The simplest curve in the toolbag that allows you to control its slope and offset.</p>
<p><img src="/images/utility-ai/LinearCurve.png" alt="Linear Curve" title="Linear Curve"></p>
<h3 id="exponential-curve">Exponential Curve</h3>
<p>This curve can raise the input to a configurable exponent, the higher the exponent the higher its rate of change is and with a slight tweak to the function we can generate its inverse. The curve function also has a parameter to offset the curve.</p>
<p><img src="/images/utility-ai/ExponentialCurve.png" alt="Exponential Curve" title="Exponential Curve"></p>
<p><img src="/images/utility-ai/InverseExponentialCurve.png" alt="Inverse Exponential Curve" title="Inverse Exponential Curve"></p>
<h3 id="logistic-curve">Logistic Curve</h3>
<p>I first encountered this curve in <a href="https://media.gdcvault.com/gdc10/slides/MarkDill_ImprovingAIUtilityTheory.pdf">Dave Mark&rsquo;s GDC presentation</a> back in 2010 and it is very easy to customize. It provides a parameter to control steepness and the midpoint of the S-curve.</p>
<p><img src="/images/utility-ai/LogisticCurve.png" alt="Logistic Curve" title="Logistic Curve"></p>
<h3 id="logit-curve">Logit Curve</h3>
<p>These are logistic curves turned on its side as Dave Mark remarked in his 2010 talk. Like the logistic curve it provides a steepness parameter and can be extended to offset the midpoint vertically.</p>
<p><img src="/images/utility-ai/LogitCurveA.png" alt="Logit Curve A" title="Logit Curve A"></p>
<p><img src="/images/utility-ai/LogitCurveB.png" alt="Logit Curve B" title="Logit Curve B"></p>
<h3 id="sigmoid-curve">Sigmoid Curve</h3>
<p>This sigmoid function comes from a <a href="https://dhemery.github.io/DHE-Modules/technical/sigmoid/">blog post</a> made years ago. I like this function a lot for its simplicity and lack of exponents so floating point inaccuracies are going to be minimal. It can also provide normalized J-curve shapes for inputs in [0, 1] range but can also provide S-curve outputs for inputs in [-1, 1] range with the same function. The function is also very simple to evaluate.</p>
<p><img src="/images/utility-ai/Sigmoid.png" alt="Sigmoid" title="Sigmoid"></p>
<p>As previously said, these are only a handful of curves out there. I didn&rsquo;t show curves like cosine or sine waves where you could change parameters like amplitude, phase, and wavelength to configure them. The ones covered will be useful for most scenarios you will encounter though.</p>
<p>Having these curve types that are data driven rather than hand crafting them feels like it is a better approach than providing raw configurable Catmull-Rom type curves like I&rsquo;ve discussed in a previous post.</p>
<h3 id="consistent-utility-scores">Consistent Utility Scores</h3>
<p>It&rsquo;s rather unfortunate but if you read a lot of the available information online on scoring based AI systems and you&rsquo;ll seldom find any mention of keeping your scoring scales consistent so that comparing them makes any sense. All too often the posts seem to mix in different scoring scales for different actions with their examples that you don&rsquo;t notice until you try to implement your own utility computations. I&rsquo;ve found that a good starting point is to normalize your scores into a [0, 1] range. This allows keeping whatever range you want for the individual scorers and as long as they are normalized before averaging or comparing then you maintain a consistent scale while allowing some flexibility for scorers. That said it doesn&rsquo;t need to be a [0, 1] range as long as the range across the system is consistent.</p>
<h3 id="practical-usage-of-scores">Practical Usage Of Scores</h3>
<p>A consistent range can also open up additional possibilities to influence your scoring system. For instance, after normalizing you could have separate biasing weights to make certain actions more or less likely to happen. In my game, I have a concept of personality traits to create a bit more variation while still using the same configured set of scorers. With this system I could have some enemies be more aggressive and I could express this trait by biasing the attack action to be more likely or I could bias the positioning scorer to not care about being surrounded by enemies after it moves to a position it can use to attack. This situation can also be reversed by implementing a trait for &ldquo;fear&rdquo; in which the enemy is less likely to stray from its team or be quick to run away from combat. I&rsquo;d say the possibilities are endless so long as you can express the scorers with mathemathical functions.</p>
<p>Since you have to compute the value for each score used in the utility system, you can create a sorted list of them starting with the best possible action going down to the worse possible action. Having this data opens up some additional possibilities from a gameplay perspective.</p>
<p>Say you don&rsquo;t want to always use the best action, think of difficulty settings in games, with this sorted list you can pick a random action from the top N best scored actions or you could have a more sophisticated system that keeps a history of what actions were taken before and you want the AI to use an action it hasn&rsquo;t used in a while. For an easy difficulty setting you could always discard the first few best scored actions so it consistently uses sub-optimal actions. Another use case is if you have a sort of &ldquo;intelligence&rdquo; trait, going back to the personality system, then that inlligence factor could be used to introduce noise into the scoring system. The smarter the enemy is the lower the noise amount will be.</p>
<p>Another interesting gameplay use case is implementing the status effect <strong>Confuse</strong>. This is often implemented by having the confused NPC randomly pick an action. If you have a sorted list of possible actions the NPC can perform then you could pick randomly from the N worse rated actions or pick from a mix of high and low scored actions just so it isn&rsquo;t always a negative.</p>
<h2 id="inertia">Inertia</h2>
<p>Inertia is a very important concept to talk about that I also rarely see mentioned or it just tends to be implied. It&rsquo;s important to know when to have your AI agent decide what it will do. If it is updating it every frame then you run the risk of running into oscillating issues where in frame N in picks action A, on frame N+1 it picks action B, and in the next frame goes back to picking action A. In the case of utility AI this can happen when several actions are scored similarly. An example of this could be an when an AI in an FPS decides it is in a bad spot as it starts to get shot at by the player. The enemy AI is scoring an &ldquo;attack the player&rdquo; and &quot; run away&quot; actions and the results are both equal. It picks &ldquo;run away&rdquo;, then soon after decides it needs to &ldquo;attack the player&rdquo;, and finally decides it needs to &ldquo;run away&rdquo; again. This behavior looks bad to the player and probably also feels equally bad to play. There are plenty of solutions to deal with this but just know that is something to be aware of when building AI systems as this isn&rsquo;t unique to utility AI. Some systems even have inertia built into its decision making process. Any planning-based system like <a href="https://medium.com/@vedantchaudhari/goal-oriented-action-planning-34035ed40d0b">GOAP</a> or <a href="https://en.wikipedia.org/wiki/Hierarchical_task_network">HTN</a> will create a plan for the agent and only update when the plan is done or something in the world invalidated the plan so the agent needs to make a new one.</p>
<h2 id="closing-thoughts">Closing Thoughts</h2>
<p>After working with this system for a bit, I really do like it a lot. It&rsquo;s very easy to add new actions and scorers. Unlike behavior trees, the amount of code required to add new functionality is a lot less. That said it can be tricky to have a general sense of what the utility model will do once you get it to a certain size. At the end of the day you are balancing a bunch of different weights and response curves so I think investing in some tools to visualize the scoring results could be valuable. Balancing the model to get the AI agents to use many of their actions in the middle of gameplay can be tough if you are relying only on the raw results from evaluating the actions. This is why I think adding things like the personality traits to bias and transform the model somewhat can be useful. That said I will probably spend more time expanding this system and see how far I get but before that I will likely finish implementing and evaluating the other AI system I wanted to properly investigate. That other system being hierarchical task networks or HTN. If I get far enough with it then I will likely follow up with another AI post in the future.</p>
]]></content>
		</item>
		
		<item>
			<title>Dynamic Resolution</title>
			<link>https://yggdrasil-917.github.io/posts/dynamic-resolution/dynamic-resolution/</link>
			<pubDate>Fri, 18 Oct 2024 15:43:50 -0700</pubDate>
			
			<guid>https://yggdrasil-917.github.io/posts/dynamic-resolution/dynamic-resolution/</guid>
			<description><![CDATA[%!s(<nil>)]]></description>
			<content type="html"><![CDATA[<p><img src="/images/dynamic-resolution/DynRes.png" alt="DynRes" title="DynRes"></p>
<ul>
<li><a href="#timing-your-application">Timing Your Application</a></li>
<li><a href="#configuring-drs">Configuring DRS</a></li>
<li><a href="#how-it-works">How It Works</a></li>
<li><a href="#temporal-issues">Temporal Issues</a></li>
<li><a href="#shader-considerations">Shader Considerations</a></li>
<li><a href="#debugging">Debugging</a></li>
<li><a href="#example">Example</a></li>
</ul>
<p>Dynamic resolution scaling or DRS is a technique where the rendering resolution is changed dynamically at runtime in order to improve GPU performance. This can help provide a smoother overall framerate for an application at the cost of lowering the image quality but still retaining the graphics settings specified by the player. However, DRS only makes sense when the application is bottlenecked by the GPU performance and, if properly implemented, will only do work when that is the case. That said, many modern games tend to be GPU bound so it is a good idea to implement this feature but also provide ways to disable it in the engine for debugging purposes.</p>
<h2 id="timing-your-application">Timing Your Application</h2>
<p>So how does this work in practice? First and foremost the engine must be able to track both the CPU and the GPU times it takes to render a frame. For CPU times, any high resolution clock will do and these days you could opt to use the c++ chrono library for that so you don&rsquo;t have to worry about platform specific implementations. This is what Tempest uses to keep track of time on the CPU. For CPU and GPU timing comparisons to make sense in this context the engine should also keep track of the amount of time the CPU waits for the GPU to present a frame. You can use that time to subtract from the overall CPU time to render a frame before you compare with the GPU timings. This way you remove any idle time spent waiting on the GPU.</p>
<p>Timing the GPU involves a bit more work though, in part because the GPU will likely be working on a different frame than what the CPU just processed. In the case of being GPU bound then the CPU will finish processing it&rsquo;s new frame before the GPU finishes its frame so if we have the CPU request the GPU timer&rsquo;s value it will likely have to inject a synchronization point and wait until the value becomes available. Doing it this way will also inflate the CPU time as it stalls until it gets the value from the GPU. What Tempest does to solve this is buffer every GPU timer query in an array whose length is the max number of GPU frames in flight plus one to account for the one the driver may be working on. Buffering will introduce some latency in getting the GPU time however, it removes any possibility to stall the CPU while it waits for the current GPU time value. To make it easy to implement this in Tempest, every rendering pass derives from a base class that has several features most or all passes will need and one of those things are the GPU timer query objects alongside a simple API to manage them.</p>
<h2 id="configuring-drs">Configuring DRS</h2>
<p>Now that we can properly time things both on the CPU and the GPU, we can start making use of them in DRS but first lets go over initializing a DRS system. Tempest exposes certian parameters to configure the behavior of DRS.</p>
<ul>
<li><strong>Target Framerate</strong> - the ideal framerate we want the application to have, in our case 60 FPS or 16ms.</li>
<li><strong>Update Interval</strong> - how often we want DRS to adjust the scaling factor. It makes sense to not adjust this on every frame as it will be obvious to the user and could become distracting.</li>
<li><strong>Minimum Height Resolution</strong> - configures the lower bound of the height rendering resolution allowed to use when computing the scaling factor. Typically this is set to 50% of the native height rendering resolution so a 1440p native resolution would have this set to 720p.</li>
<li><strong>GPU Headroom Before Increasing</strong> - this is a threshold used when deciding to increase the rendering resolution if the GPU is too underutilized at the current scale.</li>
<li><strong>Decrease Rate Of Change</strong> - a constant that controls how aggressive DRS will lower the scaling factor.</li>
<li><strong>Increase Rate Of Change</strong> - a constant that controls how aggressive DRS will increase the scaling factor.</li>
</ul>
<p>With all of these parameters you end up with a pretty flexible system and there are still a handful of other internal parameters that help drive some of the features in this system which will be covered later. Now we can look at the decision making flow that DRS in Tempest takes every frame. The diagram below shows what it looks like.</p>
<p><img src="/images/dynamic-resolution/Flow.png" alt="Flow" title="Decision Flow"></p>
<h2 id="how-it-works">How It Works</h2>
<p>Note that all of the following work is only performed if DRS is enabled. At the start of a new frame the renderer will add up all the individual GPU timers for each rendering pass submitted to figure out the overall GPU time similar to what the sample code below does.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-cpp" data-lang="cpp"><span class="line"><span class="cl"><span class="kt">float</span> <span class="n">totalGpuTime</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="k">for</span> <span class="p">(</span><span class="k">const</span> <span class="n">IRenderPass</span><span class="o">*</span> <span class="nl">p</span> <span class="p">:</span> <span class="n">passes</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="n">totalGpuTime</span> <span class="o">+=</span> <span class="n">p</span><span class="o">-&gt;</span><span class="n">GetGpuTime</span><span class="p">(</span><span class="n">device</span><span class="p">,</span> <span class="n">readIdx</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">    <span class="n">p</span><span class="o">-&gt;</span><span class="n">ResetGpuTimerQuery</span><span class="p">(</span><span class="n">device</span><span class="p">,</span> <span class="n">readIdx</span><span class="p">);</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span></code></pre></div><p>At this point we have all the data needed to send to the dynamic resolution handler. It will decide if it should adjust the resolution scale value based on the updated CPU and GPU times plus some other internal heuristics. Using the decision making flow diagram above, the first thing to check is whether the application is GPU bound. Since we know how long it took to process the previous frame on the CPU, excluding the time spent waiting for present, and now we also have the latest GPU time then we can check if the GPU time is slower than the CPU time. There is one problem with this scheme and it has to do with comparing raw times instead of keeping track of the times for several frames such that it is possible to compute an average for example. This can lead to problems where a single frame performance spike can trigger DRS to lower the rendering resolution and this is a huge reason why Tempest computes the average GPU time.</p>
<p>Consider the scenario where the game loads into a new map and it has to render the environment probe plus do all the usual convolution passes to generate all the mips. This is a very expensive process which is why it is always cached afterwards and if DRS is running it will see the GPU taking a long time to render a frame. In this case however, the long frame time was due to a one time event but if the DRS system is not aware of that then it will decide it has to lower the rendering resolution. Having a history buffer tracking the GPU times over several frames can mitigate this but it may not be enough. This is why Tempest also offers a sort of proactive API to tell the DRS system that something expensive and temporary is about to happen so it should ignore a specified amount of frames before it continues to work as normal. This API is also usable from the game scripting API so it is possible for the game to inform the DRS system about these types of events very easily.</p>
<p>Alright so lets say we are GPU bound, if we are at the minimum allowed resolution scale then there is nothing left to do and proceeds to render the frame. Otherwise, the system will compute a <strong>delta scaling factor</strong> that will modify the current dynamic resolution scale. Tempest uses an equation for this that is mostly based on the one discussed in <a href="https://www.intel.com/content/dam/develop/external/us/en/documents/dynamicresolutionrendering-183334.pdf">this paper</a> and you can see it below.</p>
<p><img src="/images/dynamic-resolution/DeltaScale.png" alt="DeltaScale" title="DeltaScale"></p>
<p>Where <strong>S&rsquo;</strong> is the new resolution scale, <strong>S</strong> is the current resolution scale, <strong>k</strong> is the rate of change constant, <strong>T</strong> is the desired frame time, <strong>t</strong> is the current frame time (averaged in our case). In Tempest the rate of change constant is different depending on whether DRS is increasing or decreasing the resolution scale. When an application is GPU bound it&rsquo;s not a bad idea to lower the rendering resolution fast so that the application can re-establish a smooth framerate quickly enough and then increase it slowly over several frames if the GPU has enough headroom to give it more work.</p>
<p>Now lets consider the situation where the application is not GPU bound but DRS has already lowered the rendering resolution. This means there is an opportunity to increase the rendering resolution by increasing the resolution scale value which typically goes from [0, 1] or more realistically [0.5, 1] as rendering at half the chosen rendering resolution is a common minimum. Lowering the resolution scale can happen at any frame if DRS decides it has to happen but increasing it is done at a specified interval instead. This is in part to increase it gradually so it isn&rsquo;t too obvious to players when it happens but also mitigates a situation where the application ping pongs between lowering and increasing the resolution scale. It&rsquo;s a good time to talk about some of the other configurable parameters in DRS that are specific to increasing the resolution scale. As you&rsquo;ll note, there is a <strong>GPU Headroom Before Increasing</strong> parameter discussed previously. This threshold is used to determine if there is enough unused time on the GPU that it makes sense to increase the GPU work by incrementing the resolution scale. You compute the difference between the target framerate and the average GPU time and if that difference is greater than or equal to the headroom threshold then it is safe to increment the resolution scale.</p>
<p>One other important thing to do in relation to increasing the resolution scale is to incorporate a sort of dampening logic to your rate of change. What I mean by this is you can likely end up in a situation where DRS decides to increase the rendering resolution and in the next frame the application is GPU bound once again so you fall into that ping-pong situation mentioned earlier. You can extend the system to be able to identify when scenarios like that happens. Once you have that, then you can attempt to mitigate those scenarios and I think a good way to mitigate it is to have a &ldquo;dampening&rdquo; factor modulating your rate of change curve. Dampening can be increased by some engine specific amount such that gradually incrementing the rendering resolution can actually converge to the ideal scaling factor for the underlying hardware. You can also have logic to reduce this dampening based on any heuristics you decide to have. This can be as simple as reducing the dampening if there have been many consecutive frames where the GPU performance is good.</p>
<p>With dynamic resolution running, the engine needs to be aware of what the scaled resolution is and what the unscaled resolution is as both will be used to render a frame. In Tempest, DRS only affects the rendering resolution used to render the world but after post processing is done the renderer uses whatever the unscaled resolution is to render things like the UI. The unscaled rendering resolution is also needed to allocate the render targets used and the renderer uses the scaled resolution to figure out what region of that render target to render into. This avoids the situation that a lot of naive dynamic rendering resolution implementations fall into in which they re-allocated all of their render targets to the specified scaled rendering resolution. This is simple to implement but terrible for performance not to mention the memory fragmentation this introduces will likely cause a crash at some point.</p>
<p>One key thing to make draw calls work with this scheme is to set your rendering state such that it renders into the scaled region of the render target the pass will write into. In other words, your viewport needs to be set to the scaled rendering resolution. If you&rsquo;re dispatching compute shaders that write to the entire render target then those need to use the scaled rendering resolution when deciding on how many threads to dispatch.</p>
<h2 id="temporal-issues">Temporal Issues</h2>
<p>DRS can introduce some complications with certain rendering features. Depending on your implementation a rendering pass that depends on some temporal resolution stability can be problematic when combined with DRS. In Tempest, volumetric fog falls into this category if it is rendered with temporal smoothing as the froxels are created based on a given rendering resolution. If that changes at any given time, the data stored in the froxels is invalid and if the rendering resolution changes often then this data will never converge to what it should so it looks wrong to the player. The dynamic resolution handler informs the renderer if the resolution scale has changed before any actual rendering work is done. This information is used in the volumetric fog passes to inform the shaders not to use the previous frame data when blending its history with the current frame and also clears any of the temporal buffers so there is no stale data in the froxels. This means that temporal smoothing is disabled for the fog if it is normally enabled but it only does so for a few frames before enabling it again and carrying on as normal.</p>
<h2 id="shader-considerations">Shader Considerations</h2>
<p>Shaders that can sample any region of a render target need to take care not to sample a region that has not been rendered into when DRS is enabled. This typically means clamping the uv coordinates to range between [0, <strong>scaledUV</strong>] where <strong>scaledUV</strong> is the value of your dynamic resolution scale. This assumes it is never larger than 1.0 like it could be if supersampling is supported with DRS.</p>
<p>If the shader relies on the texture sampler repeating the uv coordinate interval then this will need to be handled manually as now the max is not always going to be 1.0.</p>
<p>Another consideration is when a shader uses <strong>Load</strong> to sample a texture as the pixel coordinate used may need to be adjusted by the resolution scale.</p>
<p>Computing normalized screen space coordinates is also something that needs to be handled correctly.</p>
<p>Bloom and other features like it can have a black halo around the edges of the screen if uv coordinates are not properly handled.</p>
<h2 id="debugging">Debugging</h2>
<p>In my opinion, there are three important debugging features that any DRS implementation should have. The first one is to be able to turn it off completely at runtime. This is helpful when looking for bugs. The second one is a simple way to report what the current value of the dynamic rendering scale is at. In Tempest, a simple screen space debug text is rendered alongside things like the CPU and GPU times and is toggled on through the in-game console. The other feature is to be able to manually trigger DRS to downscale the rendering resolution and have it automatically increase the rendering resolution when this debug feature is disabled. This is very important when looking for correctness in your rendering passes. If there are any issues this will uncover them very quickly and then you can address the problem.</p>
<h2 id="example">Example</h2>
<p>With all of that said, here is a screenshot comparison of the usual test scene rendered at the unscaled rendering resolution and at 50% of that using the debug command to trigger downscales. For this example, that means unscaled is rendered at 1440p and the other one at 720p. You can see the UI looks exactly the same, as it should since it is rendered at 1440p for both, and the only difference is the quality of the 3D environment.</p>
<p><img src="/images/dynamic-resolution/DRS_Example.png" alt="Example" title="Example"></p>
]]></content>
		</item>
		
		<item>
			<title>Choosing A Game AI System - Behavior Trees</title>
			<link>https://yggdrasil-917.github.io/posts/behavior-trees/behavior-trees/</link>
			<pubDate>Sat, 12 Oct 2024 14:06:14 -0700</pubDate>
			
			<guid>https://yggdrasil-917.github.io/posts/behavior-trees/behavior-trees/</guid>
			<description><![CDATA[%!s(<nil>)]]></description>
			<content type="html"><![CDATA[<ul>
<li><a href="#behavior-trees">Behavior Trees</a></li>
<li><a href="#node-types">Node Types</a></li>
<li><a href="#implementation">Implementation</a></li>
<li><a href="#authoring-bts">Authoring BTs</a></li>
<li><a href="#downsides-to-bts">Downsides to BTs</a></li>
</ul>
<p>Once it was time to add an AI system to power the enemy AI for the game being made in Tempest I automatically defaulted to use behavior trees for it. This was mostly because it is what I was most familiar with at the time but wasn&rsquo;t sure if it was the right fit for a tactical RPG game that has various job classes that can be mixed and matched. Think of a job system like what is in Final Fantasy Tactics for an example. Long story short is that after implementing behavior trees I was not convinced that it was the right choice to move forward with. This post will go over some implementation details and how I got to the decision to look for something else.</p>
<h2 id="behavior-trees">Behavior Trees</h2>
<p>Behavior trees tend to be an attractive solution for game AI in part due to its hierarchical node structure that makes it easy to understand and construct complex behavior for AI agents. It&rsquo;s hierarchical structure is also important when talking about performance implications as large parts of the tree could be skipped if the agent decides not to go down a certain branch given the state of the world and other factors. AI designers also like the hierarchical structure as it makes it trivial to organize an agent&rsquo;s decision making process. If there are missing AI nodes, designers can request for an AI programmer to implement the desired features. Since the trees are built from a modular and reusable node API, programmers can implement new nodes with it and automatically have them usable in any behavior tree. So it&rsquo;s easy to see why behavior trees are so appealing in game development.</p>
<h2 id="node-types">Node Types</h2>
<p>On the topic of behavior tree nodes, lets go over the main fundamental types supported in Tempest. These nodes form the building blocks on which newer more complex nodes can inherit from.</p>
<h3 id="control-nodes">Control Nodes</h3>
<p>These nodes can dictate the flow of execution and can have one or more child nodes.</p>
<ul>
<li><strong>Selector Node</strong>: This node will execute its children from left to right until one succeeds so if a child returns <strong>failure</strong> then it moves to the next. If all children fail then the selector node returns a <strong>failure</strong> value.</li>
<li><strong>Sequence Node</strong>: Similar to a Selector node in that it executes its children from left to right but stops at the first <strong>failure</strong>.</li>
<li><strong>Parallel Node</strong>: Can execute all its children simultaneously so you can have an enemy that is firing its weapon while also moving at the same time.</li>
</ul>
<h3 id="action-nodes">Action Nodes</h3>
<p>Action nodes represent specific actions the agent can perform and usually have a return value of <strong>success</strong>, <strong>failure</strong>, or <strong>running</strong> when they are executed. These are also the leaf nodes in a behavior tree. Some concrete examples include nodes for moving a character to a location or performing an attack.</p>
<h3 id="condition-nodes">Condition Nodes</h3>
<p>Condition nodes check for a specific condition and return <strong>success</strong> or <strong>failure</strong> based on the result of the condition evaluation. Some examples include checking to see if an enemy is in attack range or checking if the agent has low health.</p>
<h3 id="decorator-nodes">Decorator Nodes</h3>
<p>Decorator nodes modify the behavior of their child nodes. For instance, they can repeat a certain action node N times or add a delay in between actions.</p>
<h2 id="implementation">Implementation</h2>
<p>A behavior tree in Tempest contains an array to hold all of its nodes and has a pointer to an optional blackboard instance as you don&rsquo;t always need agent specific data to simulate the tree. I&rsquo;ll talk a bit more about blackboards later in this post. Tempest uses a factory pattern to create new nodes trivially. There&rsquo;s a macro that a node class can use to declare the required functions that will later be used to self register with the behavior tree node factory on application start. It essentially hashes the name of the node class to create a hopefully unique value that serves as a key to the map the factory has with the value being a wrapper to function that knows how to construct that node. The hashing function used has already been covered before in the <a href="https://yggdrasil-917.github.io/posts/asset-system/asset-system/">asset system</a> post so check it out if you haven&rsquo;t already. Suffice to say it uses the <a href="https://en.wikipedia.org/wiki/Fowler%E2%80%93Noll%E2%80%93Vo_hash_function">FNV-1A</a> hashing function which is very fast and has low collision rates.</p>
<p>Statically self registering to a factory object is a pattern used a couple times throughout the engine and for the most works really well. There is one annoying issue with it though and it is in regards with c++ compilers being &ldquo;smart&rdquo; and removing what it thinks is unused code at compile time. This can happen when statically initialized variables are not referenced anywhere in the codebase. There are two solutions to this that I am aware of, one is to create a dummy function that uses those static variables and have it called somewhere in the codebase effectively tricking the compiler into keeping the code. The other is to configure compilation arguments to tell the compiler not to strip things in a library and this is what Tempest uses on the libraries where it is required.</p>
<p>Simulating a behavior tree is not like calling a function. Any part of the tree can take any number of ticks to complete and because we have to worry about framerate we can&rsquo;t wait until the entire tree has been simulated. In practice what this means is that you need to yield behavior tree execution and perform the simulation over several frames. When we return to update the simulation on a new frame we keep track of the currently active node so we don&rsquo;t need to traverse the entire tree to find it every single time we simulate it. To give an example of this, consider the <strong>MoveToTile</strong> node which all it does is tell the movement system to begin moving the character to the target tile. The node will return a value of <strong>running</strong> so the behavior tree simulation function returns in order for other things to run on that thread. Every tick the tree is simulated it returns <strong>running</strong> so long as the movement system is animating the movement. Once it finishes moving the character, the <strong>MoveToTile</strong> node will return a value of <strong>success</strong> and the simulation moves on to the next node or finishes if that was the last node.</p>
<p>Since behavior trees are part of the asset system, they are shared among all agents referencing the same asset. This poses a problem if we want to slightly alter the tree at runtime. Think of adding a cooldown timer in between action nodes that is a different length based on the enemy type. The solution to this problem comes in the form of blackboards and the ability to allocate dynamic data for a node if instance specific data is required.</p>
<h3 id="blackboard">Blackboard</h3>
<p>So what are blackboards? These essentially serve as the memory for the AI agent&rsquo;s brain. It is usually implemented as a key-value map where the key tends to be a string and the value can be a lot of different types such as bools, ints, or even pointers. These days you can find blackboards being used in areas not related to AI as you can find them in any system that may need a key-value map that can be updated at runtime. You can see an example of that in Unity&rsquo;s Shader Graph. In Tempest, a blackboard is treated as an asset so the Asset Manager will own it. This means multiple behavior trees can make use of it and could in theory share data that way or even communicate with one another.</p>
<p>In the current version of the Tempest engine, the blackboard would probably be implemented through the scriptable object interface but it was implemented long before that existed. Due to that the blackboard asset has a different way of creating and editing its data but it is still kept simple. Since it is just a map the asset is defined in a text file with a specific key-value pair format where you specify the string for its key and the value right next to it. An example of what a blackboard asset looks like in Tempest is below with some comments left in as well. In the editor the importer will parse the text and convert it to a fast binary format that is used at runtime.</p>
<pre tabindex="0"><code># Format version number
1

# Format is keyName optionalDefaultValue
# for float[3] the values are separated by whitespaces
# if default value is omitted then it assigns a value of 0 to it

: Bool
myBool true

: Int
myInt 123

: Float
myFloat 0.123f

: Vector3
myV3 1.1 2.5 3.8

: Ptr
myObject
</code></pre><h2 id="authoring-bts">Authoring BTs</h2>
<p>Short of only doing very shallow and simple behavior trees, you will need a proper authoring tool to create the tree. In Tempest I opted to create a UI tool built into the editor that takes a lot of inspiration from the behavior tree editor found in Unreal Engine. Prior to this however, Tempest did not have a node editor system and instead of making my own I decided to look for a library that does that. Since I&rsquo;m using Dear ImGui for the editor UI and considering it is quite popular these days I assumed a node editor library using that would exist. Once I found one that looked promising it took about half a day to integrate into the engine and now that forms the foundation for the behavior tree editor in Tempest.</p>
<p>Here&rsquo;s a screenshot of the behavior tree editor implemented in Tempest and you will see plenty of similarities to the Unreal one. This shows the basic steps the enemy AI will go through.</p>
<p><img src="/images/behavior-trees/PawnBehaviorTree.png" alt="Pawn BT" title="PawnBehaviorTree"></p>
<p>It uses the same layout conventions as the one found in Unreal Engine. You&rsquo;ll find the root node at the very top of the tree and node execution follows a pre-order traversal approach if no nodes are skipped. The screenshot also has the ordinal numbers rendered to show what the execution order would be. If you want to change the order of execution then all you have to do is move the nodes just like you do in Unreal Engine so it is fairly easy and familiar.</p>
<p>Another feature in the editor is modifying any properties specific to a node that has been selected. For instance, if you have a node for pausing execution for a certain amount of time you&rsquo;d be able to specify that amount when the node is selected and that data will be serialized with the asset.</p>
<p>We also need to worry about serialization but thankfully, the <a href="https://yggdrasil-917.github.io/posts/serialization/serialization/">previously</a> outlined serialization method works well here. The only difference is that it also has to serialize some editor only data with the behavior tree asset. That editor only data is node positions and links used to construct the tree seen in the editor tool. That pretty much amounts to a long string containing node indices layed out hierarchically to define the link structure, the 2D positions in the canvas, and other small things like camera zoom level. This editor only information can be stripped from the asset when cooking a build so we can optimize file size that way.</p>
<h2 id="downsides-to-bts">Downsides to BTs</h2>
<p>So after doing all of this work to support behavior trees I was still a little unsatisfied at the results they were providing in the game. Granted I could improve it a lot more if I spent more time making game specific extensions but I felt like I might be fighting against what makes behavior trees what they are. For example, after setting up a basic behavior tree for enemies the actions they took felt very predictable and quickly got boring. In part this is due to the static nature of a behavior tree. They are created in the editor and the game just loads it as is. If you add enough conditionals or branches to the tree this predictable pattern is hidden a lot better but otherwise people can figure them out rather quickly. In a game where strategy is important I feel like this is a pretty big limitation and can lead to very easily manipulating the enemy AI.</p>
<p>Something I desire to reach is a system that can provide opportunities to create emergent behaviors. I don&rsquo;t feel like this is possible with behavior trees in part because of its static nature. The most I feel I can do is provide some randomness to certain decision making processes to make it look a bit more emergent but that&rsquo;s not enough. At the end of the day nobody is forcing me to use behavior trees so I am free to explore other options instead of trying to make a solution fit my criterias.</p>
<p>The last thing I&rsquo;ll mention is that the current implementation does require a lot of code to be written. Not just for the runtime usage but also all the editor specific implementations that need to be done before a new node can actually be used. Some of the burden would be reduced if there happened to be a good reflection API to help automate certain things but alas that is not really available. I also don&rsquo;t hold out much hope that reflection built into c++ would be the answer given how many times that has been delayed.</p>
<p>In the end, I opted to start looking for a different alternative and after researching for a bit I came to a couple of other options that could fit my criterias. In the next post on AI I will go over my implementation of Utility AI and some of its pros and cons.</p>
]]></content>
		</item>
		
		<item>
			<title>Lens Flare</title>
			<link>https://yggdrasil-917.github.io/posts/lens-flare/lens-flare/</link>
			<pubDate>Sat, 14 Sep 2024 11:34:55 -0700</pubDate>
			
			<guid>https://yggdrasil-917.github.io/posts/lens-flare/lens-flare/</guid>
			<description><![CDATA[%!s(<nil>)]]></description>
			<content type="html"><![CDATA[<p><img src="/images/lens-flare/LensFlareExample.png" alt="LensFlareExample" title="Lens Flare Example"></p>
<ul>
<li><a href="#overview">Overview</a></li>
<li><a href="#scriptable-object-asset">Scriptable Object Asset</a></li>
<li><a href="#lens-flare-profile">Lens Flare Profile</a></li>
<li><a href="#lens-flare-occlusion">Lens Flare Occlusion</a></li>
<li><a href="#rendering">Rendering</a></li>
<li><a href="#lens-flare-atlas">Lens Flare Atlas</a></li>
</ul>
<h2 id="overview">Overview</h2>
<p>A lens flare is a phenomenon caused by the lens of an eye or camera when looking at very bright lights. In the real world the shapes produced by a lens flare are determined by many factors such as the shape of the lens. The different hardware configurations with cameras is one reason lens flare seen by the human eye are pretty different from lens flares created by a camera lens. With camera lenses you can typically see hexagonal shapes or circular ghosts across the viewport unlike with the human eye.</p>
<p>The goal for Tempest was to develop a flexible lens flare rendering system that could be used to emulate the types of lens flares you see coming from both cameras and human eyes. It goes without saying but this system has to be efficient as well as it makes no sense to spend too much of your frame budget on this feature. To that end, a fast and efficient data-driven sprite based rendering method was used to implement lens flares in Tempest unlike other methods that rely on screen space procedural techniques as those tend to be slower and harder to configure its look.</p>
<h2 id="scriptable-object-asset">Scriptable Object Asset</h2>
<p>First though, lets discuss what was used to make lens flare rendering data driven as I have yet to discuss what a scriptable object asset is within the context of Tempest. The scriptable object asset is a data only container where its serialized content can be customized from c++. This is achieved through a abstract base class that defines an interface to adhere to. For those familiar with scripting in Unity this concept should be familiar as the idea was pretty much lifted from that engine.</p>
<p>One big benefit of using an asset to store data is that it is memory efficient. Since the asset manager will never load the same asset multiple times you can be confident that you will only pay the memory cost for only one instance. Then any game entity seeking to access the same asset will get a reference to the already loaded asset. Finally, being loaded by the asset manager the scriptable object&rsquo;s lifetime is also managed by the asset manager which makes using scriptable objects very easy to use.</p>
<p>Here is what the scriptable object base class looks like.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-cpp" data-lang="cpp"><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">TE_ECS_API</span> <span class="n">ScriptableObject</span>
</span></span><span class="line"><span class="cl"><span class="p">{</span>
</span></span><span class="line"><span class="cl"><span class="k">protected</span><span class="o">:</span>
</span></span><span class="line"><span class="cl">    <span class="kt">bool</span> <span class="n">isValid</span> <span class="o">=</span> <span class="nb">false</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="kt">void</span> <span class="nf">CopyBaseMembers</span><span class="p">(</span><span class="n">ScriptableObject</span><span class="o">*</span> <span class="n">other</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="n">isValid</span> <span class="o">=</span> <span class="n">other</span><span class="o">-&gt;</span><span class="n">isValid</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">public</span><span class="o">:</span>
</span></span><span class="line"><span class="cl">    <span class="k">virtual</span> <span class="o">~</span><span class="n">ScriptableObject</span><span class="p">()</span> <span class="p">{</span> <span class="n">isValid</span> <span class="o">=</span> <span class="nb">false</span><span class="p">;</span> <span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">virtual</span> <span class="n">ScriptableObject</span><span class="o">*</span> <span class="nf">Clone</span><span class="p">()</span> <span class="p">{</span> <span class="k">return</span> <span class="k">nullptr</span><span class="p">;</span> <span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">virtual</span> <span class="kt">void</span> <span class="nf">Copy</span><span class="p">(</span><span class="n">ScriptableObject</span><span class="o">*</span> <span class="cm">/*other*/</span><span class="p">)</span> <span class="p">{}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">virtual</span> <span class="kt">bool</span> <span class="nf">Equals</span><span class="p">(</span><span class="n">ScriptableObject</span><span class="o">*</span> <span class="cm">/*other*/</span><span class="p">)</span> <span class="p">{</span> <span class="k">return</span> <span class="nb">false</span><span class="p">;</span> <span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1">// This is useful when comparing against other instances of a scriptable object
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="k">virtual</span> <span class="n">uint64</span> <span class="nf">GetContentHash</span><span class="p">()</span> <span class="k">const</span> <span class="p">{</span> <span class="k">return</span> <span class="mi">0</span><span class="p">;</span> <span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1">// This gets called after deserialization is done
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="k">virtual</span> <span class="kt">void</span> <span class="nf">OnInitialize</span><span class="p">()</span> <span class="p">{</span> <span class="n">isValid</span> <span class="o">=</span> <span class="nb">true</span><span class="p">;</span> <span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1">// This is usually implemented as a hash using the class name and used with a factory pattern for creation
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="k">virtual</span> <span class="n">uint64</span> <span class="nf">GetTypeHash</span><span class="p">()</span> <span class="p">{</span> <span class="k">return</span> <span class="mi">0</span><span class="p">;</span> <span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1">// This is mainly used for creating editor menus
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="k">virtual</span> <span class="k">const</span> <span class="kt">char</span><span class="o">*</span> <span class="nf">GetTypeName</span><span class="p">()</span> <span class="k">const</span> <span class="p">{</span> <span class="k">return</span> <span class="s">&#34;ScriptableObject&#34;</span><span class="p">;</span> <span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1">// This can be used to draw the ImGui UI in the editor
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="c1">// Returns true if object was modified, false otherwise
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="k">virtual</span> <span class="kt">bool</span> <span class="nf">DrawEditorUI</span><span class="p">(</span><span class="k">const</span> <span class="k">struct</span> <span class="nc">EditorHelperData</span><span class="o">&amp;</span> <span class="cm">/*data*/</span><span class="p">)</span> <span class="p">{</span> <span class="k">return</span> <span class="nb">false</span><span class="p">;</span> <span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1">// Describe how to serialize the asset
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="k">virtual</span> <span class="kt">void</span> <span class="nf">PupAsset</span><span class="p">(</span><span class="k">class</span> <span class="nc">Pupper</span><span class="o">*</span> <span class="cm">/*p*/</span><span class="p">)</span> <span class="p">{}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">template</span> <span class="o">&lt;</span><span class="k">class</span> <span class="nc">T</span><span class="o">&gt;</span>
</span></span><span class="line"><span class="cl">    <span class="k">static</span> <span class="n">T</span><span class="o">*</span> <span class="n">Instantiate</span><span class="p">(</span><span class="n">T</span><span class="o">*</span> <span class="n">original</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="n">original</span><span class="o">-&gt;</span><span class="n">Clone</span><span class="p">();</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">static</span> <span class="n">ScriptableObject</span><span class="o">*</span> <span class="nf">Instantiate</span><span class="p">(</span><span class="n">ScriptableObject</span><span class="o">*</span> <span class="n">original</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="n">original</span><span class="o">-&gt;</span><span class="n">Clone</span><span class="p">();</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl"><span class="p">};</span>
</span></span></code></pre></div><h2 id="lens-flare-profile">Lens Flare Profile</h2>
<p>With scriptable objects discussed we can now move on talk about the lens flare profile class which itself derives from the scriptable object base class to store lens flare specific configuration data.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-cpp" data-lang="cpp"><span class="line"><span class="cl"><span class="k">struct</span> <span class="nc">LensFlareElement</span>
</span></span><span class="line"><span class="cl"><span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="c1">// config data here
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="p">};</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">LensFlareProfile</span> <span class="o">:</span> <span class="k">public</span> <span class="n">ScriptableObject</span>
</span></span><span class="line"><span class="cl"><span class="p">{</span>
</span></span><span class="line"><span class="cl"><span class="k">protected</span><span class="o">:</span>
</span></span><span class="line"><span class="cl">	<span class="n">uint8</span> <span class="n">structVersion</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span> <span class="c1">// for serialization purposes
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>
</span></span><span class="line"><span class="cl">	<span class="n">DECLARE_SO_REGISTRANT</span><span class="p">(</span><span class="n">LensFlareProfile</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">public</span><span class="o">:</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">	<span class="n">LensFlareProfile</span><span class="o">*</span> <span class="n">Clone</span><span class="p">()</span> <span class="k">override</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">	<span class="kt">void</span> <span class="nf">Copy</span><span class="p">(</span><span class="n">ScriptableObject</span><span class="o">*</span> <span class="n">other</span><span class="p">)</span> <span class="k">override</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">	<span class="kt">bool</span> <span class="nf">Equals</span><span class="p">(</span><span class="n">ScriptableObject</span><span class="o">*</span> <span class="n">other</span><span class="p">)</span> <span class="k">override</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">	<span class="k">const</span> <span class="kt">char</span><span class="o">*</span> <span class="nf">GetTypeName</span><span class="p">()</span> <span class="k">const</span> <span class="k">override</span> <span class="p">{</span> <span class="k">return</span> <span class="s">&#34;LensFlareProfile&#34;</span><span class="p">;</span> <span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">	<span class="kt">bool</span> <span class="nf">DrawEditorUI</span><span class="p">(</span><span class="k">const</span> <span class="k">struct</span> <span class="nc">EditorHelperData</span><span class="o">&amp;</span> <span class="n">data</span><span class="p">)</span> <span class="k">override</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">	<span class="kt">void</span> <span class="nf">PupAsset</span><span class="p">(</span><span class="k">class</span> <span class="nc">Pupper</span><span class="o">*</span> <span class="n">p</span><span class="p">)</span> <span class="k">override</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">	<span class="n">Vector</span><span class="o">&lt;</span><span class="n">LensFlareElement</span><span class="o">&gt;</span> <span class="n">elements</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="p">};</span>
</span></span></code></pre></div><p>As you can see, it is very brief like most other classes derived from the scriptable object base class. It generally boils down to implementing functions use for cloning, copying, and comparison. Then we can also specify how to serialize the data and how to draw the UI in the editor for easy editing of each of the properties inside the class. In theory, a lot of this could be automated if a robust reflection system was available in c++ but for now all of that is done manually.</p>
<p>In the sample code you will notice a struct called <code>LensFlareElement</code> and its responsibility is to store every possible setting specific to an individual lens flare. This can be anything from color properties, shape properties, and transform properties. The lens flare profile can keep track of any number of those lens flare elements to create intricate and complex looking lens flares. The engine uses a component system similar to what you find in engines like Unity and in that fashion Tempest has a lens flare component that can be added to any entity in a scene, regardless of whether it is a light source or not. It is this component that stores a reference to a user specified lens flare profile asset and in this way it is very easy for multiple entities in a scene with a lens flare component to share the same looking lens flare. On top of that the component itself also stores a few additional global parameters that can affect some of the local settings specified by the lens flare profile. This includes things a global intensity parameter to give an example.</p>
<p>Lets expand a little on some of the supported parameters available in a lens flare element. For color properties, the lens flare element exposes settings to control its local intensity. This allows making some of the individual lens flare elements brighter or dimmer than the rest. We are also able to tint them by a user specified color or if the lens flare component is attached to a light source then we can automatically tint it based on the color of the light source. You can see this in effect with the screenshot at the top of the article as the lens flare is being tinted by the color of the directional light source. Other color related features are under consideration but no plans to implement them yet. An example of such a feature is specifying an animation curve to change the color of a lens flare element based on how far away it is from the source. This would allow creating more interesting color transitions to the lens flare.</p>
<p>In regards to transform properties for lens flare elements, the system allows you to do many different kinds of positional transforms and distortions. You can easily do all the common forms of transforms to the lens flare elements so that means you can offset positions, scale them, and even rotate them. There are also some procedural functions that can introduce some amount of distortion to the lens flare element so we can make them look a bit more complex.</p>
<p>Finally, the system support various kinds of lens flare shapes that can be chosen from a dropdown in the editor. Using SDF functions we can render circular or polygonal shapes like hexagons. We can actually render a variable number edges in a polygon so we can go from a simple triangle to something that has too many edges making it look like a circle but of course in the latter case we offer a faster alternative in the form of a circle SDF. There are properties that can control the falloff or hardness of the SDF function used to create those shapes and we can even invert the SDF function results allowing the creation of halo like lens flare elements as well.</p>
<p>The final type of lens flare shape supported is one that is determined by a grayscale texture. This fills in the gaps that the circle and polygonal shapes can&rsquo;t create performantly. This type however, required a lot more work to properly support it alongside the other types and the details about it will be discussed later in the article.</p>
<h2 id="lens-flare-occlusion">Lens Flare Occlusion</h2>
<p>Supporting lens flare occlusion is an important feature to have and implementations have varied over the years. For a long time this feature used to be done with hardware occlusion queries but these days there are better ways. In Tempest, lens flare occlusion is done by stochastically sampling the scene depth texture multiple times to create an average visibility value. Among the configurable parameters inside the lens flare component is the ability to set the search radius in screen space units. The source of the lens flare is treated as a disk in screen space that will be randomly sampled with the sampled location doubling as texture coordinates to look up the scene depth. That scene depth is compared with the screen space depth of where the lens flare source is located. If the scene depth is closer to the camera than the lens flare source then we know that sample is occluded otherwise it is visible and gets accumulated to the final visibility average. This computation can be optionally skipped if the lens flare component is setup to do not do the occlusion pass for that instance.</p>
<p>Setting up the occlusion rendering pass is fairly simple. Tempest uses a texture 2D array to store the visibility results for each lens flare that will be rendered in a frame. The width and height of each slice is only one pixel and the number of slices in the array is set to the max number of lens flares Tempest can render in one frame. At the time of this writing that max number is set to 128 so the final dimensions of the texture 2D array is 1x1x128 with a format of R32 floating point so memory footprint is very small. Also the fact that we are only rasterizing one pixel to compute the visibility results make this very fast even while using a high number of stochastic samples to lookup the scene depth.</p>
<h2 id="rendering">Rendering</h2>
<p>In order to render the lens flares, Tempest keeps track of a GPU constant buffer that contains the required data to instance render each lens flare visible in the frame. So in one draw call we can render all the lens flares. This means Tempest does one draw call to render all lens flares to create the visibility texture 2D array and one more draw call to render all the flares into the scene color render target. Each packed instance of a lens flare uses up 112 bytes with 128 total lens flares means the constant buffer is around 14KB in size. You can see what the packed struct looks like below and the constant buffer just has an array of those.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-cpp" data-lang="cpp"><span class="line"><span class="cl"><span class="k">struct</span> <span class="nc">LensFlareData</span>
</span></span><span class="line"><span class="cl"><span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="n">float4</span> <span class="n">tint</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="n">float4</span> <span class="n">data0</span><span class="p">;</span> <span class="c1">// x: localCos0, y: localSin0, zw: PositionOffsetXY
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="n">float4</span> <span class="n">data1</span><span class="p">;</span> <span class="c1">// x: OcclusionRadius, y: OcclusionSampleCount, z: ScreenPosZ, w: ScreenRatio
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="n">float4</span> <span class="n">data2</span><span class="p">;</span> <span class="c1">// xy: ScreenPos, zw: FlareSize
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="n">float4</span> <span class="n">data3</span><span class="p">;</span> <span class="c1">// x: Allow Offscreen, y: Edge Offset, z: Falloff, w: invSideCount
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="n">float4</span> <span class="n">data4</span><span class="p">;</span> <span class="c1">// x: SDF Roundness, y: Poly Radius, z: PolyParam0, w: PolyParam1
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="n">float4</span> <span class="n">data5</span><span class="p">;</span> <span class="c1">// x: occlusion index, y: LFEF flags, z: flare type
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="p">};</span>
</span></span></code></pre></div><p>Hadn&rsquo;t mentioned it yet but the draw calls to render these lens flares do not use any sort of vertex or index buffer for each sprite. It instead uses a procedural draw call where the number of instances and number of verts are specified. In out case the number of verts is set to 4 as we want quads and the number of instances is set to the number of lens flare instances packed into the constant buffer. The vertex shader takes care of computing the vertex position based on the vertex ID before being transformed by the lens flare specific transforms and we use the instance ID to lookup the correct lens flare data for the instance being drawn. This is all achieved using <code>SV_VertexID</code> and <code>SV_InstanceID</code> inputs to the vertex shader. The vertex position is computed with the sample function below using the vertex ID as input.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-hlsl" data-lang="hlsl"><span class="line"><span class="cl"><span class="kt">float2</span> <span class="n">GetQuadVertexPosition</span><span class="p">(</span><span class="kt">uint</span> <span class="n">vertexId</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="kt">float</span> <span class="n">u</span> <span class="o">=</span> <span class="n">vertexId</span> <span class="o">&amp;</span> <span class="mi">1</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="kt">float</span> <span class="n">v</span> <span class="o">=</span> <span class="p">(</span><span class="n">vertexId</span> <span class="o">&gt;&gt;</span> <span class="mi">1</span><span class="p">)</span> <span class="o">&amp;</span> <span class="mi">1</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="kt">float2</span><span class="p">(</span><span class="n">u</span> <span class="o">*</span> <span class="mi">2</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">v</span> <span class="o">*</span> <span class="mi">2</span><span class="p">);</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span></code></pre></div><p>Another important detail when rendering into the texture 2D array for occlusion information is the fact the vertex shader needs to output the index of the slice in the array the draw is rendering into. This is done by outputting a result to <code>SV_RenderTargetArrayIndex</code> which just so happens to be the same value stored in <code>data5.x</code> so this becomes trivial to do.</p>
<h2 id="lens-flare-atlas">Lens Flare Atlas</h2>
<p>There is one major feature I haven&rsquo;t talked about much yet and that is supporting lens flares that sample a user specified texture for the flare&rsquo;s shape. I wanted to support this feature while also still being able to render all lens flares in one draw call which is not the simplest thing to do when you want to allow user specified textures of any reasonable size. At first I had considered using a texture 2D array to store all these textures but the problem with that is that each slice of the array has to have the same resolution and that&rsquo;s a deal breaker. The only other option left is to dynamically pack those individual textures into one big atlas. To make this work I would also need to provide the information on where to sample that atlas to retrieve the correct texture for any given lens flare. In this case, we alias the memory of <code>data4</code> from the <code>LensFlareData</code> struct to store the scale and offset to properly sample the tile inside the atlas texture. This is safe to do since that variable is only used when the lens flare shape is set to be a procedural polygon type.</p>
<p>The first problem to solve is packing the textures of any resolution into the atlas. As far as I know that is an <a href="https://en.wikipedia.org/wiki/NP-completeness">NP-Complete</a> problem which tends to mean there is no theoretically optimal solution. Though considering this is a fairly common problem in graphics there are several algorithms out there with simple to complex heuristics that can help solve the problem quickly. In my case, I do not need the best but good enough and fast enough will do. In that spirit, Tempest uses a greedy algorithm that sorts the textures to be packed based on area and starts adding the biggest textures into the atlas first and makes its way down to the smallest textures as long as they fit in the atlas. This does not produce the most efficient use of the space in the Atlas but it is very fast and simple to implement. It&rsquo;s also worth noting the atlas is allocated using the render target pool allocation system so it is treated as a transient texture. If no lens flares need to use this atlas then the texture is not allocated and if it was allocated previously then it will eventually be deallocated if nothing has requested to use it for several frames.</p>
<p>Here is an example of what the lens flare atlas looks like after packing two user specified grayscale textures.</p>
<p><img src="/images/lens-flare/FlareAtlas.png" alt="LensFlareAtlas" title="Atlas"></p>
<p>Here is what the lens flares look like using the atlas.</p>
<p><img src="/images/lens-flare/TexturedFlares.png" alt="TexturedLensFlares" title="Textured Flares"></p>
]]></content>
		</item>
		
		<item>
			<title>Localizing Text</title>
			<link>https://yggdrasil-917.github.io/posts/localizing-text/localizing-text/</link>
			<pubDate>Sun, 04 Aug 2024 17:41:30 -0700</pubDate>
			
			<guid>https://yggdrasil-917.github.io/posts/localizing-text/localizing-text/</guid>
			<description><![CDATA[%!s(<nil>)]]></description>
			<content type="html"><![CDATA[<p>Localization is one of those things many people in game dev talk about but there doesn&rsquo;t seem to be a consensus on whether it is valuable to do in your games. For every presentation or post-mortem talking about the benefits of it and how it was key to their success you can find an equal number stating it didn&rsquo;t help. With that in mind, I&rsquo;m not entirely sure if I will localize all the text in the game I&rsquo;m making but that doesn&rsquo;t mean that I did not make a system for localization just in case I do decide to do so. I don&rsquo;t believe the game will have an excessive amount of text so the solution I built for localization is not that complex and I will outline it here.</p>
<p>So how do we make a localization system that is easy to add new languages and is performant?</p>
<p>In short, we make a table loaded with all the localized text and we use unique IDs to lookup the correct translations. Few things are faster than indexing into an array so this is what is used to store all the translated strings instead of something like a hash table. Using a hash table also has the downside of needing to hash the key in order to get the localized text back so there&rsquo;s a performance cost that can be easily avoided by using an array as the underlying data structure to store the text. With a bit of tooling we can automate the process of creating these unique IDs offline and then use them at runtime so we never need any sort of hashing to access to correct localized text.</p>
<p>At the start of the application the localization data of the desired language is loaded into memory where a static object will store the array containing all the localized text. Having it be globally accessible through an API makes it very easy to use anywhere in the application. It is never modified after loading so there is also no worry about accessing that data from a different thread. The unique IDs for each localized text is stored in a auto-generated header file where each ID is a macro that contains an unsigned integer.</p>
<p>That&rsquo;s pretty much all there is to using the localization system so lets take a look at how the authoring side of the system works.</p>
<p>The engine has a localization folder where the user may place json files containing the localization data for their project. The name of each of those files is very important as the name has to be the <a href="https://en.wikipedia.org/wiki/Language_code">language code</a> of whatever language the data in the file represents. For instance, US English file will be denoted by the language code <strong>en-US</strong>. At the moment it is assumed that the file will contain all the localized text needed in the game. It was mentioned that file itself uses the json format but only because other systems were using json files as well and not because it provides any benefit. The localization file is essentially a key value pair listing the identifier of the localized text and its actual text.</p>
<pre tabindex="0"><code>Example of an entry in the localization file
{
  &#34;Setting_GraphicsTab&#34;: &#34;Graphics&#34;,
  &#34;Graphics_Resolution&#34;: &#34;Resolution&#34;,
  ...
}
</code></pre><p>Tempest has a separate executable, referred to as the Localizer, which will parse the project&rsquo;s localization folder. The output is the header file containing up to date localization IDs for each text in the localization file and binary file containing the localized text for optimal serialization/deserialization tasks later on. So continuing from the example above, a sample output of the header file looks like this:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-cpp" data-lang="cpp"><span class="line"><span class="cl"><span class="cp">#define LOC_SETTING_GRAPHICSTAB (73u)
</span></span></span><span class="line"><span class="cl"><span class="cp">#define LOC_GRAPHICS_RESOLUTION (74u)
</span></span></span><span class="line"><span class="cl"><span class="cp"></span><span class="p">...</span>
</span></span></code></pre></div><p>Then in order to get the localized text from that ID we can utilize the localization API like the example below.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-cpp" data-lang="cpp"><span class="line"><span class="cl"><span class="k">const</span> <span class="n">LocalizedString</span><span class="o">&amp;</span> <span class="n">graphicsTabText</span> <span class="o">=</span> <span class="n">Localization</span><span class="o">::</span><span class="n">Localize</span><span class="p">(</span><span class="n">LOC_SETTING_GRAPHICSTAB</span><span class="p">);</span>
</span></span><span class="line"><span class="cl"><span class="c1">// Use localized text as needed
</span></span></span></code></pre></div><p>The one downside of this approach is that any time a localized text entry is added or removed, the header file has to be regenerated and this means compiling the engine. For now that isn&rsquo;t too much of an issue but it is an area that could be improved.</p>
<p>Finally, there is a batch file available in the engine to make it easy to run the localizer tool but this is also something that could be improved. For now though this works well with my workflow so there aren&rsquo;t any plans to update this process.</p>
<p>One last thing is that the in-game console has a helper command to trigger a full reload of the localization data. This is very useful during development when only the content of the localized text is modified and no entries are added or removed.</p>
<p>And that is pretty much the totality of the localization system inside of Tempest. As noted at the start, it is a fairly simple solution but still pretty powerful.</p>
]]></content>
		</item>
		
		<item>
			<title>Game UI</title>
			<link>https://yggdrasil-917.github.io/posts/game-ui/game-ui/</link>
			<pubDate>Fri, 02 Aug 2024 16:12:16 -0700</pubDate>
			
			<guid>https://yggdrasil-917.github.io/posts/game-ui/game-ui/</guid>
			<description><![CDATA[%!s(<nil>)]]></description>
			<content type="html"><![CDATA[<ul>
<li><a href="#ui-requirements">UI Requirements</a></li>
<li><a href="#logic-updates">Logic Updates</a></li>
<li><a href="#rendering">Rendering</a></li>
<li><a href="#stitching-triangle-strips">Stitching Triangle Strips</a></li>
<li><a href="#9-slicing-sprite">9-Slicing Sprite</a></li>
<li><a href="#basic-rich-text-support">Basic Rich Text Support</a></li>
<li><a href="#localization">Localization</a></li>
<li><a href="#frosted-glass-look">Frosted Glass Look</a></li>
<li><a href="#creating-gUI-content">Creating GUI Content</a></li>
<li><a href="#limitations">Limitations</a></li>
<li><a href="#examples">Examples</a></li>
</ul>
<p>The Tempest engine has support for two UI systems. It makes heavy use of <a href="https://github.com/ocornut/imgui">Dear ImGui</a> for the editor UI and the in-game debug console but there is also a custom UI system made to handle the game&rsquo;s UI needs. As great as Dear ImGui is, you will rarely see it used in released titles, at least not as the main system behind a game&rsquo;s UI. There are multiple reasons for it but in my opinion one of the big reasons is that it is not trivial to re-skin the UI elements. The immediate mode design of the API can also be a big factor for some. Eventually a custom game UI system was designed to meet the needs of the game being made with Tempest and most of it has been developed by this point. This post will cover many aspects of the game UI system developed so far.</p>
<h2 id="ui-requirements">UI Requirements</h2>
<p>The most important idea driving the requirements for this game UI system is that it is perfectly fine that it does not have many features but the features it does have work great. Having a general idea of what the UI will be like for the game helps tremendously to narrow down the requirements for the system.</p>
<p>So what are the specific UI requirements needed for the game?</p>
<p>Well performance means a great deal to me so being able to render the game&rsquo;s UI in under a millisecond will be a huge win. The GPU will already be taxed enough with all the supported rendering features in Tempest so keeping this as low as possible will be very important to overall performance. Ideally having only one draw call to render all the UI visible on the screen is the target to hit. This would mean all the UI uses the same &ldquo;material&rdquo; to reduce draw call count and should be achievable with a moderately complex shader.</p>
<p>Since the game will support gamepad and mouse and keyboard, the UI needs to be able to handle both for navigation and interaction. As a gamer, I find it frustrating when you play a game that may push you to use one form of hardware input but their UI doesn&rsquo;t support it so you have to switch to another form of hardware input like mouse and keyboard in order to interact with it. This is a terrible user experience and I would prefer not contribute to that messy experience.</p>
<p>Many of the common UI widget types need to be supported. In Tempest this means support for labels, buttons, sliders, toggles, dropdowns, and scrolling lists. With that set of widgets supported you can pretty much make anything you will need and with texturing support too you will be able to make it look however you want.</p>
<p>Loading up any UI panel needs to be instantaneous while running the game. There have been many games over the years where opening up a menu can trigger a half second stutter as the menu resources are loaded from disk, shaders compiled, etc. Menu navigation will be common enough that I want that to feel responsive as you open and close different menus.</p>
<p>UI assets need to support hot-reloading in the editor. This is crucial to develop the layout of new panels quickly.</p>
<p>Support for localizing text in the UI. It is really nice to have a system like this in place from the start as otherwise, it can be pretty laborious to add localization support to a system that was implemented without it.</p>
<p>Finally, any custom scripting logic needs should be easily solved with the scripting system in Tempest.</p>
<h2 id="logic-updates">Logic Updates</h2>
<p>Many UI systems have a way to establish some sort of hierarchy with an object that contains any number of child widgets. In Unity that is the canvas object and in Tempest that is the GuiPanel. This object contains a list of UI widgets so it is easy to update all of them every frame. Like many UI systems, you can setup the states for all the widgets. So you can control whether or not a widget is visible on the screen, or if you want it to be hidden but still have its logic updated, or skipped entirely. With the GuiPanel object, you can set its state to be hidden and then all its children widgets will be skipped from being updated so you can have multiple panel objects loaded into memory and only pay the performance cost for the active ones.</p>
<p>The engine has a built in component system that will iterate over all GuiPanels loaded in the scene. It can use the job system to update widget states. This logic update is meant for updating widget types that can respond to user inputs such as a button press or mouse click. On PC we need to also keep track of the mouse position so we can highlight any button underneath the mouse position. At this point in time there is no spatial data structure to optimize searching for such a widget since there aren&rsquo;t enough of those to make it worth it and multithreading is used anyway so the speed is incredibly fast.</p>
<p>One thing I find to be important these days on PC is to be able to give the user the choice of what gamepad icons to use in the UI. It&rsquo;s fairly easy to add support for the icons specific to a platform and let the user choose which ones to use for their playthrough. I hope this becomes the norm in the future and I do see more games doing this so that&rsquo;s encouraging. A nice to have feature on PC is for the UI to dynamically update what gamepad icons are used based on the most recent input received. I kinda like having the game switch to using mouse and keyboard icons if the most recent input came from the mouse but that might just be a preference of mine.</p>
<p>An important design of the UI system is to use event driven UI events. Widgets that can respond to user inputs have a way to assign lambda functions to the events the widget supports. For instance, a button widget will have an event for when the button is pressed. During its logic update, it will detect if this happened on the current frame and if so it will call the lambda for that event if it is set. This gives a very easy way to script the behavior of these widgets and a performant one too.</p>
<h2 id="rendering">Rendering</h2>
<p>As previously stated, performance is the main priority in the design of this system. One of the core principles behind that being to use one draw call to render all the visible elements or at least as few as possible. For most game UIs, this means solving the problem of rendering many quads in a performant way.</p>
<p>So how can we render the UI with one draw call?</p>
<p>Well the renderer manages one large vertex buffer to store the vertices required to render all the visible UI elements. Using the Tempest job system the CPU data is updated every frame before sending it to the GPU. Right before updating the GUI rendering data, all the visible UI elements are sorted based on their Z-order depth value. This essentially creates layers where low values are rendered behind larger values. We combine that with all widget types using the same shader and then we have the perfect recipe to draw all the elements in one draw call. The shader supports two UI atlases and a couple of font textures to handle all the texturing requirements present in the game. This does mean the shader is a bit more complex than it would be otherwise and this does mean using branching in shaders to handle all the supported widgets. I know some will get scared at the sight of branches in a fragment shader but in the UI shader they are done based on constant buffer values so they are very fast.</p>
<p>You may have noticed I mentioned nothing about an index buffer to go along with the UI vertices. I must admit I haven&rsquo;t done any recent performance tests but my gut feeling is using indexed drawing here is not going to be that benefitial and may be worse from a memory standpoint since we&rsquo;d have to manage the index buffer on CPU and GPU. It would also complicate the logic for preparing the vertices. Originally this system specified all the triangles individually, so rendering a quad required 6 vertices instead of 4 like you would with an indexed drawing method. I don&rsquo;t know if this is a good idea but I have since moved the UI system to use triangle strips instead of individual triangles. This brings the vertex requirement for one quad back down to 4 but it does mean padding the vertex buffer with <a href="https://en.wikipedia.org/wiki/Glossary_of_computer_graphics#degenerate_triangles">degenerate triangles</a> in order to be able to draw the whole UI in one draw call.</p>
<h3 id="stitching-triangle-strips">Stitching Triangle Strips</h3>
<p>This topic isn&rsquo;t mentioned a lot but it is very useful to know about it. If you aren&rsquo;t aware of what a <a href="https://en.wikipedia.org/wiki/Triangle_strip">triangle strip</a> is then very quickly it is a memory efficient way of packing vertex data where the driver has a predefined way of using them. For example, if you have four verts [A, B, C, D] defining a quad and you render it using a triangle strip primitive topology then the first triangle is formed from [A, B, C] and the driver will use the last two vertices combined with the next vertex in the buffer to make the next triangle. So the second triangle in that quad is formed by [B, C, D] and every subsequent triangle only needs to have one vertex specified as it will reuse the previous two vertices.</p>
<p>This is a great method to use when all your vertices are next to each other but how do you use it to render triangles that may not be a part of any given triangle strip? Lets say strip S is defined by the vertex buffer [A, B, C, D] and strip T is defined by [E, F, G, H]. How do we render them both in one draw call without any visual artifacts? Well as stated before this is where degenerate triangles come in to save the day. We create a strip U defined as [A, B, C, D, D, E, E, F, G, H]. That is to say we have a strip that contains both strip S and T and to bridge the gap between the two we append two vertices after strip S. One vertex is a duplicate of the last vertex of strip S and the second one is the first vertex of strip T. If you decide to resolve how the driver will interpret this buffer with a triangle strip topology you end up with something similar to what is below.</p>
<ul>
<li>A B C</li>
<li>C B D</li>
<li>C D D - deg</li>
<li>D D E - deg</li>
<li>D E E - deg</li>
<li>E E F - deg</li>
<li>E F G</li>
<li>G F H</li>
</ul>
<p>The degenerate triangles above do not get rasterized as they have no area so they will not be visible in the rendered image. The one downside of course is that it will inflate the vertex buffer, depending on how many independent triangle strips you may need to stitch together.</p>
<h3 id="9-slicing-sprite">9-Slicing Sprite</h3>
<p>Since texturing widgets is possible we also need to be able to handle texturing large sprites without warping or stretching the underlying texture. The usual method to solve that problem is using the <a href="https://docs.unity3d.com/Manual/9SliceSprites.html">9-slicing method</a> where you customize how the texturing is applied to the sprite.</p>
<p><img src="/images/game-ui/9SliceExample.png" alt="Slicing Example" title="Slicing Example"></p>
<p>In Tempest, you specify how you want it sliced using the text format to create the UI panels but more on that later. From the example image above, the regions marked as A, C, G, and I make up the corner of the sprite and those do not do anything special really. The other regions however, can be bigger than what the texture being applied to them is and in those cases tiling is used in order to avoid distorting the image.</p>
<p>As far as I know, there are two ways of implementing this. One way is to have a complex shader that figures out what region the fragment is in and textures accordingly. The other is to tessellate the sprite in the CPU taking into consideration how the slicing regions are laid out. Doing it this way means the shader does not need to change and the logic is kept in the CPU which could open opportunities for optimization like if you cache that mesh for example. Tempest renderer does the latter since we are already building the vertex buffer every frame it makes sense to add this additional logic for sprites that need to be sliced and everything else works the same.</p>
<p>This method does clash a bit with triangle strip rendering though. The regions that will tile the texture sampling need to have duplicate vertices so that we can specify the correct texture coordinates for them.</p>
<h3 id="basic-rich-text-support">Basic Rich Text Support</h3>
<p>It is very common these days for labels to contain a substring using a different color than the rest of the label, or an image, an animation, etc. This is typically solved by having support for rich text format. All this means is embedding special tags inside of your label that will determine some sort of transformation to apply to a subset of characters. The Tempest renderer has very basic support for this. In fact, the only thing supported at this moment is changing the color of parts of a label as that is the only thing that has been needed so far. That said, the architecture is there to add other kinds of tags of similar complexity to changing colors.</p>
<h3 id="localization">Localization</h3>
<p>While this is out of scope for this post, localizing UI text is supported in Tempest. There&rsquo;s a whole pipeline around creating and using these special kinds of strings that will be covered in a later post.</p>
<h3 id="frosted-glass-look">Frosted Glass Look</h3>
<p>A lot of games these days like to have that frosted glass look on their UI. It sort of simplifies the work in designing your but I also do kinda like the look so that was implemented in this UI system. The renderer already generates a blurred frame containing pretty much the entire lit scene so it can use this effect for &ldquo;free&rdquo;. There&rsquo;s a example screenshot below of the prototyped graphics settings in the game that showcases the frosted glass look.</p>
<p><img src="/images/game-ui/SettingsMenu.png" alt="Settings Menu" title="Settings Menu"></p>
<p>This effect is achieved by sampling the blurred texture and doing alpha blending in the shader between the widget&rsquo;s color and the blurred sampled color.</p>
<h2 id="creating-gui-content">Creating GUI Content</h2>
<p>After talking about all these features we still haven&rsquo;t mentioned how the UI panels are created. Sadly there is no fancy editor tool to create the UI panels instead opting to use a text based solution. Since GUIs have a hierarchy embedded into them I decided to use json as the text format to allow me to create the UI. The engine already supported reading json files so nothing new needed to be done there. All the properties for a widget is specified in the json file and given its hierarchical structure it can also easily let me specify relative positions for child widgets and the importer takes care of computing things like absolute positions. The way json keys work can also be used to create unique paths to any widget defined on that file or panel. This is used in the scripting system to request references to specific widgets in a panel and those references can be cached for later use. I think I can safely say a lot of the built in features that make up a json file are being taken advantage of to create the game UI system to great effect.</p>
<p>The json files specific to the UI system have a special kind of file extension so the asset manager can handle cooking, loading, and hot reloading of those assets. Since there is no editor gui to create these panels, it is very important to easily and quickly iterate on these UI panels so hot reloading them has been the best feature with this system by far.</p>
<p>One final note on authoring these panels is that they are made with a 16:9 aspect ratio as the target aspect ratio. Then the UI is scaled to handle other aspect ratios at runtime based on the rendering resolution. There will likely come a time where a more complex method might be needed but for now this works well.</p>
<h2 id="limitations">Limitations</h2>
<p>To no surprise there are some limitations at the moment that may or may not need to be addressed before the game is finished and I&rsquo;ll point some of them out here.</p>
<p>There is no support for clipping regions. At the moment things only get clipped based on the alpha value of the texture they sample or the vertex alpha. It could be benefitial to be able to discard fragments in specific regions of the UI but at the moment the game&rsquo;s UI design does not need it.</p>
<p>The UI panels are static, meaning there are no spatial animations. Supporting this could be a large endeavour as this would also imply providing ways to do animations from the content authoring tools and scripting. Most things wouldn&rsquo;t really need this but there could be a handful of combat related UI elements that could benefit from some animations.</p>
<p>No visual editing tool to create new UI panels, it is only text based.</p>
<h2 id="examples">Examples</h2>
<p>I&rsquo;ve added a few more examples of different panels made with this system. Just note that these are all prototypes and in no way final but thought I should give a few more examples of what the game UI can produce.</p>
<p><img src="/images/game-ui/PartyMenu.png" alt="Party Menu" title="Party Menu"></p>
<p>Thought it would be interesting to post a wireframe of what the mesh looks like when stiching together a bunch of strips into one. As you can tell, it is a little messy when you see those stray line segments connecting other strips all throughout the mesh.</p>
<p><img src="/images/game-ui/PartyMenuWireframe.png" alt="Party Menu" title="Party Menu Wireframe"></p>
<p>Here is an example of what the combat UI can look like at this point.</p>
<p><img src="/images/tempest-engine/editor.png" alt="Party Menu" title="Combat UI"></p>
]]></content>
		</item>
		
		<item>
			<title>Scriptable Entity</title>
			<link>https://yggdrasil-917.github.io/posts/scriptable-entity/scriptable-entity/</link>
			<pubDate>Sat, 27 Jul 2024 17:58:27 -0700</pubDate>
			
			<guid>https://yggdrasil-917.github.io/posts/scriptable-entity/scriptable-entity/</guid>
			<description><![CDATA[%!s(<nil>)]]></description>
			<content type="html"><![CDATA[<p>The <strong>Entity</strong> class is the base class in Tempest used for anything that can exist in the scene. This is comparable to the GameObject class in Unity or the Actor class in Unreal. Unlike the GameObject class in Unity however, entities do not require a transform component in order to exist in the scene. The class itself is very simple. All it has is an entity handle and a pointer to the scene that owns the entity. The entity handle comes from a framework called <a href="https://github.com/skypjack/entt">Entt</a> and is what Tempest uses to map the relationship between components and the entity.</p>
<p>Components in Tempest are structs that only contain data. There is no strict requirement for that in the engine other than personal taste. There are some component types that require logic and are handled by specialized systems that iterate over all of the components of that type. Updating components this way makes it very easy to use the job system to implement the logic update in a multithreaded manner. Component systems do not have to use multithreading though as sometimes there aren&rsquo;t enough components to update so using single threaded updates makes more sense. One such example of a component system is the system updating transform component data where if a transform has moved since the last frame then several matrices specific to that component get updated and cached for later use in the pipeline.</p>
<p>One special component type in the engine is the <strong>ScriptComponent</strong>. This is what makes it possible to script entities. It does this by storing an array of <strong>ScriptableEntity</strong> types which exposes the scripting API to objects deriving from this class. This API provides several hooks that will get called at specific locations within the engine&rsquo;s loop. Hooks like when the script is first created or attached to an entity, simulation callback for update logic, etc. It also provides ways to serialize properties for the entity and some editor functionality like custom property drawing.</p>
<p>Here is a screenshot depicting a high level flow chart of where the scriptable entity user callbacks fit into the engine.</p>
<p><img src="/images/scriptable-entity/TempestExecutionOrder.png" alt="Execution Order" title="Execution Order"></p>
<h2 id="on-scene-load">On Scene Load</h2>
<p>When a scene is loaded these scriptable entity functions get called. In the editor the scene needs to go into play mode for <strong>OnEnable</strong> and <strong>OnStart</strong> to be called.</p>
<ul>
<li><strong>OnCreate</strong> - Called once when a new instance of an entity is created. Will always be called before <strong>OnEnable</strong> and <strong>OnStart</strong>. It also does not matter if the entity is disabled by default. This is a good place to do any sort of allocation or caching.</li>
<li><strong>OnEnable</strong> - If the entity is enabled by default then this gets called right after <strong>OnCreate</strong> and before <strong>OnStart</strong>. After that it only gets called if the script was enabled after being disabled.</li>
</ul>
<h2 id="frame-update">Frame Update</h2>
<p>While the scene is in play mode, these functions will get called.</p>
<ul>
<li><strong>OnStart</strong> - Gets called the first time the script is updated and only if it is enabled.</li>
<li><strong>OnFixedSimulate</strong> - Can get called a variable number of times per frame depending on framerate or even not at all. Physics updates happen right after this phase in the pipeline.</li>
<li><strong>OnSimulate</strong> - Called once per frame and is the main location for any sort of update logic.</li>
</ul>
<h2 id="on-object-destruction">On Object Destruction</h2>
<ul>
<li><strong>OnDestroy</strong> - Called at the end of a frame when the entity is destroyed</li>
</ul>
<h2 id="on-object-disabled">On Object Disabled</h2>
<ul>
<li><strong>OnDisable</strong> - Called at the end of a frame when the script is disabled. Can also be called before <strong>OnDestroy</strong> when the entity is destroyed.</li>
</ul>
<h2 id="scriptable-entity-execution-order">Scriptable Entity Execution Order</h2>
<p>Scripting API is executed synchronously not unlike what you see in other popular engines. They do have access to the job system so scripts can do multithreaded tasks if they need to. If script execution is synchronous then how do you specify execution order? There is a simple mechanism to solve this problem. When a new script class is created in C++, you can optionally specify its execution priority otherwise it uses the default value of 0. This integer value is used to sort scripts every frame to establish the execution order.</p>
]]></content>
		</item>
		
		<item>
			<title>Interlaced Rendering</title>
			<link>https://yggdrasil-917.github.io/posts/interlaced-rendering/interlaced-rendering/</link>
			<pubDate>Fri, 26 Jul 2024 11:20:44 -0700</pubDate>
			
			<guid>https://yggdrasil-917.github.io/posts/interlaced-rendering/interlaced-rendering/</guid>
			<description><![CDATA[%!s(<nil>)]]></description>
			<content type="html"><![CDATA[<ul>
<li><a href="#what-is-it">What Is It</a></li>
<li><a href="#why-use-it">Why Use It</a></li>
<li><a href="#implementation">Implementation</a></li>
<li><a href="#deinterlacing">Deinterlacing</a></li>
<li><a href="#performance">Performance</a></li>
<li><a href="#final-thoughts">Final Thoughts</a></li>
</ul>
<h2 id="what-is-it">What Is It</h2>
<p>A more common name might be interlaced video. The idea originates decades ago in the TV industry where companies wanted to save on bandwidth. To quote Wikipedia, the interlaced signal contains two images of a video frame captured consecutively which enhances motion perception to the viewer, and reduces flicker by taking advantage of the characteristics of the human visual system. In other words, the images are rendered at half resolution in either the vertical or horizontal axis. Then the current image and the previous image are combined to reconstruct a new image that has twice the resolution of the individual images. <a href="https://en.wikipedia.org/wiki/Interlaced_video">Here</a> is a nice gif animating the process of interlacing two video fields to construct a higher quality image.</p>
<h2 id="why-use-it">Why Use It</h2>
<p>In realtime rendering, we can use the same idea as interlaced video to reap similar benefits. Assuming your overall performance is GPU bound then using lower bandwidth will yield better performance. Since Tempest uses a deferred renderer, being GPU bound is a common occurrence so implementing interlaced rendering will generally have a positive effect on performance. Using interlaced rendering implies using lower resolution render targets when rendering the 3D world. Any computationally intensive rendering passes will benefit from a lower resolution output. So adopting interlaced rendering can introduce performance benefits in various areas of the pipeline.</p>
<p>So if it can have these benefits then why aren&rsquo;t more engines using this type of rendering? Reconstructing the final image from two lower resolution images does introduce some rendering artifacts, especially when things are moving fast. The screenshot below shows an example of interlace artifacts after image reconstruction. The image is zoomed in to make the issue obvious and during normal gameplay it often doesn&rsquo;t stand out unless you know where to look. If you&rsquo;ve never seen it, I recommend looking at the <a href="https://www.slideshare.net/slideshow/dynamic-resolution-and-interlaced-rendering/253712465#68">presentation</a> that goes over interlaced rendering, which is also where the image below is from.</p>
<p><img src="/images/interlaced-rendering/InterlacedArtifacts.png" alt="Interlaced Artifacts" title="Interlaced Artifacts"></p>
<p>Other non-temporal based image reconstruction techniques suffer from similar issues. If you&rsquo;re familiar with <a href="https://pixiogaming.com/blogs/latest/checkerboard-rendering-an-ingenious-approach-to-4k-gaming">Checkerboard Rendering</a> techniques that were used when the PS4 Pro was released then you will know what I&rsquo;m talking about. Eventually advanced spatio-temporal upscalers got good enough to replace interlaced and checkerboard rendering solutions and the industry hasn&rsquo;t really looked back.</p>
<h2 id="implementation">Implementation</h2>
<p>In Tempest, the goal is to not use any temporal upscaler or TAA solution to construct the final image. This is only for stylistic reasons as I personally miss the sharp look frames used to have before these temporal solutions became ubiquitous. For this reason SMAA is the anti-aliasing technique of choice in Tempest. That said the engine does support FSR2 but it is mostly meant for comparing its results with other techniques in the engine. If by the end of the game&rsquo;s dev cycle the FSR solution is still working correctly then it might be available for users to enable through the graphics settings but the focus is to not rely on these techniques as much as possible.</p>
<p>Before going into the implementation details of interlaced rendering I&rsquo;ve added a gif below of the rendering test scene. It has two numbered frames 1 and 2, respectively. One frame is rendered using the normal progressive solution and the other frame uses interlaced rendering to construct the final image using the current and previous frame. Do you think you can spot which frame is using interlaced rendering?</p>
<p><img src="/images/interlaced-rendering/InterlacedRenderingComparison.gif" alt="Interlaced Comparison" title="Interlaced Comparison"></p>
<p>If you look at the two frames carefully then you will likely be able to tell which frame is using interlaced rendering. However, while playing the game you&rsquo;re likely not thinking about that though so you won&rsquo;t even notice the artifacts most of the time. Without further ado the frame using interlaced rendering is the one marked as number one.</p>
<p>Since most rendering resolutions used today are widescreen, the interlaced rendering solution will halve the width of the render targets as that will yield the best performance. The solution could be extended to halve vertical or horizontal resolution based on the aspect ratio but to keep things simple it will always halve the horizontal resolution. So for example, if the selected rendering resolution is 2560x1440 then the render targets used for the 3D environment will be set to 1280x1440.</p>
<h3 id="deinterlacing">Deinterlacing</h3>
<p>After all the geometry has been rendered, a deinterlace pass runs to reconstruct the image to the selected rendering resolution. In the example above, this would mean deinterlacing into a render target with the resolution of 2560x1440. The image is not yet presented to the backbuffer but instead now is when all fullscreen effects will run and the pipeline is the same as the normal progressive renderer. The presentation on interlaced rendering describes several different ways to deinterlace the image and I highly suggest you read the presentation for more details as I will only cover the deinterlace method used in Tempest.</p>
<p>The chosen deinterlace method is referred to as &ldquo;Weave&rdquo; in the linked interlaced rendering presentation, of which you can see a slide from it below. The basic idea is to insert the pixel columns of the new image in between every column of the previous image at which point you end up with an image that is twice the width of the previous images.</p>
<p><img src="/images/interlaced-rendering/WeaveSlide.png" alt="Weave Slide"></p>
<p>Like the slide mentions, reconstructing static scenes works extremely well and most of the deinterlace methods described in the presentation are fast methods that can achieve that quality. Dynamic scenes can however, show artifacts as previously detailed in this post. In those cases a more expenside deinterlace method can minimize those issues. Such a method is the temporal deinterlaced method but supporting it requires keeping track of several additional render targets so memory and performance requirements are higher. Keeping with the theme of the Tempest engine, no temporal solution is used and I typically prefer simple solutions if the result is good enough.</p>
<p>To perform the deinterlace pass, a fullscreen draw call with a custom fragment shader is used. The renderer does not explicitly store the previous frame&rsquo;s interlaced rendering results in order to keep VRAM usage as low as it can be while doing interlaced rendering. It does however, persistently store the result of the final scene color in a render target and this is what is used to represent the previous frame in the deinterlace pass. We can&rsquo;t read and write to it in the fragment shader so what the renderer does is setup hardware blending using the typical transparent blend mode. So for the fragments that do not need to be updated in the draw call will simply return a fully black pixel, including alpha set to 0. This will leave those fragments unmodified after the draw call and the fragments that need to be updated will simply sample the interlaced scene color render target and returns that value. Below is a code snippet detailing what the fragment shader function does. The final piece of the puzzle is to jitter the projection matrix every frame similar to what is done with TAA but only jittered horizontally in this case. Then we alternate updating the odd pixel columns on one frame and the even ones on the next frame so the entire reconstructed image is updated.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-hlsl" data-lang="hlsl"><span class="line"><span class="cl"><span class="c1">// Deinterlace fragment shader</span>
</span></span><span class="line"><span class="cl"><span class="kt">float4</span> <span class="n">MainPS</span><span class="p">(</span><span class="k">in</span> <span class="kt">float4</span> <span class="n">i_position</span> <span class="o">:</span> <span class="nd">SV_Position</span><span class="p">,</span> <span class="kt">half2</span> <span class="n">i_texcoord</span> <span class="o">:</span> <span class="n">TEXCOORD0</span><span class="p">)</span> <span class="o">:</span> <span class="nd">SV_Target</span>
</span></span><span class="line"><span class="cl"><span class="p">{</span>
</span></span><span class="line"><span class="cl">  <span class="kt">float2</span> <span class="n">uv</span> <span class="o">=</span> <span class="n">i_texcoord</span> <span class="o">*</span> <span class="n">g_Data</span><span class="p">.</span><span class="n">viewportScale</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">  <span class="kt">float4</span> <span class="n">finalColor</span> <span class="o">=</span> <span class="kt">float4</span><span class="p">(</span><span class="mo">0</span><span class="p">,</span><span class="mo">0</span><span class="p">,</span><span class="mo">0</span><span class="p">,</span><span class="mo">0</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">  <span class="kt">uint</span> <span class="n">pixelX</span> <span class="o">=</span> <span class="p">(</span><span class="kt">uint</span><span class="p">)</span><span class="n">i_position</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">  <span class="kt">bool</span> <span class="n">oddPixel</span> <span class="o">=</span> <span class="p">(</span><span class="n">pixelX</span> <span class="o">&amp;</span> <span class="mi">1</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">  <span class="kt">bool</span> <span class="n">doOdd</span> <span class="o">=</span> <span class="n">g_Data</span><span class="p">.</span><span class="n">updateOddColumns</span> <span class="o">!=</span> <span class="mo">0</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">  <span class="k">if</span> <span class="p">((</span><span class="n">oddPixel</span> <span class="o">&amp;&amp;</span> <span class="n">doOdd</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">  	<span class="o">||</span> <span class="p">(</span><span class="o">!</span><span class="n">oddPixel</span> <span class="o">&amp;&amp;</span> <span class="o">!</span><span class="n">doOdd</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">  <span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="n">finalColor</span> <span class="o">=</span> <span class="n">SceneColor</span><span class="p">.</span><span class="n">SampleLevel</span><span class="p">(</span><span class="n">s_LinearClampSampler</span><span class="p">,</span> <span class="n">uv</span><span class="p">,</span> <span class="mo">0</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">  <span class="p">}</span>
</span></span><span class="line"><span class="cl">  
</span></span><span class="line"><span class="cl">  <span class="k">return</span> <span class="n">finalColor</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span></code></pre></div><h2 id="performance">Performance</h2>
<p>The performance test was done with a rendering resolution of 2560x1440 so interlaced rendering uses a 1280x1440 resolution and it is running on a 2060 GPU. Using RenderDoc to time the GPU frame we can see that the rendering test scene can take around 10 - 11 milliseconds to render without interlaced rendering and can be as fast as 6 milliseconds to render with interlaced rendering. That is fairly close to a 2x speedup which is amazing considering that only the world is rendered using interlaced rendering while the rest of the pipeline uses the reconstructed image.</p>
<p>It is also important to mention that this interlaced rendering implementation makes good use of the 2x2 warp that fragment shaders typically execute as. If you search for other implementations of interlaced rendering reveals variants that use the stencil buffer to disallow rendering into odd or even pixel columns during the world rendering and then they complain about no performance improvements. This is absolutely not the way to implement interlaced rendering and should be avoided in favor of something like what this post has outlined.</p>
<h2 id="final-thoughts">Final Thoughts</h2>
<p>Interlaced rendering has so far provided many benefits to both runtime performance and memory usage while only introducing a handful of rendering artifacts. It seems to be really useful for the kind of game being made with Tempest where the camera is setup to offer a bird&rsquo;s eye view of the map. For games that require the camera to be up close to the environment may have some difficulties preserving model silhouettes with interlaced rendering. I suspect depth discontinuities would present themselves as flickering when a naive deinterlace method is used. The RE engine, used for Resident Evil titles, has demonstrated that interlace rendering can work well in those games. I suspect they probably use a temporal based interlaced rendering solution but I haven&rsquo;t done too much research on their implementation as there isn&rsquo;t any info about it that I could find.</p>
<p>Bottom line is that this technique is very useful and can be considered an alternative to modern spatio-temporal upscalers. It&rsquo;s also much simpler to implement and maintain than any upscaler, except for maybe FSR 1.0 since it is just a spatial upscaler. I do wish more developers would consider using and iterating on techniques like interlaced and checkerboard rendering as I think they can be improved even more. This can then offer more options to gamers as there is a camp that does not like the softness of images or ghosting artifacts produced by DLSS and its ilk while others have less tolerance for jaggies so they opt for upscalers.</p>
]]></content>
		</item>
		
		<item>
			<title>Tempest Engine Loop</title>
			<link>https://yggdrasil-917.github.io/posts/tempest-engine-loop/tempest-engine-loop/</link>
			<pubDate>Wed, 24 Jul 2024 20:30:08 -0700</pubDate>
			
			<guid>https://yggdrasil-917.github.io/posts/tempest-engine-loop/tempest-engine-loop/</guid>
			<description><![CDATA[%!s(<nil>)]]></description>
			<content type="html"><![CDATA[<p>The previous <a href="https://yggdrasil-917.github.io/posts/tempest-gpu-frame/tempest-gpu-frame/">post</a> did an in-depth look into how a Tempest frame is put together on the GPU. In this post I would like to do the same but looking at things from the CPU side. Essentially we will dive into what the engine loop does to create a brand new frame.</p>
<p>This time around we will look at a new scene in the middle of a combat scenario playing out as more things will happen on the CPU than the rendering test scene we looked at previously.</p>
<p><img src="/images/tempest-engine-loop/Combat.png" alt="Combat Scene" title="Combat Scene"></p>
<p>Tempest has support for the <a href="https://github.com/wolfpld/tracy">Tracy</a> profiler and you can see it in action below. The screenshot is a zoomed out view of the CPU timeline where you can see multiple frames being shown. We will zoom in and look at an individual frame while going over different systems that run in the engine loop.</p>
<p><img src="/images/tempest-engine-loop/cpuTimeline.png" alt="Tracy Timeline" title="Timeline"></p>
<p>And here is a screenshot showing only one frame. I suggest opening the image in a new tab so you can view the different performance markers spread throughout the frame. You may notice in the Tracy captures that there is a job system being used. The laptop running when this trace was captured has support for 12 threads and as such you can see 11 threads allocated for the job system plus the main thread to divide the work.</p>
<p><img src="/images/tempest-engine-loop/cpuTimelineZoomedIn.png" alt="Tracy Timeline" title="Frame Timeline"></p>
<p>I should note the editor allocates a few more threads on top of what the job system needs. These threads are used for things like handling network packets to support inter-process communication, file watching, etc. For the most part those threads are not doing anything and just waiting for work to come in which is why they didn&rsquo;t show up in the Tracy capture.</p>
<h2 id="running-the-editor">Running The Editor</h2>
<p>Here is the totality of the main function used by the editor but the player uses pretty much the same function.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-cpp" data-lang="cpp"><span class="line"><span class="cl"><span class="c1">// Tempest editor&#39;s main function
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="n">int32</span> <span class="nf">main</span><span class="p">(</span><span class="n">int32</span> <span class="n">argc</span><span class="p">,</span> <span class="kt">char</span><span class="o">**</span> <span class="n">argv</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="k">const</span> <span class="n">CommandLine</span> <span class="n">cmdLine</span><span class="p">(</span><span class="n">argc</span><span class="p">,</span> <span class="n">argv</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">    <span class="n">TempestEditor</span> <span class="n">editor</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">editor</span><span class="p">.</span><span class="n">Startup</span><span class="p">(</span><span class="n">cmdLine</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="mi">1</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="n">editor</span><span class="p">.</span><span class="n">RunEngineLoop</span><span class="p">();</span> <span class="c1">// where the work happens
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>
</span></span><span class="line"><span class="cl">    <span class="n">editor</span><span class="p">.</span><span class="n">Shutdown</span><span class="p">();</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span></code></pre></div><p>We start by extracting any information from the command line before we pass that to the initialization function where it will handle any setup the various systems need. This involves things like reading configuration files, creating the application&rsquo;s window, crash reporter hookup, and many other things. The editor has several things more to initialize (i.e. file watcher) that the player does not have to worry about and this is where it happens. If something failed during initialization then that will likely get logged and then exits. Otherwise, we fall into the engine loop where most things happen. Then we have the shutdown phase which as the name suggests is where all the cleanup happens before the application exits.</p>
<h2 id="engine-loop-structure">Engine Loop Structure</h2>
<p>To nobody&rsquo;s surprise every engine has a game loop however, no two are exactly the same. Despite the differences they tend to share the same ideas and have similar structure. Below is pseudocode depicting what goes on in the Tempest engine loop and you can also use the Tracy screenshot above to follow along.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-cpp" data-lang="cpp"><span class="line"><span class="cl"><span class="c1">// Simplified Tempest loop structure
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="k">while</span> <span class="p">(</span><span class="n">keepRunning</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="n">PumpWindowEvents</span><span class="p">();</span>
</span></span><span class="line"><span class="cl">    <span class="n">UpdateInput</span><span class="p">();</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="n">SimulateFixedTimeStep</span><span class="p">();</span>
</span></span><span class="line"><span class="cl">    <span class="n">Simulate</span><span class="p">(</span><span class="n">deltaTime</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="n">Render</span><span class="p">();</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="n">WaitForTargetFramerate</span><span class="p">();</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span></code></pre></div><h3 id="start-of-frame">Start Of Frame</h3>
<p>The very first thing done in the loop is to detect if there is any scene transition queued up and if so then the engine will load the new scene before doing anything else. In the editor, there is a concept of editing or playing the currently loaded scene. This is where the editor will change state and go from edit to play or vice-versa. Right after this is where the new frame&rsquo;s delta time is computed before sharing with all the other systems in the engine. Something to be aware of when computing the delta time is that the value can be completely wrong when you step through the application with a debugger. It&rsquo;s very easy to take a while stepping through the debugger and by the time the delta time is computed it ends up being much higher than your target framerate. A trick to minimize the problem is to clamp the delta time to your target framerate when the debugger is attached thereby avoiding spikes in the delta time values.</p>
<p>At this point OS specific events are processed. In Windows terminology, this is where the events and messages are pumped and determine the keyboard and mouse state, window state, etc. Once that is done the engine can update the engine specific input data structures. Currently the last thing it does before world simulation is to update some engine subsystems like the online subsystem. On PC this is responsible for handling the Steam API so things like achievements get updated on the backend here.</p>
<h3 id="world-simulation">World Simulation</h3>
<p>At this part of the loop the engine will run all the systems that update world&rsquo;s state. From the pseudocode above, this is where <strong>SimulateFixedTimeStep</strong> runs. Its function is to any system that wants to be updated once per frame using a fixed delta time. This is where the physics engine gets updated. In Tempest, Physx is supported although at the time of this writing it is disabled since the game being developed with Tempest does not require it. In addition to the physics engine, any scriptable entity that implements their fixed time step simulation function will be updated here.</p>
<p>The next step of the world simulation is the <strong>Simulate</strong> function. This is probably what most people are most familiar with. The engine will iterate through all the systems that want to be updated at this point in the frame. For instance, the engine has a system that will iterate through all entities that have a transform component to update them before any other subsystem reads them. As you can tell these component systems have a update order since some systems will refer to values that other systems may modify. This is handled in the engine by assigning each component system to a specific update phase determined by a enum value. Then these components get sorted every frame based on that enunm value so we have a easy way of specifying the update order.</p>
<p>Another example of a system that runs here is the particle emitter update. It will go through all particle emitters in the scene and simulate them based on their configuration. Again, it will do this update using the job system in order to be performant considering some emitters can have hundreds of particles. Job system support is available for any and all component systems in the engine. For some it does not make much sense to use the job system since there may not be that many entities using those components and could actually be detrimental to the performance as there is a base cost to use the job system. You can see the multithreading in effect in the Tracy screenshot, specifically under the Update Game Data (High Priority) marker where it is updating all the transform components using every thread available.</p>
<h3 id="rendering">Rendering</h3>
<p>After simulating the world comes the rendering phase, in other words, the engine can start preparing all the data to submit to the GPU for rendering. The most important task that happens here is going through all the renderer components and assigning them to the correct set of render queues. Due to the flexibility of the renderer some things may opt to not render shadows or not render motion vectors. As such the engine keeps track of separate render queues for different features. This also lets the engine sort these render queues differently in ways that can potentially offer specific benefits for whatever render pass may use the queue. Since there can be a lot of models needing to be assigned to their queues each frame, this system emulates thread local arrays so each thread in the job system can have exclusive access to a region of memory and make it easy to add models to the render queue array. It is later in the frame that all these thread local arrays get merged into one array so it can easily be sorted and later used for rendering. Various component systems opt to not use thread synchronization primitives like mutexes for performance reasons but at the cost of more memory. With some profiling this architecture was proven to be faster than locking the critical section as it would be a resource with a lot of contention in a frame.</p>
<p>It wasn&rsquo;t mentioned but this is also where frustum culling would happen before assigning entities to their render queues. This is also done using the job system so multithreading is supported with the frustum culling system. However, it is disabled by default since the game will have most things visible on the screen at all times so performing frustum culling was a net negative for performance. That said it can be easily toggled on using the built in game console for submitting debug commands.</p>
<p>Now the engine can build its frame graph that can be compiled and executed right after. The execution can be done with multithreading which is what the renderer does. It uses a couple of threads from the job system to record all the command lists before submitting them to the GPU. The render passes that compose that frame graph are fairly easy to add to the engine. The complexity is determined by whether it is a render pass that will be rendering models or just a fullscreen pass or compute pass to be used for things like post process. The main complexity comes with creating pipeline state objects which can be a bit of a pain when the render pass supports all kinds of draw call state setup like depth testing, depth writing, and many more. At the moment the renderer uses an intermediate struct to represent the render state features a draw call will need and hashes them to create an integer value that can be looked up in a PSO map. If the map does not contain a PSO with that key then it knows it has to create a new one and then cache that afterwards. Here we do use a mutex to lock the modification of the map since this part is multithreaded.</p>
<p>After all the scene rendering is done, there is still one rendering task remaining for the editor. That task is rendering the editor&rsquo;s UI which in Tempest means rendering with Dear ImGui. Thankfully ImGui makes this really easy to do once you have the rendering backend integrated. In the case of Tempest this needed to be custom made as none of the provided ones were enough but offered good guidance on what needed to be done to make it work.</p>
<h3 id="end-of-frame">End Of Frame</h3>
<p>The very last thing to do is to present the frame. You may or may not have noticed that nothing was mentioned about the CPU working on the current frame while the renderer works on the previous frame&rsquo;s data. This is what most modern engines do but Tempest does not. It uses a more old school approach where the both the CPU and GPU are working on the same frame but with some modern ideas implemented as well. There may not be overlapping work done between adjacent frames but there are modern concepts sprinkled throughout the engine&rsquo;s architecture to balance things out. The job system is one such concepth. All of this helps to create a very fast frame on the CPU as you can see on the Tracy screenshot where the frame is done in about 5ms.</p>
<p>After that, if vSync is disabled then the engine will wait for a target framerate assuming the frame has not blown past that. It achieves that with a simple while loop but can decide to sleep the thread instead if there is more than 5ms before achieving the target framerate. Sleeping can help keep the CPU from heating up too much and also allows other external processes access to the CPU core the main thread will be on. A word of caution though, if you rely on sleeping a thread on Windows then know that the default resolution of periodic timers need to be configured in case you sleep a thread with a small value. The lowest supported resolution is 1ms which is what Tempest will set it to when the application starts. If you don&rsquo;t do this the thread will be awoken at a much later time than what you may specify.</p>
]]></content>
		</item>
		
		<item>
			<title>Tempest Gpu Frame</title>
			<link>https://yggdrasil-917.github.io/posts/tempest-gpu-frame/tempest-gpu-frame/</link>
			<pubDate>Sun, 21 Jul 2024 08:54:06 -0700</pubDate>
			
			<guid>https://yggdrasil-917.github.io/posts/tempest-gpu-frame/tempest-gpu-frame/</guid>
			<description><![CDATA[%!s(<nil>)]]></description>
			<content type="html"><![CDATA[<ul>
<li><a href="#shadows-phase">Shadows Phase</a></li>
<li><a href="#depth-phase">Depth Phase</a></li>
<li><a href="#prelighting-phase">PreLighting Phase</a></li>
<li><a href="#lighting-phase">Lighting Phase</a></li>
<li><a href="#imgui-phase">ImGui Phase</a></li>
<li><a href="#nvidia-nsight-preview">NVidia NSight Preview</a></li>
</ul>
<p><img src="/images/tempest-gpu-frame/TestScene.png" alt="Test Scene" title="Test Scene"></p>
<p>This post will go over one of the rendering test scenes and we&rsquo;ll see the steps the Tempest engine takes on the GPU to render a frame. The engine has its own editor separate from the player executable, which is what is shipped to people. The editor does pretty much the same thing the player does plus a few editor only rendering tasks so the scene we will analyze is actually running in the editor.</p>
<p>As mentioned in previous posts, the engine uses a deferred renderer with a gbuffer layout setup as shown in the screenshot below. The renderer uses several command lists and is broken up into several rendering phases. This can give opportunities to submit the command list once it is done recording on the CPU so we can keep the GPU fed over the course of the frame.</p>
<p><img src="/images/decals/GBufferLayout.png" alt="GBuffer Layout" title="GBuffer"></p>
<h2 id="shadows-phase">Shadows Phase</h2>
<p>This is the very first phase for the renderer. In this phase, we take care of rendering tasks that need to run as early as possible, for example, GPU skinning compute shaders run here to update vertex buffers before they are needed in subsequent passes. The main thing however, is rendering all the shadows needed for the frame. This means running cascade shadow maps pass and any local shadows required by the scene&rsquo;s local punctual light sources such as spot or point lights.</p>
<h3 id="cascade-shadow-maps">Cascade Shadow Maps</h3>
<p>CSM has a configurable number of cascades and caps out at a typical count of 4 cascades. If the renderer has to render more than one cascade then multithreading is used to record each cascade pass in its own command list. This means there are at most 4 command lists dedicated to rendering cascade shadows. Currently the architecture requires the first cascade to be rendered synchronously so as to make sure any required rendering resources such as PSOs are created and initialized before we can use multithreading to record the other cascades. This is not the most optimal solution but is simple and has worked well enough in practice. It is however, an area to improve in the future.</p>
<p>Different from a lot of other CSM algorithms, Tempest uses a technique based on <a href="https://www.intel.com/content/www/us/en/developer/articles/technical/sample-distribution-shadow-maps.html">Sample Distribution Shadow Maps</a>. Contrary to other techniques SDSM tries to automate the cascade configuration while trying to make the best out of the resolution of the individual cascade shadow map. It is a bit more involved to support as the camera&rsquo;s depth texture needs to be analyzed every frame and the result of that analysis read back to the cpu so it can generate the optimal partitioning for each cascade. This means that instead of worrying about stabilizing the cascades as the camera moves we can instead focus on making optimal use of the shadow map&rsquo;s resolution in such a way that we can get sub-pixel resolution when sampling said shadow map.</p>
<p>Tempest uses a texture 2D array to store each of the shadow map cascades. These days texture arrays are ubiquitous and I believe required for modern APIs. This simplifies setting up the rendering and sampling of shadow maps instead of using the age old trick of packing all cascades into one 2D texture. A preview of cascade 0 is below.</p>
<p><img src="/images/tempest-gpu-frame/Cascade0.png" alt="Cascade0" title="Shadow Cascade 0"></p>
<h3 id="local-shadows">Local Shadows</h3>
<p>Tempest supports directional, spot, and point light sources. Only one directional light source is supported though (sun or moon) and that will use the CSM method outlined previously. This limitation does not extend to the other supported light types which will instead use the local shadows system. This system will be stored in a 2D shadow map atlas whose resolution is determined by the user specified shadow quality setting. At its highest setting it will use a 4K resolution and goes all the way down to 1024x1024 in the lowest setting. In the editor the lights can specify what resolution to use for their shadow map or default to whatever the shadow quality setting will use. Lights can also specify the update frequency of their shadow map. This allows fully caching the shadow map from a light source to improve performance or we they can just render their shadow map every frame. These local shadows will only render if they can be stored in the shadow map atlas. If the atlas gets full while still having pending shadow map requests then it will just ignore those. Due to the limited space, the renderer will try to sort the shadow map requests based on distance to the camera rendering the scene so it tries to prioritize the shadow maps close by.</p>
<p>Unlike many other renderers, the point light shadow maps are not rendered into cube maps. Instead each face of the shadow cube map is rendered into the 2D shadow map atlas just like spot light shadow maps. This keeps the rendering code the same between the two light types and the only difference is in regards to sampling the shadow map. In the lighting pass, the shader needs to figure out what face to sample from in order to apply the correct shadow fragment. To do this it requires looking at the light&rsquo;s world space direction vector to figure out the cube map face. Each face has an id associated with it that the shader can then add to the light buffer&rsquo;s shadow index to get the correct shadow map. The renderer has a punctual light buffer that contains all the required data on a light source and also contains a shadow buffer for local light sources. The shadow buffer itself has all the needed information to sample the correct region in the shadow map atlas. The light buffer has a index into this shadow buffer so it can retrieve the shadow specific information for that light source. In the case of a point light, that index will point to the start of its shadow cube map, in other words, the positive X face of the cube map. It is useful to separate these two buffers since not all light sources will cast shadows so it makes sense to optimize memory usage.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-hlsl" data-lang="hlsl"><span class="line"><span class="cl"><span class="cp">#define CUBEMAPFACE_POSITIVE_X 0</span>
</span></span><span class="line"><span class="cl"><span class="cp">#define CUBEMAPFACE_NEGATIVE_X 1</span>
</span></span><span class="line"><span class="cl"><span class="cp">#define CUBEMAPFACE_POSITIVE_Y 2</span>
</span></span><span class="line"><span class="cl"><span class="cp">#define CUBEMAPFACE_NEGATIVE_Y 3</span>
</span></span><span class="line"><span class="cl"><span class="cp">#define CUBEMAPFACE_POSITIVE_Z 4</span>
</span></span><span class="line"><span class="cl"><span class="cp">#define CUBEMAPFACE_NEGATIVE_Z 5</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="kt">float</span> <span class="n">CubeMapFaceID</span><span class="p">(</span><span class="kt">float3</span> <span class="n">dir</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="kt">float</span> <span class="n">faceID</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="p">(</span><span class="nb">abs</span><span class="p">(</span><span class="n">dir</span><span class="p">.</span><span class="n">z</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="nb">abs</span><span class="p">(</span><span class="n">dir</span><span class="p">.</span><span class="n">x</span><span class="p">)</span> <span class="o">&amp;&amp;</span> <span class="nb">abs</span><span class="p">(</span><span class="n">dir</span><span class="p">.</span><span class="n">z</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="nb">abs</span><span class="p">(</span><span class="n">dir</span><span class="p">.</span><span class="n">y</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">    <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="n">faceID</span> <span class="o">=</span> <span class="p">(</span><span class="n">dir</span><span class="p">.</span><span class="n">z</span> <span class="o">&lt;</span> <span class="mf">0.0</span><span class="p">)</span> <span class="o">?</span> <span class="n">CUBEMAPFACE_NEGATIVE_Z</span> <span class="o">:</span> <span class="n">CUBEMAPFACE_POSITIVE_Z</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl">    <span class="k">else</span> <span class="k">if</span> <span class="p">(</span><span class="nb">abs</span><span class="p">(</span><span class="n">dir</span><span class="p">.</span><span class="n">y</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="nb">abs</span><span class="p">(</span><span class="n">dir</span><span class="p">.</span><span class="n">x</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">    <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="n">faceID</span> <span class="o">=</span> <span class="p">(</span><span class="n">dir</span><span class="p">.</span><span class="n">y</span> <span class="o">&lt;</span> <span class="mf">0.0</span><span class="p">)</span> <span class="o">?</span> <span class="n">CUBEMAPFACE_NEGATIVE_Y</span> <span class="o">:</span> <span class="n">CUBEMAPFACE_POSITIVE_Y</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl">    <span class="k">else</span>
</span></span><span class="line"><span class="cl">    <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="n">faceID</span> <span class="o">=</span> <span class="p">(</span><span class="n">dir</span><span class="p">.</span><span class="n">x</span> <span class="o">&lt;</span> <span class="mf">0.0</span><span class="p">)</span> <span class="o">?</span> <span class="n">CUBEMAPFACE_NEGATIVE_X</span> <span class="o">:</span> <span class="n">CUBEMAPFACE_POSITIVE_X</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">faceID</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span></code></pre></div><p>Now that all shadows have been recorded, the command lists for them get submitted to the graphics queue and we move on to the next phase.</p>
<h2 id="depth-phase">Depth Phase</h2>
<p>As the name suggests, this phase will render the scene&rsquo;s depth into a texture but will also do several other render passes that only depend on the depth texture. Examples of passes that run in this phase are ones like object velocities, a depth pyramid used for ray-marching, distortion maps, etc. I&rsquo;ll expand on some of them here.</p>
<h3 id="prepass">Prepass</h3>
<p>Some argue the usefulness of a depth prepass in a deferred renderer but at least in Tempest there is a performance benefit to it so the renderer will always do it. Tempest uses a inverted depth range so fragments close to the camera appear white and the farthest fragments will be black. This is done to improve the depth texture accuracy. The renderer also uses an infinite projection matrix so there is technically no far plane. In this pass the depth test is set to <strong>greatar than or equal</strong> (due to reversed depth) and samples the albedo texture and alpha clip for masked geometry. Other rendering passes will set the depth test to <strong>equal</strong> and do not have to explicitly handle masked geometry as the depth test will take care of discarding fragments that would normally be handled by alpha clipping. By doing this fragment shaders do not need to have a clip function to discard alpha clipped fragments and in doing so the hardware depth testing optimizations will very likely be turned on since it does not have to evaluate the fragment before doing the depth test like it does with alpha clipped or blended geometry.</p>
<p><img src="/images/tempest-gpu-frame/DepthTexture.png" alt="Depth Texture" title="Depth Texture"></p>
<p>This is also where the stencil values are populated. Each bit of the 8 bit stencil value is used for specific purposes. The big features this allows is creating projection channels for screen space decals so you can exclude some meshes from receiving specific decals and the other big one is lighting channels which does the same thing decal projection channels do but for lighting. One bit is used for excluding certain objects from specific rendering features and the last remaining bit is open for something in the future.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-hlsl" data-lang="hlsl"><span class="line"><span class="cl"><span class="c1">// Stencil layout during the decal and deferred lighting pass</span>
</span></span><span class="line"><span class="cl"><span class="c1">//     BIT ID | USE</span>
</span></span><span class="line"><span class="cl"><span class="c1">//     [0]    | custom bit(bit to be use by any rendering passes, but must be properly reset to 0 after using)</span>
</span></span><span class="line"><span class="cl"><span class="c1">//     [1]    | unused</span>
</span></span><span class="line"><span class="cl"><span class="c1">//     [2]    | Receive decals</span>
</span></span><span class="line"><span class="cl"><span class="c1">//     [3]    | Receive decals</span>
</span></span><span class="line"><span class="cl"><span class="c1">//     [4]    | Receive decals</span>
</span></span><span class="line"><span class="cl"><span class="c1">//     [5]    | Lighting channels</span>
</span></span><span class="line"><span class="cl"><span class="c1">//     [6]    | Lighting channels</span>
</span></span><span class="line"><span class="cl"><span class="c1">//     [7]    | Lighting channels</span>
</span></span></code></pre></div><h3 id="distortion-map-pass">Distortion Map Pass</h3>
<p>In this test scene there is a single distortion particle rendered around where the two spheres on the left are. This effect is done in multiple passes but first you have to create the distortion map itself. In essence what the distortion map is a fullscreen UV distortion effect. It creates it by rendering models and particles that contribute to the distortion into a fullscreen render target with a format of RG16F. It sets the blend mode to additive so any overlapping distortion models just add to the distortion strength. Most of the draw calls in this pass will rely on a normal map to create the distortion result.</p>
<p><img src="/images/tempest-gpu-frame/DistortionPass.png" alt="Distortion Pass" title="Distortion Pass"></p>
<p>As you can see from the screenshot, the particle is rendered behind geometry into the distortion map. The result is a properly depth tested particle that creates a distortion based on a shockwave normal map texture that you can see on the right side of the image. After all draw calls are done you end up with a fullscreen texture containing UV distortion offsets that will be applied at a later time in the frame.</p>
<h3 id="depth-moments">Depth Moments</h3>
<p>The last thing I&rsquo;ll point out here is the rendering passes to build a blurred depth moments pyramid. This is currently only used during the screen space global illumination pass. What this rendering pass will do is take the current scene depth texture rendered earlier in the frame and converts it to a depth moments texture with mips so that it can be linearly filtered later on when sampling the mip chain. This is more or less the same as what variance shadow maps do where a moment is a two channel texture with r = depth and g = depth*depth. This allows the shader to use Chebyshev&rsquo;s inequality to sample the depth moments texture and the fact it has mips can allow the shader to sample those during ray-marching for a performance boost.</p>
<h2 id="prelighting-phase">PreLighting Phase</h2>
<p>At this point the renderer can start building the data needed for lighting. Anyone familiar with a deferred renderer will know this to be the point where the gbuffer pass will be done. So this phase is essentially rendering the gbuffer, render passes that modify it, and any other rendering passes that contribute to the lighting.</p>
<h3 id="gbuffer">GBuffer</h3>
<p>This is where all the gbuffer data for the frame gets created. All the draw calls will set the depth test to <strong>equal</strong> with depth writes disabled and test against the depth texture generated in the previous phase. Not surprinsingly it uses MRT to output to 5 different render targets. The gbuffer layout image at the start of the article covers the 4 render targets that form the gbuffer data but there is a fifth render target that gets initialized to the emission. That dataset isn&rsquo;t explicitly stored in a gbuffer since there was no need to sample that data later on in the frame. As such it was decided to store that data in the render target that will contain the lighting of the frame and reduce memory usage that way.</p>
<p>Here&rsquo;s all the gbuffers rendered in the test scene, ordered in the same way as the gbuffer layout describes it to be.</p>
<p><img src="/images/tempest-gpu-frame/GBuffer.gif" alt="GBuffer" title="GBuffers"></p>
<p>After rendering the gbuffer we would normally render any decals but this test scene does not contain any so for more info on that you can look at the previous post about decals in Tempest.</p>
<h3 id="screen-space-ao">Screen Space AO</h3>
<p>So the gbuffer can store any material based AO that comes from a texture but that&rsquo;s often not enough. To complement that, Tempest has support for <a href="https://www.activision.com/cdn/research/Practical_Real_Time_Strategies_for_Accurate_Indirect_Occlusion_NEW%20VERSION_COLOR.pdf">Ground Truth AO</a>. At the time it was implemented it was the most modern SSAO implementation but these days it might be better to support something like <a href="https://ar5iv.labs.arxiv.org/html/2301.11376">this</a> instead. As the name implies this will create a fullscreen ambient occlusion texture that can then be combined with the gbuffer AO values to get very good AO results. The highest quality version of this technique will also output a fullscreen bent normals texture that will be used for GI sampling. For other quality settings it will instead use the world normal stored in the gbuffer.</p>
<h3 id="gbuffer-normals-blur">GBuffer Normals Blur</h3>
<p>The ground environment for the game being made with Tempest is made out of cubes. These cubes have very hard edges that for stylistic purposes I wanted the edges to look a little softer. One way to do that without explicitly modeling the geometry is to blur the gbuffer storing the normals. This is what is done in Tempest and the idea originally came from a game called <a href="https://www.teardowngame.com/">Teardown</a>. The developer of that game had done a youtube video interview at some point where he talked about different aspects of the renderer used in that game.</p>
<h2 id="lighting-phase">Lighting Phase</h2>
<p>Now the renderer can start putting together the lighting results for the frame. The first thing done in this phase is the deferred lighting pass which is done in a compute shader. This pass will use all the gbuffers, shadow maps, SSAO, and the irradiance map for the sky. So the deferred lighting applies direct lighting and the skylight but there is still more to do with the lighting. Here&rsquo;s what the scene looks like after applying deferred lighting.</p>
<p><img src="/images/tempest-gpu-frame/DeferredLit.png" alt="Deferred Lighting" title="Deferred Lighting"></p>
<h3 id="sky">Sky</h3>
<p>Atmospheric scattering and physically based sky is computed and applied after deferred lighting. The sky is based on <a href="https://github.com/sebh/UnrealEngineSkyAtmosphere">Hillaire&rsquo;s sky</a> which is the same solution in Unreal Engine but with more bells and whistles. That technique is the best one I&rsquo;ve seen yet for both performance and the quality you get from it. To apply the sky to the scene lighting, a fullscreen triangle is used instead of a cube or sphere like many other solutions do. The trick is to render the fullscreen triangle at the far plane and enable depth testing. After that it&rsquo;s just a little bit of math to compute ray-marching parameters.</p>
<p>That said the sky component in the engine also supports using a HDRI for the sky or go more stylized and create a sky based on a color gradient.</p>
<h3 id="ssr-and-ssgi">SSR and SSGI</h3>
<p>If SSR or SSGI is enabled, a mip chain is created from the current lit scene color where each mip is blurred. These mips are sampled based on material properties such as roughness where the higher the roughness the higher the mip is used. There&rsquo;s nothing special about the SSR implementation but the SSGI implementation is somewhat different from others. It is based on <a href="https://github.com/Raikiri/LegitEngine">SSVGI</a> which comes from one of the senior programmers that works on Path of Exile. This implementation stood out to me as it is not one that is requiring a temporal solution to look good and I&rsquo;ve been favoring techniques that do not rely on temporal filters to look good or run performantly.</p>
<p>And this is what the scene looks like after applying the remaining GI to the lighting results.</p>
<p><img src="/images/tempest-gpu-frame/DeferredLit2.png" alt="Lit with GI" title="Deferred Lit + GI"></p>
<h3 id="volumetric-fog">Volumetric Fog</h3>
<p>This is the only effect in this frame that is allowed to have a temporal filter as it is quite important for performance. Nothing unique here as if you&rsquo;ve seen one implementation then you&rsquo;ve seen most. Only thing I&rsquo;ll mention here is that the volumetric fog has support for rendering particles that will contribute to the fog&rsquo;s density. This creates localized fog effects using the particle system in the engine. It is a very nice effect but can get expensive very fast as the particles need to be rasterized multiple times based on how big they are.</p>
<h3 id="grid-floor-and-icons-editoronly">Grid Floor and Icons (EditorOnly)</h3>
<p>The grid floor most people are familiar with gets rendered with no depth testing so it is easy to see and any entity icons for light sources or other entities is also rendered. The engine can also toggle rendering these things and make it look like how it does in the game view.</p>
<h3 id="transparency">Transparency</h3>
<p>Due to Tempest using a deferred renderer, transparency needs to have its own solution. There is support for dithered transparency which does allow rendering those models in the deferred renderer but the visual quality can be unacceptable. Other techniques like depth peeling are more expensive than they are worth so Tempest does what most other engines do in this scenario and just render transparency using a forward renderer. As of now it only supports lighting with the directional light source as local lights support has not been needed yet. Unlit transparent models get rendered right after the lit transparents do and this includes particle effects.</p>
<p>One other transparency solution used is order independent transparency via <a href="https://cg.ivd.kit.edu/english/mboit.php">Moment-based OIT</a>. This is sparingly used however, as it is a multi-pass technique so it can get expensive rather quickly. Only unlit models are supported as of now and can be seen in the test scene as the left-most trio of cubes are rendered using this method.</p>
<h3 id="fullscreen-passes">Fullscreen Passes</h3>
<p>Now that all geometry has been rendered, the only thing left are all the fullscreen rendering passes like SMAA and any other post process effect (bloom, exposure, etc.).</p>
<p><img src="/images/tempest-gpu-frame/FinalLit.png" alt="Final Lit" title="Final Lit"></p>
<h3 id="in-game-ui">In-game UI</h3>
<p>The in-game UI solves the age old problem of rendering many quads in a efficient manner. All the UI elements use the same shader and rely on a texture atlas big enough to store all the UI textures. Every frame a vertex buffer is built based on what is visible on screen at that time. Due to the UI system using the same vertex buffer for everything and using the same material means that it can all be rendered in one draw call. One cool thing with the UI is that we can reuse the bloom texture and blend with a UI element to create that frosted glass look for free essentially. This effect is visible on the UI menu.</p>
<p><img src="/images/tempest-gpu-frame/FinalLitUI.png" alt="Final Lit UI" title="Final Lit UI"></p>
<h2 id="imgui-phase">ImGui Phase</h2>
<p>This phase will only run in the editor. After the scene rendering is done, the editor will render all the UI elements for the editor. The texture containing the scene lighting will also get rendered as a ImGui image. The aspect ratio of that scene rendering is optionally preserved so the user can choose to have the image take up all available space or just enough to maintain its aspect ratio.</p>
<p>All of this and more things that I didn&rsquo;t mention was able to be done in a laptop using a NVidia 2060 rendering the scene at 1440p while the editor rendered on a ultra wide screen monitor and it took around 19 milliseconds. The bottleneck being heavily skewed towards all the fullscreen effects like SSR and SSGI. That said a 2060 isn&rsquo;t really suited to render a PBR frame at 1440p 60 frames per second. All things considered I&rsquo;m especially happy with the performance considering there are still things to do to optimize the engine that will eventually be done.</p>
<h2 id="nvidia-nsight-preview">NVidia NSight Preview</h2>
<p>I&rsquo;ll briefly preview what a GPU trace of the same scene running in the player looks like. I intend on making a post on performance and profiling which is where I will go into more details. For now I just want to show what an external tool like NVidia&rsquo;s NSight has to say about the renderer. I suggest opening the image in a new tab so you can see more details. I&rsquo;ll reiterate that this is running on a laptop with a 2060 GPU and rendering the scene at 2560x1440 with a target framerate of 60Hz. As the image shows though, the frame took a little over 17ms to render which means dynamic resolution would kick in had it not been disabled for the capture. That said most of the rendering passes are configured to use their highest quality and there is room for improvement too but that&rsquo;s a problem for a later time.</p>
<p><img src="/images/tempest-gpu-frame/NSightGpuTrace.png" alt="NSight GPU Trace" title="NSight GPU Trace"></p>
<p>One important take away from the capture is that the GPU is always active throughout the frame as you can see from the <strong>GPU Active</strong> counter. That tends to rule out the renderer doing anything obviously bad for performance. Another cool thing is that you can see the red boxes at the top middle of the image regarding the <strong>GPU context</strong> tracker. Those red boxes denote external processes running on the machine that interrupts your application. Those interruptions will inflate your application&rsquo;s framerate and knowing that happened in a capture will let you understand potential performance spikes in the frame. Loads of other useful info on the capture but that might be covered at a future time.</p>
]]></content>
		</item>
		
		<item>
			<title>Decals</title>
			<link>https://yggdrasil-917.github.io/posts/decals/decals/</link>
			<pubDate>Mon, 15 Jul 2024 18:11:49 -0700</pubDate>
			
			<guid>https://yggdrasil-917.github.io/posts/decals/decals/</guid>
			<description><![CDATA[%!s(<nil>)]]></description>
			<content type="html"><![CDATA[<ul>
<li><a href="#tempest-gbuffer">Tempest GBuffer</a></li>
<li><a href="#how-they-work">How They Work</a></li>
<li><a href="#sampling-stencil">Sampling Stencil</a></li>
<li><a href="#sort-order">Sort Order</a></li>
<li><a href="#batch-rendering">Batch Rendering</a></li>
<li><a href="#gbuffer-modifications">GBuffer Modidfication</a></li>
<li><a href="#unique-applications">Unique Applications</a></li>
<li><a href="#performance">Performance</a></li>
</ul>
<p>There are a couple of different ways to implement decals, each with their pros and cons. For this post I&rsquo;ll go over how Tempest implements screen space deferred decals to modify the gbuffer in various ways. Decals tend to offer very easy ways to modify the scene while keeping shader complexity at a manageable level but at the cost of additional draw calls to render the decals.</p>
<h2 id="tempest-gbuffer">Tempest GBuffer</h2>
<p>Before going into details about the decal implementation, it is worth going over some of the details of Tempest&rsquo;s gbuffer layout.</p>
<p><img src="/images/decals/GBufferLayout.png" alt="GBuffer Layout"></p>
<p>There is also one additional render target that isn&rsquo;t technically part of the gbuffer but still very important to the final render. That is emission and GI which is stored in the render target that stores the final scene lighting. The first gbuffer layout did have a dedicated gbuffer to store emission but there were never any situations where sampling just the emissive was needed. That meant it was better to simply store emission and GI in the scene color render target instead, saving one entire render target&rsquo;s worth of memory. That said the emissive render target used a floating point format as that was needed to reduce banding.</p>
<p>For anyone familiar with other gbuffer layouts, this shouldn&rsquo;t come as any surprise as it is very similar to a lot of other layouts out there so I&rsquo;ll only call out a few details about it. The gbuffer normals are stored in a two component render target. This is done by converting a typical world normal unit vector to a <a href="https://jcgt.org/published/0003/02/01/">octahedron encoding</a>. There are very fast ways to encode and decode using this method that it allowed the usage of a render target format that has a smaller bandwidth than other formats without encoding. This is one area where I feel like every deferred renderer solves the storage of normal vectors differently. For instance, another popular solution is to use no encoding and have a render target format of RGB10A2 so it adds up to 32 bits per fragment, the same as the format Tempest uses for world normals. I found that using octahedron encoding and 16 bits per channel yielded slightly better results than the latter option but again the differences are minimal. The other thing to expand upon is what exactly is stored in the last gbuffer render target. The alpha channel of GBuffer2 stores the id of what BRDF is to be used for that fragment during lighting and GBuffer3 stores any data needed to accomplish that. One example of data stored in GBuffer3 is subsurface color and its intensity used for foliage lighting.</p>
<h2 id="how-they-work">How They Work</h2>
<p>These decals modify gbuffer content and as such they are rendered right after the gbuffer pass is done. All the decals use the same underlying mesh, a unit cube centered around the origin. The depth test and depth writing is turned off when drawing a decal. This is largely done as the shader needs to sample the depth texture and the stencil values. Unfortunately it isn&rsquo;t possible to bind the depth texture in read only mode and sample it in the shader as otherwise the DirectX debug layer screams at you. You can of course copy the depth texture and get around it that way but there aren&rsquo;t enough reasons to copy the depth texture at the moment so it isn&rsquo;t worth paying the performance cost to copy the depth texture. The last render state to configure before drawing the decal is the blend mode to use. What blend mode to use depends on what type of information is being modified and will discussed in more detail later in this post.</p>
<p>With drawing a cube to represent the volume of the decal we also need to somehow carve out the correct shape of the decal based on the geometry the decal is projecting onto. Luckily we can do that with the depth texture and a little bit of math. We can compute the fragment&rsquo;s world position using the depth texture and then we can transform that to the decal&rsquo;s local space. Once we have that we can do a simple box bounds check to determine if the fragment is actually part of the decal or not.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-hlsl" data-lang="hlsl"><span class="line"><span class="cl"><span class="c1">// Bounds check in decal&#39;s local space to discard fragments that</span>
</span></span><span class="line"><span class="cl"><span class="c1">// are not part of the decal. This is where the fact we use a</span>
</span></span><span class="line"><span class="cl"><span class="c1">// unit cube for the volume comes into play.</span>
</span></span><span class="line"><span class="cl"><span class="nb">clip</span><span class="p">(</span><span class="mf">0.5</span> <span class="o">-</span> <span class="nb">abs</span><span class="p">(</span><span class="n">decalPosOS</span><span class="p">));</span>
</span></span></code></pre></div><p>At this point we have the decal&rsquo;s shape and we can now compute the texture coordinates using the decal position in object space so we can sample any textures the decal will use.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-hlsl" data-lang="hlsl"><span class="line"><span class="cl"><span class="c1">// decalPosOS is in the [-0.5, 0.5] range so remap it to [0, 1] and then we can do the usual </span>
</span></span><span class="line"><span class="cl"><span class="c1">// UV scale and offset transform for any sort of tiling support.</span>
</span></span><span class="line"><span class="cl"><span class="kt">float2</span> <span class="n">decalUV</span> <span class="o">=</span> <span class="p">(</span><span class="n">decalPosOS</span><span class="p">.</span><span class="n">xz</span> <span class="o">+</span> <span class="mf">0.5</span><span class="p">)</span> <span class="o">*</span> <span class="n">g_Material</span><span class="p">.</span><span class="n">scaleAndOffset</span><span class="p">.</span><span class="n">xy</span> <span class="o">+</span> <span class="n">g_Material</span><span class="p">.</span><span class="n">scaleAndOffset</span><span class="p">.</span><span class="n">zw</span><span class="p">;</span>
</span></span></code></pre></div><h2 id="sampling-stencil">Sampling Stencil</h2>
<p>It&rsquo;s pretty rare to find any information about sampling the depth texture and getting the stencil value from it. Most of the time you will have the hardware do the stencil test so you don&rsquo;t have to worry about handling the stencil values directly but there are times where you have to. This is one such time as we are not doing depth testing when rendering the decal for reasons outlined previously. In order to do this we have to properly setup the shader resource view for the depth texture so that we can access the stencil value. Tempest uses a <strong>D24S8</strong> format and that means we need to use <strong>DXGI_FORMAT_X24_TYPELESS_G8_UINT</strong> when setting up the resource view. Then we can sample the depth texture like the sample below in order to get the stencil value for any given fragment.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-hlsl" data-lang="hlsl"><span class="line"><span class="cl"><span class="kt">Texture2D</span><span class="o">&lt;</span><span class="kt">uint2</span><span class="o">&gt;</span> <span class="n">SceneStencil</span> <span class="o">:</span> <span class="k">register</span><span class="p">(...);</span>
</span></span><span class="line"><span class="cl"><span class="c1">// Check if we can project on this fragment based on the stencil value</span>
</span></span><span class="line"><span class="cl"><span class="p">{</span>
</span></span><span class="line"><span class="cl">  <span class="k">const</span> <span class="kt">uint</span> <span class="n">projectionMask</span> <span class="o">=</span> <span class="p">(</span><span class="kt">uint</span><span class="p">)</span><span class="n">g_Material</span><span class="p">.</span><span class="n">buffer</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="n">y</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">  <span class="k">const</span> <span class="kt">uint</span> <span class="n">receiveDecal</span> <span class="o">=</span> <span class="p">(</span><span class="n">SceneStencil</span><span class="p">.</span><span class="n">Load</span><span class="p">(</span><span class="kt">uint3</span><span class="p">(</span><span class="n">i</span><span class="p">.</span><span class="n">screenPos</span><span class="p">.</span><span class="n">xy</span><span class="p">,</span> <span class="mo">0</span><span class="p">)).</span><span class="n">y</span> <span class="o">&gt;&gt;</span> <span class="n">STENCIL_RECEIVE_DECALS_BIT</span><span class="p">)</span> <span class="o">&amp;</span> <span class="mh">0x7</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">  <span class="k">if</span> <span class="p">((</span><span class="n">projectionMask</span> <span class="o">&amp;</span> <span class="n">receiveDecal</span><span class="p">)</span> <span class="o">==</span> <span class="mo">0</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="nb">clip</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">);</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span></code></pre></div><p>With the ability to sample the stencil value in the shader we can now exclude specific models from receiving decals. There are times where we may have moving models that intersect the decal volume but we don&rsquo;t want them to receive any of the decal projection. The way Tempest handles this is to use 3 bits from the stencil buffer to create decal channels. With 3 bits we have 3 channels to use and with a little bit manipulation we can check for overlapping channels and decide if a fragment receives the decal being projected.</p>
<h2 id="sort-order">Sort Order</h2>
<p>If you have mutiple overlapping decals, the renderer should have a way to determine the blend order. How this is achieved is sort of engine specific but there&rsquo;s often some underlying sorting system for generating the order of draw calls. Then using a sort bias you can change the priority of how the decal is rendered. Without getting into details as that topic is out of scope for this post, this is what Tempest ends up doing. It has support for generating a sort key based on various parameters like material id, distance from camera, etc. The decals have a sort order they can modify in the decal component that will modify the generated sort key value and in effect changes the sorting results. The higher the sort order value the later the decal is rendered so it renders on top of others.</p>
<p>In the image below, there are two overlapping decals. On the left half both have the same sort order and on the right half the red tinted decal has a higher sort order so it gets rendered on top of the other decal.</p>
<p><img src="/images/decals/DecalOverlapMerged.png" alt="Sort Order"></p>
<h2 id="batch-rendering">Batch Rendering</h2>
<p>It is very easy to get into a situation where you have a lot of decals being rendered and while each individual decal is fast to render it adds up quickly. Tempest has a batch rendering solution used by most draw calls except in a few specific cases. The decal implementation automatically supported this feature however, there needed to be a handful of extensions made to this system in order to support all the desired decal features. For example, using the sort order mentioned above can break batching but the flexibility it provides outweighs the costs. Changing what channels a decal projects to can also break batching. Otherwise, if those settings are the same between decals using the same material then it will be instanced.</p>
<h2 id="gbuffer-modifications">GBuffer Modifications</h2>
<p>The decal&rsquo;s shader can modify any property of the gbuffer in its draw call. All gbuffer render targets are bound during the decal&rsquo;s draw call instead of binding only the render targets that will be modified. The reason being to keep the code simple, low shader permuation count, and only worry about performance if it actually becomes a problem. The game&rsquo;s performance will determine this but I suspect the performance problems will lie elsewhere. All render targets have the typical transparency blend mode except for the emission output which uses an additive one and AO decals use a multiplicative blend mode.</p>
<p>Here is an example of a decal that changes the emissive values. As a bonus, Tempest supports a screen space global illumination pass which ends up picking up the emission changes from the decal and creates bounced lighting on the wall.</p>
<p><img src="/images/decals/DecalEmissive.png" alt="Decal Emissive"></p>
<p>Here is another example that blends the normal stored in the gbuffer normal. This one however, isn&rsquo;t entirely accurate as the blending is being done between encoded values when it should be done with the decoded values before encoding back to the octahedron format. That would require copying the gbuffer normals into another texture and just isn&rsquo;t worth it. The blending strength can be adjusted until you get something good enough and so far has worked well enough. This is something worth revisiting in the future, especially if a different format for normals is chosen.</p>
<p><img src="/images/decals/DecalNormal.png" alt="Decal Normal"></p>
<h2 id="unique-applications">Unique Applications</h2>
<p>It is worth pointing out that this decal system can be extended beyond the typical decal and handle some more unique problems. One such example is a cheap omni light source without actually using a point light and going through the PBR pipeline. It&rsquo;s not a one to one replacement to an actual light source but is more than suitable for what is typically referred to as a fill light or even small light sources like a building&rsquo;s exit sign. These decals do just about everything the typical decal does however you do not have to do the local space box bounds check to create the decal shape. In the case of the omni light you can use a circle gradient function that is tinted by a user specified color and intensity. The size of it is determined by the size of the decal itself and a few other parameters. The result is then added to the emission values.</p>
<p>Here is an example of an omni light that is tinted red.</p>
<p><img src="/images/decals/DecalOmniLight.png" alt="Decal OmniLight"></p>
<p>You can apply essentially the same ideas as the omni light decal but for ambient occlusion stored in the gbuffer. Using the same circle gradient function you can modulate the AO but you must make sure to have a blend mode that modulates the results for this to work. Below is a screenshot of this in action where the cube outline denotes the decal&rsquo;s volume so anything inside will have its AO modulated as can be seen around the storm trooper&rsquo;s legs.</p>
<p><img src="/images/decals/DecalAO.png" alt="Decal AO"></p>
<p>Since this is only modifying the AO stored in the gbuffer, this technique works without issues with screen space ambient occlusion.</p>
<h2 id="performance">Performance</h2>
<p>Performance for screen space decals will be determined by the complexity of the shader and how big the decal volume is. Overlapping decals will have a negative effect to overall performance as you are re-evaluating fragments. That said decals can be rendered very fast and making good use of the batching system also helps a lot. Some benchmarks done with RenderDoc have shown the decals in Tempest to take around 10 - 20 microseconds for each decal draw call so it&rsquo;s pretty fast. The omni light and AO decals will be a bit more expensive but not by much if there size is comparable to other decals.</p>
]]></content>
		</item>
		
		<item>
			<title>Scripting With Cpp</title>
			<link>https://yggdrasil-917.github.io/posts/scripting-with-cpp/scripting-with-cpp/</link>
			<pubDate>Wed, 03 Jul 2024 11:57:54 -0700</pubDate>
			
			<guid>https://yggdrasil-917.github.io/posts/scripting-with-cpp/scripting-with-cpp/</guid>
			<description><![CDATA[%!s(<nil>)]]></description>
			<content type="html"><![CDATA[<p>Early on in Tempest&rsquo;s development it was decided not to adopt a scripting language and instead use c++, the same language used to make the engine. This more or less goes against the norm these days seeing as how most engines have a scripting language. In fact, you can probably count the number of professional engines that only offer c++ for scripting in one hand. Unreal Engine being by far the most popular one in that category. There are some smaller engines like <a href="https://flaxengine.com/">Flax</a> that offers c++ or c# for scripting otherwise, you&rsquo;re likely using something other than c++ for your scripting needs.</p>
<p>I&rsquo;ve been asked several times in the past what scripting language I decided to adopt for Tempest and people are usually surprised at the fact that I stuck with c++. So I&rsquo;ll use this post to go over the reasons why, however, I can&rsquo;t stress enough that all decisions have pros and cons. This is no different. That said I can live with the cons for the kinds of games I&rsquo;m trying to make with Tempest.</p>
<h2 id="deciding-on-cpp">Deciding On Cpp</h2>
<p>So how did I go about deciding on c++? There&rsquo;s actually a lot of things I did before making my decision and I&rsquo;ll cover some of them here. The very first thing I did was to take a look at the current state of the game scripting language landscape. The engine I made before Tempest was a long time ago and for that I had decided to use Lua as the scripting language. One of the main reasons was to get first hand knowledge on setting up a scripting language in a custom engine and at the time Lua seemed pretty popular for this. Fast forward to present time and the scripting language ecosystem hasn&rsquo;t really changed all that much since the last time I looked into this. The popular scripting languages still seemed to be the same as they were back then. Mostly c#, lua, and python. I&rsquo;m ignoring languages like GDScript as that is tied to Godot but I do recognize that one has gained a lot of popularity as Godot has gotten more popular. That said I&rsquo;ve added below a few thoughts I had when evaluating each of those languages.</p>
<ul>
<li><strong>c#</strong> - Unity made this super popular for game scripting and there is a large community out there with loads of third party libraries for anything you may need. Unity however, has done many custom things to make c# useful for game development. Things that would not be available to my custom engine and thus makes it a tougher sell to adopt c#. I was close to deciding to bite the bullet and add support for it in Tempest but looking at Mono quickly removed any desire to use it so I didn&rsquo;t.</li>
<li><strong>lua</strong> - Another very popular option touted to be lightweight and easy to integrate. I can definitely vouch for it being easy to integrate into a custom c++ engine. It is dynamically typed though and that is something I&rsquo;m not really willing to deal with unless work makes me. Dynamic typing makes it so easy to hide bugs that I just prefer not rely too much on systems like that. The community has gotten bigger but it still seems to lag behind the other two languages I&rsquo;m mentioning here. This also means there are less libraries to be found than in c# or python so it&rsquo;s possible you may have to do more things yourself.</li>
<li><strong>python</strong> - Similar enough to lua but again dynamically typed so I want to stay away from it. Has a lot of libraries and large community. Performance though is a serious issue as it is very easy to write code that looks performant but due to how the language works it ends up being a hard to detect performance bottleneck. Some of that will be mitigated with experience using the language but it is still a tough sell.</li>
</ul>
<p>Another thing I don&rsquo;t see mentioned often with regards to scripting languages is debugging your scripts in your favorite IDE. In many cases, you may need to write a custom plugin to enable breakpoints inside your chosen scripting language and that&rsquo;s if it is even possible to do that. I know it is fairly new but Unreal Verse does not support breakpoints right now and instead expects developers to use print statements for their debugging. For some of the bigger game engine developers, it&rsquo;s common for them to provide their own IDE plugins to enable things like breakpoints for example. This is sort of a hidden cost to adopting a scripting language whereas, sticking with c++ you already have all of that in working condition.</p>
<p>Memory management is another key thing to consider. A lot of scripting languages may have garbage collection or rely on ARC whereas, c/c++ works very differently by default but can be extended to have things like GC (see Unreal Engine). In the case of c#, you have to think about managed memory and if you have to cross the boundary between managed and unmanaged then things can start getting a bit annoying to deal with the requirements that can have. Not to mention crossing language boundaries can be annoying as well. I&rsquo;m picking a little on c# here but crossing language boundaries can be defficult in other scripting languages.</p>
<p>Developing and maintaining a powerful scripting API for your game dev needs is a ton of work. It&rsquo;s not uncommon to duplicate work already done in native. For instance, a math library built to meet your game development needs is likely going to be required in your scripting API but you likely already have that built in your native language or are using a third party library for that. All of a sudden you need support for vectors, matrices, RNG, and the list goes on and on. You might think that it&rsquo;s a good idea to just build a wrapper API in your scripting language that simply calls native functions all the time but you will learn it isn&rsquo;t a good idea as crossing language barriers has non-negligible cost that quickly adds up to become a performance issue. This then brings up the age old question of what exactly should be exposed at an API level to the scripting language. It&rsquo;s not always clear how to handle this and is something that should be asked anytime more things are added to your scripting layer. This becomes a bigger problem as a solo developer since extending the scripting layer also means a larger codebase to maintain. This is also a problem that much larger engines run into as well. I&rsquo;ve run into so many situations using Unreal where certain functions don&rsquo;t exists in blueprint but are there in c++ or a variant of a function I need is in blueprint but not the correct variant. If you&rsquo;re working from source then it is likely easy to add support for it but otherwise you&rsquo;re stuck with that limitation and creates tons of frustrations.</p>
<p>Now lets talk about performance for a bit. This is one major sticking point with scripting languages in general. The argument being that scripting languages exist for their ease of use and not for their performance. On the one hand, I&rsquo;m glad the simplicity of these scripting languages has made it possible for more people to contribute to gameplay, editor tools, etc. On the other hand, I&rsquo;ve had one too many situations throughout my career where I had to convert scripts into c++ in order to improve performance and be able to ship features. While this isn&rsquo;t the norm, it does happen often enough that sometimes it makes me question the usefulness of scripting languages. This also applies to node based scripting tools like blueprint. The nodes can often be a little too high level to the point where developers don&rsquo;t even think about what a node may actually be doing behind the scenes and just assume it is a fast operation. Oh and if the node graph is complex enough that the original author can&rsquo;t even debug it when problems occur then you can bet that&rsquo;s going to be redone in c++.</p>
<p>One huge thing I do miss about using c++ for scripting has to do with hot reloading. C++ has always been difficult on that front. Tons of solutions developed over the years but none of them seem to be very reliable or even working these days. Even the live coding feature in Unreal is very finicky. There are many situations where hot reloading can&rsquo;t work in the language. For most part you&rsquo;re only able to change data values and only in your cpp files as header changes are out of the question. This is something scripting languages usually excel at. I say usually since for several years now hot reloading c# code in Unity has been inconsistent to say the least. The main issue they&rsquo;ve had for a while now is that reloading their c# domain can take a very long time and sometimes after it has finished you may run into issues with your scripts. Point being that just adopting a scripting language doesn&rsquo;t automatically make hot reloading easy or useful. I&rsquo;m secretly hoping that c++ modules might be able to make things better but so far I haven&rsquo;t seen much work done on that front so it remains to be seen if this might be the way forward for hot reloading c++ code. It&rsquo;s also worth mentioning that VS 2022 brought a hot reloading feature to c++ and I was delighted that it worked once upon a time but as my project has gotten much bigger that feature stopped working.</p>
<p>I haven&rsquo;t talked about compilation yet. C++ is obviously a compiled language and as such will also generate machine code that in theory is also optimal for the platform it is running on. This does mean that it needs to be compiled and linked before it can be used whereas some scripting languages are interpreted so no compilation or linking is needed. This  means faster iteration times which in game development is very important. C++ can be slow to compile if you&rsquo;re careless with how you structure the codebase. This is something you need to be on top of throughout development so you don&rsquo;t fall into the trap of including all sorts of headers everywhere in your codebase and then realize your compile times are horrible because of that. This is pretty much what happend to Unreal Engine 4 early on before somebody had the unfortunate task of cleaning up header includes througout the engine and coming up with better coding practices to minimize that issue moving forward.</p>
<p>I&rsquo;ve rambled on a bit too long and I haven&rsquo;t mentioned all the things I considered but hopefully this gets the point across as to how I went about deciding on c++ for everything in my engine. This post will maybe come across as a bit harsh on scripting languages but I do see their benefit in the industry despite my opinions. However, I&rsquo;m not trying to make a competitor to any of the popular game engines out there so I feel no need to emulate every single thing they do and instead I&rsquo;d rather do my own thing. At the end of the day that&rsquo;s sort of the point of making a custom game engine isn&rsquo;t it?</p>
]]></content>
		</item>
		
		<item>
			<title>Crash Reporting</title>
			<link>https://yggdrasil-917.github.io/posts/crash-reporting/crash-reporting/</link>
			<pubDate>Sun, 30 Jun 2024 10:21:04 -0700</pubDate>
			
			<guid>https://yggdrasil-917.github.io/posts/crash-reporting/crash-reporting/</guid>
			<description><![CDATA[%!s(<nil>)]]></description>
			<content type="html"><![CDATA[<ul>
<li><a href="#supporting-minidumps">Supporting Minidumps</a></li>
<li><a href="#crash-report">Crash Report</a></li>
<li><a href="#win32-ui">Win32 UI</a></li>
<li><a href="#trigger-crash-reporter">Trigger Crash Reporter</a></li>
<li><a href="#where-reports-live">Where Reports Live</a></li>
</ul>
<p>If you&rsquo;ve ever had to debug a fatal exception then you likely know how hard it can be to fix those issues when you only have the steps to reproduce the problem and sometimes you don&rsquo;t even have that. These days a lot of things can contribute to a crash and it&rsquo;s important to get as much information as you can. Hardware information is always very useful to have. Things like cpu and gpu models, how much RAM the system has, etc. Gathering hardware information can sometimes shed a light on problems specific to a piece of hardware or driver version. It would be great if there was an automated way to collect this information, among other things, and store it somewhere developers can look at the data to do some debugging on their end.</p>
<p>This is pretty much what all popular engines do. Unity and Unreal for example, have a separate application to handle crash reporting on their editors as well as any games made with those engines. The engine will make sure to launch their crash reporter whenever a fatal exception has occured. This application is very straightforward to use and it&rsquo;s responsibilties boil down to automatically bundling a minidump, most recent log file, and other data so that it can send it off to a server. The crash reporter also lets the user type some additional information to attach to the report. Things like what user was doing when the crash occured and anything else they may want to add. This is the approach the Tempest crash reporter takes. A screenshot below shows what the Tempest crash reporter looks like in all its Win32 glory. Looks sort of ugly but gets the job done.</p>
<p><img src="/images/crash-reporting/CrashReporter.png" alt="Crash Reporter"></p>
<h2 id="supporting-minidumps">Supporting Minidumps</h2>
<p>If you aren&rsquo;t aware what application minidumps are then I will briefly mention what they are. In short, the minidump is a file that contains various useful information for debugging at a later point in time. Information such as call stack at the time of the fatal exception, local variables, loaded modules, and will also point to the source code line that triggered the exception. Needless to say, this is going to be the most important file to have from a crash report. However, these files do not get created automatically and the c++ project needs to be configured properly for them to be useful. Using Visual Studio 2022 as the IDE of choice, what you need to configure is in your C/C++ general section, set <strong>Debug Information Format</strong> to <strong>Program Database</strong> and then make sure that in your linker debugging section&rsquo;s <strong>Generate Debug Info</strong> is set to <strong>Generate Debug Information</strong>. This should make your release or shipping builds generate debug symbols in a PDB file. It is also good practice to save these PDB files when you make a new build so you can easily use the correct PDB file when loading up the minidump in VS or your debugger of choice.</p>
<p>The next thing required is to create the minidump file when the fatal exception is being handled. There are many articles out there that describe how to do this. It isn&rsquo;t a lot of code so I&rsquo;ll post below what Tempest does so you can see for yourself.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-cpp" data-lang="cpp"><span class="line"><span class="cl"><span class="c1">// After this runs a minidump file is created at the location
</span></span></span><span class="line"><span class="cl"><span class="c1">// specified by the filepath variable.
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="k">static</span> <span class="kt">void</span> <span class="nf">CreateMinidump</span><span class="p">(</span><span class="k">struct</span> <span class="nc">_EXCEPTION_POINTERS</span><span class="o">*</span> <span class="n">apExceptionInfo</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="p">{</span>
</span></span><span class="line"><span class="cl">  <span class="n">HMODULE</span> <span class="n">mhLib</span> <span class="o">=</span> <span class="o">::</span><span class="n">LoadLibrary</span><span class="p">(</span><span class="n">_T</span><span class="p">(</span><span class="s">&#34;dbghelp.dll&#34;</span><span class="p">));</span>
</span></span><span class="line"><span class="cl">  <span class="n">MINIDUMPWRITEDUMP</span> <span class="n">pDump</span> <span class="o">=</span> <span class="p">(</span><span class="n">MINIDUMPWRITEDUMP</span><span class="p">)</span><span class="o">::</span><span class="n">GetProcAddress</span><span class="p">(</span><span class="n">mhLib</span><span class="p">,</span> <span class="s">&#34;MiniDumpWriteDump&#34;</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">  
</span></span><span class="line"><span class="cl">  <span class="kt">char</span> <span class="n">filepath</span><span class="p">[</span><span class="n">MAX_PATH</span> <span class="o">+</span> <span class="mi">1</span><span class="p">];</span>
</span></span><span class="line"><span class="cl">  <span class="n">snprintf</span><span class="p">(</span><span class="n">filepath</span><span class="p">,</span> <span class="k">sizeof</span><span class="p">(</span><span class="n">filepath</span><span class="p">),</span> <span class="s">&#34;%s/crashdump.dmp&#34;</span><span class="p">,</span> <span class="n">Application</span><span class="o">::</span><span class="n">GetAppDataDir</span><span class="p">());</span> 
</span></span><span class="line"><span class="cl">  <span class="n">HANDLE</span> <span class="n">hFile</span> <span class="o">=</span> <span class="o">::</span><span class="n">CreateFileA</span><span class="p">(</span><span class="n">filepath</span><span class="p">,</span> <span class="n">GENERIC_WRITE</span><span class="p">,</span> <span class="n">FILE_SHARE_WRITE</span><span class="p">,</span> <span class="nb">NULL</span><span class="p">,</span> <span class="n">CREATE_ALWAYS</span><span class="p">,</span> <span class="n">FILE_ATTRIBUTE_NORMAL</span><span class="p">,</span> <span class="nb">NULL</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">  
</span></span><span class="line"><span class="cl">  <span class="n">_MINIDUMP_EXCEPTION_INFORMATION</span> <span class="n">ExInfo</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">  <span class="n">ExInfo</span><span class="p">.</span><span class="n">ThreadId</span> <span class="o">=</span> <span class="o">::</span><span class="n">GetCurrentThreadId</span><span class="p">();</span>
</span></span><span class="line"><span class="cl">  <span class="n">ExInfo</span><span class="p">.</span><span class="n">ExceptionPointers</span> <span class="o">=</span> <span class="n">apExceptionInfo</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">  <span class="n">ExInfo</span><span class="p">.</span><span class="n">ClientPointers</span> <span class="o">=</span> <span class="n">FALSE</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">  
</span></span><span class="line"><span class="cl">  <span class="n">pDump</span><span class="p">(</span><span class="n">GetCurrentProcess</span><span class="p">(),</span> <span class="n">GetCurrentProcessId</span><span class="p">(),</span> <span class="n">hFile</span><span class="p">,</span> <span class="n">MiniDumpNormal</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">ExInfo</span><span class="p">,</span> <span class="nb">NULL</span><span class="p">,</span> <span class="nb">NULL</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">  <span class="o">::</span><span class="n">CloseHandle</span><span class="p">(</span><span class="n">hFile</span><span class="p">);</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span></code></pre></div><p>It is important to mention that the minidump file will be created by the application that just had a fatal exception. This fatal exception could be anything, including memory corruption. Due to the unknown nature of the fatal exception it is very important to be careful with the code you run when handling the exception. Particularly take care to not do any or very few dynamic memory allocations as there is no guarantee that will work. Of course, this does not only apply to creating the minidump file but anything done while handling the exception.</p>
<h2 id="crash-report">Crash Report</h2>
<p>In addition to creating a minidump file, the Tempest crash reporter will also create an additional text file that contains some useful information. It logs the exception code by value and also a string so it is easy to identify. A callstack is created but it&rsquo;s only useful in development as otherwise, in shipping builds the callstack won&rsquo;t be able to symbolicate the function addresses. It also adds some system info like what Windows OS, processor, etc. Once again, it gathers all this extra information with little dynamic memory allocations and where there are allocations, that&rsquo;s usually because the Windows API is doing some behind the scene. You can see a bit of the crash report information in the crash reporter screenshot above.</p>
<p>The last couple things the crash report generates that are also very important have to do with a unique ID for the report itself that is tied to the machine that created the crash and the other is the game&rsquo;s build number. The crash report ID is super useful as you can use external tools to bundle crash reports based on that ID so you can get a sense of what problems might be plaguing a certain user. You can also use it to track progress on improving stability for that user and set of hardware. The game build/version number is also important to track in my opinion. You can again use external software to bundle crash reports based on what version of the game and get a sense of what the major problems are for that build. I&rsquo;ll mention soon enough what software I&rsquo;m using to be able to perform these queries.</p>
<h2 id="win32-ui">Win32 UI</h2>
<p>Using the Win32 API to make the UI for the crash reporter was for the most part easy but there was one unexpected thing that was way more annoying to handle than I thought it would be. You&rsquo;ll notice in the crash reporter screenshot that there is a text box where the user can type any additional information into it. I wanted this box to handle all the main keyboard shortcut that people expect these days to work. Copy and paste keyboard shortcuts for instance, are supported by default in the Win32 API so no issues there but if you wanted to highlight all the text using Ctrl+a then you would find out that does nothing. Adding support for that was not as trivial as you might think and searching online yielded several workarounds that were more complex than I thought it needed to be. Eventually I stumbled on a post that ran into the same issue and it presented the solution they used. It was a simple solution and was easy to integrate into my crash reporter. All you have to do is create a new window procedure that specifically handles the Ctrl+a keyboard shortcut and then make the text box window use that function.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-cpp" data-lang="cpp"><span class="line"><span class="cl"><span class="c1">// This function will handle the Ctrl+a keyboard shortcut to highlight all the text
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="n">LRESULT</span> <span class="n">CALLBACK</span> <span class="nf">Edit_Prc</span><span class="p">(</span><span class="n">HWND</span> <span class="n">hwnd</span><span class="p">,</span> <span class="n">UINT</span> <span class="n">msg</span><span class="p">,</span> <span class="n">WPARAM</span> <span class="n">wParam</span><span class="p">,</span> <span class="n">LPARAM</span> <span class="n">lParam</span><span class="p">,</span> <span class="n">UINT_PTR</span> <span class="n">uIdSubclass</span><span class="p">,</span> <span class="n">DWORD_PTR</span> <span class="n">dwRefData</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="p">{</span>
</span></span><span class="line"><span class="cl">  <span class="k">if</span> <span class="p">(</span><span class="n">msg</span> <span class="o">==</span> <span class="n">WM_CHAR</span> <span class="o">&amp;&amp;</span> <span class="n">wParam</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">  <span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="n">SendMessage</span><span class="p">(</span><span class="n">hwnd</span><span class="p">,</span> <span class="n">EM_SETSEL</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="mi">1</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">  <span class="p">}</span>
</span></span><span class="line"><span class="cl">  <span class="k">return</span> <span class="n">DefSubclassProc</span><span class="p">(</span><span class="n">hwnd</span><span class="p">,</span> <span class="n">msg</span><span class="p">,</span> <span class="n">wParam</span><span class="p">,</span> <span class="n">lParam</span><span class="p">);</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">// Later when creating the input text box window
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="n">HWND</span> <span class="n">hwnd</span> <span class="o">=</span> <span class="n">CreateWindowW</span><span class="p">(...);</span> <span class="c1">// handle to the input text box window
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="n">SetWindowSubclass</span><span class="p">(</span><span class="n">hwnd</span><span class="p">,</span> <span class="n">Edit_Prc</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">);</span> <span class="c1">// Sets the correct window proc to handle the select all text keyboard shortcut
</span></span></span></code></pre></div><h2 id="trigger-crash-reporter">Trigger Crash Reporter</h2>
<p>Now that we&rsquo;ve talked about how the crash report data is created and what it contains, let&rsquo;s talk about how the executable prepares itself to launch the crash reporter if a fatal exception happens. In c++ this done in a very simple way. It boils down to setting up a callback that will run when a fatal exception happens. To my knowledge, on Windows there are at least two different functions that allows this setup. The Tempest engine uses <a href="https://learn.microsoft.com/en-us/windows/win32/api/errhandlingapi/nf-errhandlingapi-setunhandledexceptionfilter">SetUnhandledExceptionFilter</a> and the other option is <a href="https://learn.microsoft.com/en-us/cpp/c-runtime-library/reference/set-se-translator?view=msvc-170">_set_se_translator</a>. Whichever function the application uses the setup is the same and that&rsquo;s to call the respective function on application initialization. Deciding which function to use will highly depend on your application as well as any requirements imposed by third party libraries used so be sure to read the documentation and choose accordingly. You can easily test your setup by dereferencing an uninitialized pointer and run the executable without the debugger attached. If it is setup correctly then you should see your callback get called when the application crashes.</p>
<h2 id="where-reports-live">Where Reports Live</h2>
<p>We&rsquo;ve yet to mention what happens when the user clicks &ldquo;Send&rdquo; in the crash reporter. Obviously we need a place to store these crash reports. Some platforms may already offer a place for that and you simply need to configure your application to use it but in other cases you need to host that data yourself. Being a small developer your storage needs are going to be pretty basic and if you can save some money then all the better. This was the main thing I wanted to figure out before deciding to make the crash reporter since if there is no good and cheap solution that meets a small developer&rsquo;s needs then it might not be worth spending the time to develop it. Looking for solutions I stumbled on to a Twitter post where an indie developer mentioned using Slack as a place to send to the crash reports to. I don&rsquo;t tend to use Slack personally but I do use Discord and decided to look for a Discord specific solution. To my excitement I saw that a Discord Webhook could be used to send data to a server.</p>
<p>The steps to set this up were pretty simple. Just make a new server for the game and in that server you can make a private channel where it will host all the crash reports. Through the Discord app you can create a special webhook id for the channel that you can then use with a HTTP post request in order to send the crash report data to the channel. So the crash reporter takes care of making a zip file containing the minidump, crash report, and log file. This is set as an attachment to the HTTP post request. It also sends a string with the post request which contains the message the user typed in the crash reporter and a few other key strings that are useful for searching through the channel in Discord. These key strings are things like the user&rsquo;s unique ID and game build version number. You can use either one to filter the crash report channel using Discord&rsquo;s own search feature. So if you wanted to find all the reports attached to a specific user you can search the channel using the user&rsquo;s unique ID and see all the reports generated by that user. All super useful and for a small developer probably everything you need.</p>
]]></content>
		</item>
		
		<item>
			<title>Shader Compiler</title>
			<link>https://yggdrasil-917.github.io/posts/shader-compiler/shader-compiler/</link>
			<pubDate>Sat, 29 Jun 2024 09:27:15 -0700</pubDate>
			
			<guid>https://yggdrasil-917.github.io/posts/shader-compiler/shader-compiler/</guid>
			<description><![CDATA[%!s(<nil>)]]></description>
			<content type="html"><![CDATA[<ul>
<li><a href="#editor-integration">Editor Integration</a></li>
<li><a href="#shader-cache">Shader Cache</a></li>
<li><a href="#hot-reloading">Hot Reloading</a></li>
<li><a href="#tempest-shader">Tempest Shader</a></li>
</ul>
<p>These days every game engine out there is going to need to compile shaders but how they go about it tends to be somewhat different depending on the engine&rsquo;s needs. At the time of this writing Tempest only supports the Windows platform and supports DirectX 12 and Vulkan. The compiler uses the <a href="https://github.com/microsoft/DirectXShaderCompiler">dxc executable</a> under the hood to compile for both DX12 and Vulkan.</p>
<p>The Tempest shader compiler is a separate executable similar to what other engines do where the editor will automatically launch it as a child process. When the shader compiler is launched this way it uses inter process communication (IPC) through local sockets to send information to the editor and listen to packets from the editor. It can also run in standalone mode where it compiles all dirty shaders or optionally recompiles everything in the engine. This is the mode the build pipeline uses.</p>
<h2 id="editor-integration">Editor Integration</h2>
<p>One important thing to mention about the Tempest engine tool ecosystem is that for tools that need to communicate with other Tempest tools requires the use of IPC. This is achieved through a daemon that serves as a hub of sorts for interpreting packet types that come in and internally figures out what data to send and to what tools to send that data to. This is referred to as the Tempest Daemon. This setup is currently only used with the editor as the player does not need to talk to any other applications at the moment. On editor startup, it will configure the IPC setup by first starting up the daemon and will wait until it establishes connection with it before then starting the shader compiler. The shader compiler gets launched but not in standalone mode. It instead will be required to connect to the daemon as well before the compiler proceeds to compile any dirty shaders. Once the compiler is done an acknowledgement packet is sent to the editor if everything finished successfully otherwise, it should exit due to engine level shader errors. To finish setting up IPC, the editor spawns a new thread in order to handle all the network related IPC tasks and not block the main thread while doing so. This thread will keep running until the editor is closed.</p>
<p>Another key thing the editor will do is start a thread to handle file watching for any changes. This system is used for several things but one of them is to know when a shader file is modified while the editor is running. As soon as the thread detects a change to a shader file a network packet representing what file was changed is prepared and marshalled off to the shader compiler. The packet boils down to a string containing several tokens delimited by a semicolon. Below is the function used internally to prepare the network packet with the required information for the shader compiler to handle the compilation job. It also shows the function the shader compiler uses to send a packet to the editor when it successfully compiles a shader.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-cpp" data-lang="cpp"><span class="line"><span class="cl"><span class="kt">void</span> <span class="n">Packet</span><span class="o">::</span><span class="n">PrepareShaderCompilationJobPacket</span><span class="p">(</span><span class="k">const</span> <span class="kt">char</span><span class="o">*</span> <span class="n">networkAddress</span><span class="p">,</span> <span class="k">const</span> <span class="kt">char</span><span class="o">*</span> <span class="n">filepath</span><span class="p">,</span> <span class="k">const</span> <span class="kt">char</span><span class="o">*</span> <span class="n">shaderStage</span><span class="p">,</span> <span class="k">const</span> <span class="kt">char</span><span class="o">*</span> <span class="n">entryPoint</span><span class="p">,</span> <span class="k">const</span> <span class="kt">char</span><span class="o">*</span> <span class="n">defines</span><span class="p">,</span> <span class="k">const</span> <span class="kt">char</span><span class="o">*</span> <span class="n">api</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="p">{</span>
</span></span><span class="line"><span class="cl">  <span class="n">data</span><span class="p">.</span><span class="n">type</span> <span class="o">=</span> <span class="n">PacketType</span><span class="o">::</span><span class="n">BroadcastTo</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">  <span class="kt">char</span> <span class="n">payload</span><span class="p">[</span><span class="n">Packet</span><span class="o">::</span><span class="n">maxMessageSize</span><span class="p">]</span> <span class="o">=</span> <span class="p">{};</span>
</span></span><span class="line"><span class="cl">  <span class="k">const</span> <span class="n">int32</span> <span class="n">charsWritten</span> <span class="o">=</span> <span class="n">strlen</span><span class="p">(</span><span class="n">defines</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span> <span class="o">?</span> <span class="n">snprintf</span><span class="p">(</span><span class="n">payload</span><span class="p">,</span> <span class="k">sizeof</span><span class="p">(</span><span class="n">payload</span><span class="p">),</span> <span class="s">&#34;%s;%s;%s;%s&#34;</span><span class="p">,</span> <span class="n">filepath</span><span class="p">,</span> <span class="n">api</span><span class="p">,</span> <span class="n">shaderStage</span><span class="p">,</span> <span class="n">entryPoint</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">                                                  <span class="o">:</span> <span class="n">snprintf</span><span class="p">(</span><span class="n">payload</span><span class="p">,</span> <span class="k">sizeof</span><span class="p">(</span><span class="n">payload</span><span class="p">),</span> <span class="s">&#34;%s;%s;%s;%s;%s&#34;</span><span class="p">,</span> <span class="n">filepath</span><span class="p">,</span> <span class="n">api</span><span class="p">,</span> <span class="n">shaderStage</span><span class="p">,</span> <span class="n">entryPoint</span><span class="p">,</span> <span class="n">defines</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">  <span class="k">if</span> <span class="p">(</span><span class="n">charsWritten</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">Warnf</span><span class="p">(</span><span class="s">&#34;Local payload buffer is too small to fit all shader compilation options&#34;</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">  
</span></span><span class="line"><span class="cl">  <span class="n">strcpy</span><span class="p">(</span><span class="n">data</span><span class="p">.</span><span class="n">u</span><span class="p">.</span><span class="n">broadcastPacket</span><span class="p">.</span><span class="n">ip</span><span class="p">,</span> <span class="n">networkAddress</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">  <span class="n">strcpy</span><span class="p">(</span><span class="n">data</span><span class="p">.</span><span class="n">u</span><span class="p">.</span><span class="n">broadcastPacket</span><span class="p">.</span><span class="n">msg</span><span class="p">,</span> <span class="n">payload</span><span class="p">);</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">// Used when all shader variant compilation succeeds
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="kt">void</span> <span class="n">Packet</span><span class="o">::</span><span class="n">PrepareShaderCompilationResultPacket</span><span class="p">(</span><span class="k">const</span> <span class="kt">char</span><span class="o">*</span> <span class="n">networkAddress</span><span class="p">,</span> <span class="k">const</span> <span class="n">String</span><span class="o">&amp;</span> <span class="n">result</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="p">{</span>
</span></span><span class="line"><span class="cl">  <span class="n">data</span><span class="p">.</span><span class="n">type</span> <span class="o">=</span> <span class="n">PacketType</span><span class="o">::</span><span class="n">BroadcastTo</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">  <span class="kt">char</span> <span class="n">payload</span><span class="p">[</span><span class="n">Packet</span><span class="o">::</span><span class="n">maxMessageSize</span><span class="p">]{};</span>
</span></span><span class="line"><span class="cl">  <span class="k">const</span> <span class="n">int32</span> <span class="n">charsWritten</span> <span class="o">=</span> <span class="n">snprintf</span><span class="p">(</span><span class="n">payload</span><span class="p">,</span> <span class="k">sizeof</span><span class="p">(</span><span class="n">payload</span><span class="p">),</span> <span class="s">&#34;%s&#34;</span><span class="p">,</span> <span class="n">result</span><span class="p">.</span><span class="n">c_str</span><span class="p">());</span>
</span></span><span class="line"><span class="cl">  <span class="k">if</span> <span class="p">(</span><span class="n">charsWritten</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">Warnf</span><span class="p">(</span><span class="s">&#34;Local payload buffer is too small to fit all shader compilation result&#34;</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">  <span class="n">Debugf</span><span class="p">(</span><span class="s">&#34;CompilationResultPacket sending &#39;%s&#39; to &#39;%s&#39;&#34;</span><span class="p">,</span> <span class="n">payload</span><span class="p">,</span> <span class="n">networkAddress</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">  
</span></span><span class="line"><span class="cl">  <span class="n">strcpy</span><span class="p">(</span><span class="n">data</span><span class="p">.</span><span class="n">u</span><span class="p">.</span><span class="n">broadcastPacket</span><span class="p">.</span><span class="n">ip</span><span class="p">,</span> <span class="n">networkAddress</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">  <span class="n">strcpy</span><span class="p">(</span><span class="n">data</span><span class="p">.</span><span class="n">u</span><span class="p">.</span><span class="n">broadcastPacket</span><span class="p">.</span><span class="n">msg</span><span class="p">,</span> <span class="n">payload</span><span class="p">);</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span></code></pre></div><h2 id="shader-cache">Shader Cache</h2>
<p>The engine has support for a shader cache that gets shipped with the executable. Only the editor and the shader compiler are able to create the shader cache. The cache itself is composed of multiple individual files instead of one large file containing all compiled shaders. This is mainly done to keep shader loading code simple but the more optimal approach is certainly to coalesce all shader caches into one large file. Each file that forms the cache is essentially binary blobs containing identifying information for all the shader variants in the blob as well as the bytecode generated from dxc for each shader variant. The shader cache&rsquo;s data is specific to the rendering backend API it belongs to so for example, there is one cache for DX12 and a different one for Vulkan.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-cpp" data-lang="cpp"><span class="line"><span class="cl"><span class="c1">// Sample code to pack shader variants into one binary blob after compilation succeeds
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="k">for</span> <span class="p">(</span><span class="k">const</span> <span class="n">std</span><span class="o">::</span><span class="n">pair</span><span class="o">&lt;</span><span class="k">const</span> <span class="n">String</span><span class="p">,</span> <span class="n">Vector</span><span class="o">&lt;</span><span class="n">BlobEntry</span><span class="o">&gt;&gt;&amp;</span> <span class="nl">it</span> <span class="p">:</span> <span class="n">g_ShaderBlobs</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="p">{</span>
</span></span><span class="line"><span class="cl">  <span class="n">fs</span><span class="o">::</span><span class="n">path</span> <span class="n">outputPath</span> <span class="o">=</span> <span class="n">it</span><span class="p">.</span><span class="n">first</span><span class="p">;</span> 
</span></span><span class="line"><span class="cl">  <span class="n">FileHandle</span> <span class="n">handle</span> <span class="o">=</span> <span class="n">File</span><span class="o">::</span><span class="n">Open</span><span class="p">(</span><span class="n">outputPath</span><span class="p">.</span><span class="n">generic_string</span><span class="p">().</span><span class="n">c_str</span><span class="p">(),</span> <span class="n">FileMode</span><span class="o">::</span><span class="n">FM_Write</span><span class="p">,</span> <span class="nb">true</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">  <span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">handle</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">  <span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="n">Errorf</span><span class="p">(</span><span class="s">&#34;Error writing permutation shader file&#34;</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">    <span class="k">continue</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">  <span class="p">}</span>
</span></span><span class="line"><span class="cl">  <span class="n">defer</span><span class="p">(</span><span class="n">File</span><span class="o">::</span><span class="n">Close</span><span class="p">(</span><span class="n">handle</span><span class="p">););</span>
</span></span><span class="line"><span class="cl">  <span class="k">const</span> <span class="kt">char</span><span class="o">*</span> <span class="n">signature</span> <span class="o">=</span> <span class="s">&#34;NVSP&#34;</span><span class="p">;</span> <span class="c1">// 4 byte magic number used by NVRHI
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>  <span class="n">File</span><span class="o">::</span><span class="n">Write</span><span class="p">(</span><span class="n">tag</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">handle</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">  
</span></span><span class="line"><span class="cl">  <span class="k">const</span> <span class="k">auto</span><span class="o">&amp;</span> <span class="n">entries</span> <span class="o">=</span> <span class="n">g_ShaderBlobs</span><span class="p">[</span><span class="n">it</span><span class="p">.</span><span class="n">first</span><span class="p">];</span>
</span></span><span class="line"><span class="cl">  <span class="k">for</span> <span class="p">(</span><span class="k">auto</span><span class="o">&amp;</span> <span class="nl">entry</span> <span class="p">:</span> <span class="n">entries</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">  <span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="n">String</span> <span class="n">inputFilename</span> <span class="o">=</span> <span class="n">entry</span><span class="p">.</span><span class="n">compiledPermutationFile</span><span class="p">.</span><span class="n">generic_string</span><span class="p">().</span><span class="n">c_str</span><span class="p">();</span>
</span></span><span class="line"><span class="cl">    <span class="n">BinaryBlob</span> <span class="n">inputFileData</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">File</span><span class="o">::</span><span class="n">Load</span><span class="p">(</span><span class="n">inputFilename</span><span class="p">.</span><span class="n">c_str</span><span class="p">(),</span> <span class="n">inputFileData</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">    <span class="p">{</span>
</span></span><span class="line"><span class="cl">      <span class="n">Errorf</span><span class="p">(</span><span class="s">&#34;Failed to open file %s&#34;</span><span class="p">,</span> <span class="n">inputFilename</span><span class="p">.</span><span class="n">c_str</span><span class="p">());</span>
</span></span><span class="line"><span class="cl">      <span class="k">return</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="n">ShaderBlobEntry</span> <span class="n">binaryEntry</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="n">binaryEntry</span><span class="p">.</span><span class="n">permutationSize</span> <span class="o">=</span> <span class="p">(</span><span class="n">uint32</span><span class="p">)</span><span class="n">entry</span><span class="p">.</span><span class="n">permutation</span><span class="p">.</span><span class="n">size</span><span class="p">();</span>
</span></span><span class="line"><span class="cl">    <span class="n">binaryEntry</span><span class="p">.</span><span class="n">dataSize</span> <span class="o">=</span> <span class="n">inputFileData</span><span class="p">.</span><span class="n">size</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="n">File</span><span class="o">::</span><span class="n">Write</span><span class="p">(</span><span class="o">&amp;</span><span class="n">binaryEntry</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="k">sizeof</span><span class="p">(</span><span class="n">binaryEntry</span><span class="p">),</span> <span class="n">handle</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">    <span class="n">File</span><span class="o">::</span><span class="n">Write</span><span class="p">(</span><span class="n">entry</span><span class="p">.</span><span class="n">permutation</span><span class="p">.</span><span class="n">data</span><span class="p">(),</span> <span class="mi">1</span><span class="p">,</span> <span class="n">entry</span><span class="p">.</span><span class="n">permutation</span><span class="p">.</span><span class="n">size</span><span class="p">(),</span> <span class="n">handle</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">    <span class="n">File</span><span class="o">::</span><span class="n">Write</span><span class="p">(</span><span class="n">inputFileData</span><span class="p">.</span><span class="n">data</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputFileData</span><span class="p">.</span><span class="n">size</span><span class="p">,</span> <span class="n">handle</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">  <span class="p">}</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">// Function signature for loading shader from the cache
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="n">ShaderHandle</span> <span class="n">ShaderFactory</span><span class="o">::</span><span class="n">CreateShader</span><span class="p">(</span><span class="k">const</span> <span class="kt">char</span><span class="o">*</span> <span class="n">fileName</span>
</span></span><span class="line"><span class="cl">                                       <span class="p">,</span> <span class="k">const</span> <span class="kt">char</span><span class="o">*</span> <span class="n">entryName</span>
</span></span><span class="line"><span class="cl">                                       <span class="p">,</span> <span class="k">const</span> <span class="n">Vector</span><span class="o">&lt;</span><span class="n">ShaderMacro</span><span class="o">&gt;&amp;</span> <span class="n">defines</span>
</span></span><span class="line"><span class="cl">                                       <span class="p">,</span> <span class="n">nvrhi</span><span class="o">::</span><span class="n">ShaderType</span> <span class="n">shaderType</span>
</span></span><span class="line"><span class="cl">                                       <span class="p">,</span> <span class="kt">bool</span> <span class="n">forceCreate</span><span class="p">);</span>
</span></span></code></pre></div><p>As noted above with the CreateShader function, in order to create a shader we need the obvious things like filename and shader type but we also need any of the defines used to compile the shader. This is so we can get the correct shader variant from the compiled shader blob as it contains all the shader variants. For now we do a simple linear search inside that binary blob to find the correct shader permutation. It&rsquo;s simple and works well but it is definitely not a scalable solution given the problem with shader permutation explosion. If it ever does become a performance problem then a better solution is likely to add some sort of table of content built into the binary blob so searches can be done a lot quicker.</p>
<p>The game being worked on with this engine is attempting to make a variety of shaders using dynamic branching instead of the usual static branching which creates a new shader variant for each static branch. The main benefit of limiting the use of static branching is that it keeps the number of shader permutations low which in turn keeps build times very low as these days the bottleneck in a build is usually compiling all the shader permutations in the game. Downside of course, is individual shader performance can suffer but it is important to know that there are different kinds of dynamic branching with their performance impact. The shaders in Tempest tend to use dynamic branching based on a value passed to the shader from a constant buffer which means all threads take the same branch during shader execution. Branch performance has certainly gotten better over the years so people should not be afraid of using them but it goes without saying that profiling should also be done to make sure no serious issue is introduced.</p>
<h2 id="hot-reloading">Hot Reloading</h2>
<p>Every engine should make it a priority to support hot reloading of assets and shaders are no different. It makes iteration so much better and you&rsquo;ll be all the happier seeing your changes take effect quickly. In Tempest, there are two extensions for shader files. One is .hlsli for include files and the other is .hlsl which is the shader file with the entry points for whatever shader type it is. Also worth pointing that a hlsl file can have a vertex shader and a fragment shader in the same file and still compile correctly. I point this setup out because of how hot reloading is currently implemented in the engine. When the editor is running and a modification is done to a hlsl file the hot reloading logic will kick in. The editor sends a packet to the shader compiler so it takes care of compiling all the shader variants for that file. If all the shaders compiled successfully then the shader compiler will send a packet to the editor telling it that it can attempt to hot reload the shader file path contained in the packet. If even one shader variant failed to compile then the editor is never notified to hot reload the shader so things continue on unchanged until another edit is made to the shader. The compile errors are logged in the console as well as a log file for later viewing so you can see what file failed and where it failed.</p>
<p>The hot reloading logic is not executed if a hlsli file is edited. This is mainly due to not being implemented at the moment. To properly do this the shader compiler would need to store some sort of dependency graph somewhere so it can find what hlsl files depend on that modified header file and force a recompile. I also do like not having this feature as during development I mainly want to see the changes on the hlsl file I&rsquo;m actively developing instead of having any shaders dependent on that header file recompile when they aren&rsquo;t needed. There are some header changes that are too invasive that I can&rsquo;t follow this workflow and have to recompile most shaders to ensure everything is working but those are few and far between. Think for example, changing the layout or size of a constant buffer. After I&rsquo;m happy with the changes to a hlsli file I always make sure to recompile all the shaders in the engine to ensure I didn&rsquo;t miss anything. This is as simple as deleting the shader cache folder and relaunching the editor or run the shader compiler in standalone mode. Compilation is multi threaded with the game having around 1000 shaders or so last I looked so the shader compiler gets through all compilation tasks in less than 10 seconds on my laptop. That includes building the shader cache for DirectX 12 and Vulkan.</p>
<h2 id="tempest-shader">Tempest Shader</h2>
<p>Let&rsquo;s go over a simple shader example. Below is a blit shader from the Tempest engine that can support 2D texture or texture2DArray as input</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-cpp" data-lang="cpp"><span class="line"><span class="cl"><span class="c1">// Simple copy shader
</span></span></span><span class="line"><span class="cl"><span class="c1">// $fragment_variants TEXTURE_ARRAY
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>
</span></span><span class="line"><span class="cl"><span class="cp">#if TEXTURE_ARRAY
</span></span></span><span class="line"><span class="cl"><span class="cp"></span><span class="n">Texture2DArray</span> <span class="nl">tex</span> <span class="p">:</span> <span class="k">register</span><span class="p">(</span><span class="n">t0</span><span class="p">);</span>
</span></span><span class="line"><span class="cl"><span class="cp">#else
</span></span></span><span class="line"><span class="cl"><span class="cp"></span><span class="n">Texture2D</span> <span class="nl">tex</span> <span class="p">:</span> <span class="k">register</span><span class="p">(</span><span class="n">t0</span><span class="p">);</span>
</span></span><span class="line"><span class="cl"><span class="cp">#endif
</span></span></span><span class="line"><span class="cl"><span class="cp"></span><span class="n">SamplerState</span> <span class="nl">samp</span> <span class="p">:</span> <span class="k">register</span><span class="p">(</span><span class="n">s0</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="kt">void</span> <span class="nf">MainPS</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="n">in</span> <span class="n">float4</span> <span class="nl">pos</span> <span class="p">:</span> <span class="n">SV_Position</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">in</span> <span class="n">float2</span> <span class="nl">uv</span> <span class="p">:</span> <span class="n">TEXCOORD0</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">out</span> <span class="n">float4</span> <span class="nl">o_rgba</span> <span class="p">:</span> <span class="n">SV_Target</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="p">{</span>
</span></span><span class="line"><span class="cl"><span class="cp">#if TEXTURE_ARRAY
</span></span></span><span class="line"><span class="cl"><span class="cp"></span>    <span class="n">uint</span> <span class="n">layer</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="c1">// only need the first layer as of now
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="n">o_rgba</span> <span class="o">=</span> <span class="n">tex</span><span class="p">.</span><span class="n">Sample</span><span class="p">(</span><span class="n">samp</span><span class="p">,</span> <span class="n">float3</span><span class="p">(</span><span class="n">uv</span><span class="p">,</span> <span class="n">layer</span><span class="p">));</span>
</span></span><span class="line"><span class="cl"><span class="cp">#else
</span></span></span><span class="line"><span class="cl"><span class="cp"></span>    <span class="n">o_rgba</span> <span class="o">=</span> <span class="n">tex</span><span class="p">.</span><span class="n">Sample</span><span class="p">(</span><span class="n">samp</span><span class="p">,</span> <span class="n">uv</span><span class="p">);</span>
</span></span><span class="line"><span class="cl"><span class="cp">#endif
</span></span></span><span class="line"><span class="cl"><span class="cp"></span><span class="p">}</span>
</span></span></code></pre></div><p>As you can see at the very top of the shader there is a comment line that starts with a $ followed by a keyword and a value. For anyone familiar with hlsl authoring in Unity, that line should make sense. For those unfamiliar with it, this line specifically tells the shader compiler that this shader file has two variants, one with TEXTURE_ARRAY defined and another one without it. You&rsquo;ll also notice that it is specifying that only the fragment shader has the variant so the other shader stages will not be affected by this shader variant. This keeps shader compilation fast and keeps memory to a minimum. At this moment the compiler supports four of these special pragma statements that I will outline below.</p>
<ul>
<li><strong>vertex_variants</strong> - Only the vertex shader produces variants specified by the list of values preceding this keyword</li>
<li><strong>fragment_variants</strong> - Only the fragment shader produces variants specified by the list of values preceding this keyword</li>
<li><strong>variants</strong> - All shader stages or compute shader will produce variants specified by the list of values preceding this keyword</li>
<li><strong>with_debug_symbols</strong> - This tells the compiler to include debug symbols for the shader file being compiled</li>
</ul>
<p>A limitation of sorts is that the entry point function for each shader stage has to have a certain name in order for the shader compiler to find. For instance, a vertex shader needs to have a MainVS as the entry point function, for fragment shader it&rsquo;s MainPS, and for a compute shader it is MainCS. This is again to keep the code simple and it has worked out fine so far so this will likely not change anytime soon. Shaders can also output to multiple render targets without any issue as long as they follow the requirements needed for MRT. There&rsquo;s a few render passes in the engine that uses that but I will cover that in a later post. For now just know that the engine uses deferred rendering so the gbuffer pass is one such pass that uses MRT for its output.</p>
<p>Another limitation of the compiler is that it does not do any reflection on the compiled shader. Due to this it is pretty common to have to write new c++ code to support a brand new shader. In a way this is intentional as it forces me to rely on existing shaders in the engine which can help keep the shader permutation problem under control. That said, at times you just have to make a new shader and live with that. I am still considering how I might implement this in the future.</p>
]]></content>
		</item>
		
		<item>
			<title>Serialization</title>
			<link>https://yggdrasil-917.github.io/posts/serialization/serialization/</link>
			<pubDate>Thu, 27 Jun 2024 07:28:57 -0700</pubDate>
			
			<guid>https://yggdrasil-917.github.io/posts/serialization/serialization/</guid>
			<description><![CDATA[%!s(<nil>)]]></description>
			<content type="html"><![CDATA[<ul>
<li><a href="#pupping">Pupping</a></li>
<li><a href="#text-file-pupping">Text Pupping</a></li>
<li><a href="#binary-file-pupping">Binary Pupping</a></li>
<li><a href="#random-thoughts">Random Thoughts</a></li>
</ul>
<h2 id="pupping">Pupping</h2>
<p>The method used for serialization in Tempest is referred to as pupping or pup which stands for pack-unpack. I first heard about this method close to a decade ago but the idea of it stuck with me. That idea is fairly simple. Rather than creating serilization and deserialization functions for each object type we instead create pupper objects for each type of medium bundled with a set of read and write functions for each fundamental data type. A pupper object will contain all the data and functions needed to handle both reading and writing for a specific medium like file or network serialization. Take for example, a text file pupper object might contain a file stream that each pup function would use to read and write with it.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-cpp" data-lang="cpp"><span class="line"><span class="cl"><span class="c1">// Base class snippet for every pupper object
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="k">class</span> <span class="nc">Pupper</span>
</span></span><span class="line"><span class="cl"><span class="p">{</span>
</span></span><span class="line"><span class="cl">  <span class="k">public</span><span class="o">:</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="k">enum</span> <span class="k">class</span> <span class="nc">IoMode</span> <span class="o">:</span> <span class="n">uint8</span>
</span></span><span class="line"><span class="cl">    <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="n">Read</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">Write</span>
</span></span><span class="line"><span class="cl">    <span class="p">};</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="k">virtual</span> <span class="kt">void</span> <span class="nf">WriteKey</span><span class="p">(</span><span class="k">const</span> <span class="n">String</span><span class="o">&amp;</span> <span class="cm">/*newKey*/</span><span class="p">,</span> <span class="kt">bool</span> <span class="cm">/*addNewLine */</span><span class="o">=</span> <span class="nb">false</span><span class="p">)</span> <span class="p">{}</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="k">virtual</span> <span class="kt">void</span> <span class="nf">PupPrimitive</span><span class="p">(</span><span class="kt">char</span><span class="o">&amp;</span> <span class="n">value</span><span class="p">)</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="k">virtual</span> <span class="kt">void</span> <span class="nf">PupPrimitive</span><span class="p">(</span><span class="n">String</span><span class="o">&amp;</span> <span class="n">value</span><span class="p">)</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="k">virtual</span> <span class="kt">void</span> <span class="nf">PupPrimitive</span><span class="p">(</span><span class="n">uint8</span><span class="o">&amp;</span> <span class="n">value</span><span class="p">)</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="k">virtual</span> <span class="kt">void</span> <span class="nf">PupPrimitive</span><span class="p">(</span><span class="n">uint16</span><span class="o">&amp;</span> <span class="n">value</span><span class="p">)</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="k">virtual</span> <span class="kt">void</span> <span class="nf">PupPrimitive</span><span class="p">(</span><span class="n">uint32</span><span class="o">&amp;</span> <span class="n">value</span><span class="p">)</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="k">virtual</span> <span class="kt">void</span> <span class="nf">PupPrimitive</span><span class="p">(</span><span class="n">uint64</span><span class="o">&amp;</span> <span class="n">value</span><span class="p">)</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="k">virtual</span> <span class="kt">void</span> <span class="nf">PupPrimitive</span><span class="p">(</span><span class="n">int8</span><span class="o">&amp;</span> <span class="n">value</span><span class="p">)</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="k">virtual</span> <span class="kt">void</span> <span class="nf">PupPrimitive</span><span class="p">(</span><span class="n">int16</span><span class="o">&amp;</span> <span class="n">value</span><span class="p">)</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="k">virtual</span> <span class="kt">void</span> <span class="nf">PupPrimitive</span><span class="p">(</span><span class="n">int32</span><span class="o">&amp;</span> <span class="n">value</span><span class="p">)</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="k">virtual</span> <span class="kt">void</span> <span class="nf">PupPrimitive</span><span class="p">(</span><span class="n">int64</span><span class="o">&amp;</span> <span class="n">value</span><span class="p">)</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="k">virtual</span> <span class="kt">void</span> <span class="nf">PupPrimitive</span><span class="p">(</span><span class="n">half</span><span class="o">&amp;</span> <span class="n">value</span><span class="p">)</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="k">virtual</span> <span class="kt">void</span> <span class="nf">PupPrimitive</span><span class="p">(</span><span class="kt">float</span><span class="o">&amp;</span> <span class="n">value</span><span class="p">)</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="k">virtual</span> <span class="kt">void</span> <span class="nf">PupPrimitive</span><span class="p">(</span><span class="kt">double</span><span class="o">&amp;</span> <span class="n">value</span><span class="p">)</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="k">virtual</span> <span class="kt">void</span> <span class="nf">PupPrimitive</span><span class="p">(</span><span class="kt">bool</span><span class="o">&amp;</span> <span class="n">value</span><span class="p">)</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1">// Any extra functions...
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>
</span></span><span class="line"><span class="cl">  <span class="k">protected</span><span class="o">:</span>
</span></span><span class="line"><span class="cl">    <span class="n">IoMode</span> <span class="n">mode</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="p">};</span>
</span></span></code></pre></div><h2 id="text-file-pupping">Text File Pupping</h2>
<p>It is always a good idea to support text based serialization. In Tempest, the text file pupper implements the Pupper base class posted above. There are some missing functions in that snippet but are crucial functions for text file serialization. One of the biggest advantages of using text based serialization is that it is human readable and so it is also very easy to edit and version control. In the editor most things will use this text file pupper object. In the game, game settings are stored in text but everything else is stored in binary.</p>
<p>During the development of the format the text pupper uses I realized I was using a very verbose schema for the text serialization. It was kinda a simpler XML style and this was not really an ideal outcome in my opinion. In the end the schema was redone to look similar to what YAML does. This lead to the serialized text being easier to read and edit. Plus it was also easier to parse so it got a little faster after the reimplementation. The schema YAML uses is essentially a key value pair where the value can be a simple POD(plain old data type) or it could be an array. This is the same for the text file pupper does. Arrays and string value types need to serialize a little bit more data, namely the length of the array or string.</p>
<p>The text file pupper essentially boils down to using a file stream for reading and writing. When deserializing, the pupper loads all the text file&rsquo;s content into RAM so as to avoid reading from disk every time it reads a variables data. This means it operates on a binary blob buffer when reading data and this leads to optimal performance. For serialization it just uses the file stream object directly every time it writes data for a variable instead of writing to a binary blob in memory.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-cpp" data-lang="cpp"><span class="line"><span class="cl"><span class="c1">// Same functions get used for both serialization and deserialization
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="n">Pupper</span><span class="o">*</span> <span class="n">p</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="n">uint32</span> <span class="n">version</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="n">p</span><span class="o">-&gt;</span><span class="n">WriteKey</span><span class="p">(</span><span class="s">&#34;Version&#34;</span><span class="p">);</span> 
</span></span><span class="line"><span class="cl"><span class="n">PupPrimitive</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">version</span><span class="p">);</span>
</span></span></code></pre></div><h2 id="binary-file-pupping">Binary File Pupping</h2>
<p>The binary file pupper object works exactly the same as the text file pupper. The only difference is that the pup functions for reading and writing are working with binary data instead of text. This is the pupper of choice for serializing assets and several other things in the engine. This allows serialization to take less disk space and generally makes it fast to load at runtime.</p>
<h2 id="random-thoughts">Random Thoughts</h2>
<p>When serializing structs, it&rsquo;s important to also serialize data that can identify the version of that struct. This allows for versioning the data of a struct that gets serialized. For example, if a member variable is removed from serialization you will want to know if you are loading serialized data that still has that removed variable. With a simple version number on the struct being serialized you can have a more robust serialization system. In the example given, after removing the variable from serialization you would also increment the version number for that struct. Then during deserialization you can compare the serialized version number against what the latest struct version number is and then make decisions according to those differences. In Tempest 4 bytes are used to represent the version number of a struct, a uint32. This is likely a bit too much for most cases where maybe 2 or even 1 byte might be enough to represent all possible versions of a certain struct before launching a game.</p>
<p>Also worth mentioning is that new kinds of pupper objects can be created that are not simply writing to a local file. For instance, if you need a network serializer then this is possible to do using this framework. The same kinds of read and write functions can be overwritten to write to memory buffer and at a later point just sent over the network. I&rsquo;m sure there are plenty of other use cases where this pupping framework can be applied to great success and the best part about it is that it is very simple to implement and maintain.</p>
]]></content>
		</item>
		
		<item>
			<title>Asset System</title>
			<link>https://yggdrasil-917.github.io/posts/asset-system/asset-system/</link>
			<pubDate>Wed, 26 Jun 2024 08:40:45 -0700</pubDate>
			
			<guid>https://yggdrasil-917.github.io/posts/asset-system/asset-system/</guid>
			<description><![CDATA[%!s(<nil>)]]></description>
			<content type="html"><![CDATA[<ul>
<li><a href="#assets">Assets</a></li>
<li><a href="#asset-lifetime">AssetLifetime</a></li>
<li><a href="#asset-registry">AssetRegistry</a></li>
<li><a href="#cooking">Cooking</a></li>
<li><a href="#cook-on-the-fly">CookOnTheFly</a></li>
<li><a href="#offline-cooking">OfflineCooking</a></li>
</ul>
<h2 id="assets">Assets</h2>
<p>The Tempest engine, like most other engines out there, has a concept of an asset along with an asset manager that can handle asset lifetimes as well as asset cooking. The engine contains a base class that all asset types derive from. A simplified version of that Asset base class is below.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-cpp" data-lang="cpp"><span class="line"><span class="cl"><span class="k">struct</span> <span class="nc">AssetHandle</span>
</span></span><span class="line"><span class="cl"><span class="p">{</span>
</span></span><span class="line"><span class="cl">  <span class="c1">// This contains the unique path to the asset, stored as a string 
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>  <span class="c1">// and a hash value of that path evaluated at compile time using constexpr.
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>  <span class="n">StringHash</span> <span class="n">id</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">  
</span></span><span class="line"><span class="cl">  <span class="k">operator</span> <span class="nf">uint64</span><span class="p">()</span> <span class="k">const</span> <span class="p">{</span> <span class="k">return</span> <span class="n">id</span><span class="p">.</span><span class="n">GetHash</span><span class="p">();</span> <span class="p">}</span>
</span></span><span class="line"><span class="cl">  <span class="k">operator</span> <span class="k">const</span> <span class="kt">char</span><span class="o">*</span><span class="p">()</span> <span class="k">const</span> <span class="p">{</span> <span class="k">return</span> <span class="n">id</span><span class="p">.</span><span class="n">ToString</span><span class="p">();</span> <span class="p">}</span>
</span></span><span class="line"><span class="cl">  <span class="k">operator</span> <span class="n">fs</span><span class="o">::</span><span class="n">path</span><span class="p">()</span> <span class="k">const</span> <span class="p">{</span> <span class="k">return</span> <span class="n">id</span><span class="p">.</span><span class="n">ToString</span><span class="p">();</span> <span class="p">}</span>
</span></span><span class="line"><span class="cl">  <span class="k">operator</span> <span class="nf">uint64</span><span class="p">()</span> <span class="p">{</span> <span class="k">return</span> <span class="n">id</span><span class="p">.</span><span class="n">GetHash</span><span class="p">();</span> <span class="p">}</span>
</span></span><span class="line"><span class="cl">  <span class="k">operator</span> <span class="k">const</span> <span class="kt">char</span><span class="o">*</span><span class="p">()</span> <span class="p">{</span> <span class="k">return</span> <span class="n">id</span><span class="p">.</span><span class="n">ToString</span><span class="p">();</span> <span class="p">}</span>
</span></span><span class="line"><span class="cl"><span class="p">};</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">Asset</span>
</span></span><span class="line"><span class="cl"><span class="p">{</span>
</span></span><span class="line"><span class="cl">  <span class="k">protected</span><span class="o">:</span>
</span></span><span class="line"><span class="cl">    <span class="n">AssetHandle</span> <span class="n">handle</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="n">uint64</span> <span class="n">typeId</span><span class="p">;</span> <span class="c1">// Hashed value based on the type of asset
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="c1">// some more things
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>  
</span></span><span class="line"><span class="cl">  <span class="k">public</span><span class="o">:</span>
</span></span><span class="line"><span class="cl">    <span class="c1">// helper functions
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="k">const</span> <span class="n">AssetHandle</span><span class="o">&amp;</span> <span class="n">GetHandle</span><span class="p">()</span> <span class="k">const</span> <span class="p">{</span> <span class="k">return</span> <span class="n">handle</span><span class="p">;</span> <span class="p">}</span>
</span></span><span class="line"><span class="cl">    <span class="n">uint64</span> <span class="nf">AssetId</span><span class="p">()</span> <span class="k">const</span> <span class="p">{</span> <span class="k">return</span> <span class="n">handle</span><span class="p">;</span> <span class="p">}</span>
</span></span><span class="line"><span class="cl">    <span class="k">const</span> <span class="kt">char</span><span class="o">*</span> <span class="nf">AssetPath</span><span class="p">()</span> <span class="k">const</span> <span class="p">{</span> <span class="k">return</span> <span class="n">handle</span><span class="p">;</span> <span class="p">}</span>
</span></span><span class="line"><span class="cl"><span class="p">};</span>
</span></span></code></pre></div><p>Let&rsquo;s talk a little bit about the AssetHandle struct. This is the entryway to loading assets in the Tempest engine. They are essentially a wrapper aroung a hashed string with some helper methods for ease of use with certain APIs. Asset handles support serialization so when they get deserialized we can tell the asset manager to load the asset represented by the asset handle. This allows game scripts to save asset references so for example, a game script could have an asset handle that points to a particle system asset. When the script gets initialized it will also tell the asset manager to load the asset represented by the handle. It is important to note that the asset manager will not load the same asset twice but instead checks an internal cache for loaded assets and returns early if it has been loaded before otherwise the asset is loaded and the cache is updated. There is a slight caveat to that behavior that will be explained later when talking about asset lifetimes.</p>
<p>By default assets get loaded synchronously but there is support for async loading. The reason async loading is not the default is due to certain asset types lacking threading support. The engine was upgraded to c++20 recently which gives us access to coroutines so that could be a possible extension to synchronous asset loading in the future that might be worth exploring. Something worth mentioning is that all engine specific source assets are stored in plain text as this makes it very easy to edit outside of the editor and makes diffing with your version control software of choice very easy. They are however stored in binary form after they are cooked.</p>
<p>Based on a recommendation found in the Game Engine Architecture book by Gregory, the string hash function used is FNV-1a. It&rsquo;s a pretty simple algorithm to implement with a really low collision rate so it should be rare the times a different string produces the same hash value as another string. That said it is still a good idea to have debug code check for collisions in the editor. If there are collisions the solution is just to rename the string that produced the collision.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-cpp" data-lang="cpp"><span class="line"><span class="cl"><span class="c1">// Sample FNV-1a implementation
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="cp">#define FNV_OFFSET 2166136261u
</span></span></span><span class="line"><span class="cl"><span class="cp">#define FNV_PRIME 16777619u
</span></span></span><span class="line"><span class="cl"><span class="cp"></span>
</span></span><span class="line"><span class="cl"><span class="k">constexpr</span> <span class="n">size_t</span> <span class="nf">CalculateFNV</span><span class="p">(</span><span class="k">const</span> <span class="kt">char</span><span class="o">*</span> <span class="n">str</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="p">{</span>
</span></span><span class="line"><span class="cl">  <span class="k">constexpr</span> <span class="n">size_t</span> <span class="n">prime</span> <span class="o">=</span> <span class="n">FNV_PRIME</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">  <span class="n">size_t</span> <span class="n">hash</span> <span class="o">=</span> <span class="n">FNV_OFFSET</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">  <span class="k">while</span> <span class="p">(</span><span class="o">*</span><span class="n">str</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">  <span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="n">hash</span> <span class="o">=</span> <span class="p">(</span><span class="n">hash</span> <span class="o">^</span> <span class="p">(</span><span class="o">*</span><span class="n">str</span><span class="p">))</span> <span class="o">*</span> <span class="n">prime</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="o">++</span><span class="n">str</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">  <span class="p">}</span>
</span></span><span class="line"><span class="cl">  
</span></span><span class="line"><span class="cl">  <span class="k">return</span> <span class="p">(</span><span class="n">hash</span> <span class="o">^</span> <span class="p">(</span><span class="o">*</span><span class="n">str</span><span class="p">))</span> <span class="o">*</span> <span class="n">prime</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span></code></pre></div><h2 id="asset-lifetime">Asset Lifetime</h2>
<p>The Tempest engine doesn&rsquo;t have a garbage collection system like what you would find in Unreal Engine. Due to the design of the game being made with this engine, it is very clear what asset lifetimes will be so a complex garbage collection system is not needed. The design pretty much ties the asset lifetime to the lifetime of a level. With that knowledge we can assume that when a level is unloaded it is safe to delete any and all assets loaded for that level. For the sake of simplicity in the design of this asset lifetime management system, the engine does not try to be smart and check what sort of assets the level we are transitioning to has so that the engine may skip loading assets it has already loaded into memory. In practice this means we reload an asset that was already loaded in the previous level but it hasn&rsquo;t been a source of performance issues as level transitions are still very fast. This is something that may need to be considered in the future if level complexity gets high enough that load times suffer because of this.</p>
<p>So how does the asset manager keep loaded assets internally? Well it keeps a nested UnorderedMap similar to the one below. An UnorderedMap is the same as std::unordered_map but using custom allocators.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-cpp" data-lang="cpp"><span class="line"><span class="cl"><span class="k">using</span> <span class="n">AssetPtr</span> <span class="o">=</span> <span class="n">std</span><span class="o">::</span><span class="n">unique_ptr</span><span class="o">&lt;</span><span class="n">Asset</span><span class="o">&gt;</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="n">UnorderedMap</span><span class="o">&lt;</span><span class="n">uint64</span><span class="p">,</span> <span class="n">UnorderedMap</span><span class="o">&lt;</span><span class="n">uint64</span><span class="p">,</span> <span class="n">AssetPtr</span><span class="o">&gt;&gt;</span> <span class="n">loadedAssets</span><span class="p">;</span>
</span></span></code></pre></div><p>Each level loaded into memory keeps a map of the assets loaded for that specific level. The outer map uses a key of type uint64 that represents the hash of a level and the value is the map of loaded assets for that level. The inner map uses a uint64 type for a key as well which is the asset&rsquo;s hashed id and the values are unique pointers to the asset. Using smart pointers for the assets lets of release all the memory used by those assets once we clear the map, typically done during a level transition. This way of managing assets does lead to the potential of duplicating assets in memory if multiple levels load the same asset but so far in practice it hasn&rsquo;t been a source of concern.</p>
<p>This lifetime system has a couple of &ldquo;special&rdquo; kinds of levels that are useful for some unique purposes. One such level is referred to as the permanent scene id. This is useful for loading global assets, in other words, assets the game may need at any time while the game is running or if you want to preload certain common assets. Such assets are things like UI textures and fonts. It is much better to load these when the game starts instead of reloading the assets any time a UI menu is invoked. These global assets then get released when game exits so from a asset lifetime perspective, these assets are always safe to invoke while the game is running. Another special level type is for transient assets. These are assets that need to be loaded for a temporary task and you want to free the memory afterwards.</p>
<p>It is important to note that the asset manager returns a struct called AssetRef instead of a pointer to the asset being loaded. Then when the actual asset is needed that asset ref object can be used to get a temporary pointer to the asset. If the pointer is not null then we have a valid asset and can do whatever we need. The asset ref struct is simply two uint64 member variables. One for the level&rsquo;s hash that owns the asset and the other is the asset hash itself. The main reason for using this kind of indirection is so that the asset manager can internally do modifications to the asset without invaliding pointers to it. For example, hot reloading an asset will create a new asset pointer so the previous one becomes a dangling pointer but this is not a problem with the current level of indirection.</p>
<h2 id="asset-registry">Asset Registry</h2>
<p>The asset registry is essentially one large map of cooked assets that is created and managed by the editor and the cooker. The map stores asset metadata that can be useful for editor features like moving a file to another location within the content system. Whenever an asset is cooked, metadata associated with that asset gets added to the registry and later serialized. In the beginning this registry had more uses outside of the editor but they have been slowly phased out as they&rsquo;ve seen little use and instead is more an editor only feature these days. The metadata can include things like GUIDs, file paths, and other useful bits of info. The registry itself is stored in plain text for development purposes but can also be stored in binary form.</p>
<h2 id="cooking">Cooking</h2>
<p>Like a lot of other engines, Tempest engine will ingest different kinds of assets authored through DCC tools and convert them to a custom engine specific binary format. The engine takes an approach similar to what Unity does when it imports an asset. Tempest has more or less a custom vtable for all the import functions required to support every type of asset in the engine. So part of the process in supporting a specific type of asset is to map an asset extension to an import function. So for example, a jpeg asset will invoke the importer function for a texture asset. When the import is done the cooked asset is stored in a folder for cooked assets for a given platform. However, the source asset is left unmodified in the content folder making it easy to do updates to the source asset. If no valid asset extension to import function is found then the asset is ignored and it is logged that it was skipped. It&rsquo;s also worth pointing out that some types of assets also create a metafile alongside the source asset similar to what Unity does. As of now only texture assets do this in order to store texture settings in that metafile.</p>
<p>Cooking is only allowed to happen in the editor or when the offline cooker is running. The player is only allowed to read cooked data and will error out if it tries to cook an asset it does not have the data for. There are technically two cooking modes, cook on the fly and offline cooking. Both will be expanded on later in this article.</p>
<h2 id="cook-on-the-fly">Cook on the fly</h2>
<p>This is the mode the editor uses and what this means is that it will only cook an asset when a request to load that asset occurs. When loading an asset, the asset manager checks to see if there is a cooked version of that source asset. If there isn&rsquo;t then it proceeds to import the asset otherwise, it will check if the source asset has been updated since the last time it was cooked. If it has been updated since then it will get cooked. This is where the std::filesystem API comes in handy to check the last modification timestamp of both the source asset file and the cooked binary file. So if the last modification timestamp for the source asset file is newer then we know we should cook it. After cooking is done the asset registry is updated to include the new asset.</p>
<h2 id="offline-cooking">Offline Cooking</h2>
<p>The offline cooker is what the build pipeline uses to cook the assets. The cooker takes as input a list of levels to include in the build. It can also accept a list of assets to always cook regardless of whether or not they are referenced in a level. This is to accommodate the case where assets are loaded from scripts instead of being in the level&rsquo;s file. By default the offline cooker will use incremental cooking where it operates much like the cook on the fly method so only dirty assets get updated. It can also do a full recook of all the assets to make sure everything is up to date and this is the preferred method when running the build pipeline. How this tool figures out what to cook is fairly simple. Generally speaking, the assets are stored in text format and are only in binary after being cooked. Level assets follow this pattern. Any time the level has a reference to an asset it will have serialized data for an asset handle in text. So the tool opens a file handle to the level&rsquo;s text file and scans for those tokens. By the end it will have a list of all referenced assets in that level. It does the same for all levels that will be included in the build so it ends up with all statically referenced assets. The tool then adds the assets that should always be included in the build and finally we can start the actual cooking process. Once the cooking is done there is some diagnostic data reported at the end where things like number of assets cooked is reported, total disk memory used by the assets, total disk space used by asset type, etc.</p>
]]></content>
		</item>
		
		<item>
			<title>Tempest Engine</title>
			<link>https://yggdrasil-917.github.io/posts/tempest-engine/tempest-engine/</link>
			<pubDate>Sun, 23 Jun 2024 06:40:54 -0700</pubDate>
			
			<guid>https://yggdrasil-917.github.io/posts/tempest-engine/tempest-engine/</guid>
			<description><![CDATA[%!s(<nil>)]]></description>
			<content type="html"><![CDATA[<ol>
<li><a href="#introduction">Introduction</a></li>
<li><a href="#why-build-a-new-engine">Why Build A New Engine</a></li>
<li><a href="#pros">Pros</a></li>
<li><a href="#cons">Cons</a></li>
<li><a href="#conclusion">Conclusion</a></li>
</ol>
<h2 id="introduction">Introduction</h2>
<p>About two years ago I had started building a new engine in C++ with the initial intention of having some base framework I could experiment with and also challenging myself to build a proper game editor since I had yet to do that. I had built a few engines in the past but it was always with the intention of learning more things so I generally avoided using third party libraries. This meant I would implement everything myself or at least the vast majority of it. For this engine though, it was more about making things with it so I was ok with using third party libraries. After a year into the development of the engine, I had a suite of tools that were good enough to convince me to use them to make a game and thus fulfill my intent of creating something with this engine. At that point what I call the Tempest Engine was sort of born. Since then I&rsquo;ve been working on the engine whenever the game needed a feature I had not implemented yet.</p>
<p>To get a little bit ahead of myself, I added a screenshot below of what the editor currently looks like while running one of the combat scenarios in the game. I&rsquo;ll eventually go over the various things about the engine in different posts. I should also mention all the art assets are placeholder at this point.</p>
<p><img src="/images/tempest-engine/editor.png" alt="Editor Screenshot" title="Tempest Editor"></p>
<h2 id="why-build-a-new-engine">Why Build A New Engine</h2>
<p>Some of you may ask why use an unproven engine for my game instead of using an off the shelf solution like Unity or Unreal that has been around for a long time. I have many reasons why I&rsquo;m not going down that route even though I&rsquo;m familiar with both of those engines. I would say that&rsquo;s also why I don&rsquo;t want to use them for anything other than work these days. I had mainly been using Unity for the last few years and right now is just not a great time to use that engine. Too many packages are in development hell or have been prematurely marked as production ready when they really aren&rsquo;t. That codebase is in a lot of flux right now. Solutions that worked for a certain package version become obsolete very quickly while the problems still linger so a brand new solution needs to figured out.</p>
<p>As for Unreal, it has all I need but I also don&rsquo;t care for how bloated it is these days. Editor can be fairly unstable depending on what you&rsquo;re doing. Running Unreal makes my PC work so hard it almost sounds like I&rsquo;m launching a rocket to space with how fast the fans are spinning. I also have never really liked blueprints or how Epic has pushed that workflow on most things in the engine. C++ in Unreal feels worse than it should be and I say that while understanding some of the limitations c++ bring to the scripting side of game development. Namely hot reloading c++ code is a nightmare and will not always work. It might not ever feel as well integrated as c# in Unity. Maybe c++ modules can help change some of that but that&rsquo;s never gonna happen in Unreal without a full rewrite.</p>
<p>There&rsquo;s also something that&rsquo;s been on my mind since I started this and that&rsquo;s the fact that I wouldn&rsquo;t have to pay Epic or Unity money to use my own engine. I may have to pay some amount for some of the libraries I&rsquo;m using, assuming the game makes enough money that I need to pay them. Considering platforms like Steam take a 30% cut, console platforms do the same, and other things that take away from your total I think every bit you can save helps out in the end.</p>
<p>Bottom line is that I could make my game in either engine but I feel I would be fighting against engine issues due to how they were made or design principles where things have to be done a very specific way that engine forces you to adopt. I&rsquo;m confident in my abilities to make Tempest good enough to release a game on it some day. That said I&rsquo;ll first talk about some of the pros of building my own engine and then I&rsquo;ll mention some of the cons.</p>
<h2 id="pros">Pros</h2>
<p>Lets start with the obvious pro. I&rsquo;ve implemented everything myself. This means I have intimate knowledge on how all the systems in the engine work. There is no blackbox so to speak. Whenever bugs happen I tend to have a good idea of what the problem is and what the solution should be. This results in bugs being fixed in a much quicker pace than if I was using Unity or Unreal.</p>
<p>Another pro is that I have a pretty good idea of what I want my game to be so the requirements are well defined. Because of that I don&rsquo;t have to rely on a highly generic game engine with loads of features I will never need or use and possibly even deal with problems some of those features may cause during development. Having a good idea of what the game will be also leads to a lean codebase. I keep track of how large the codebase is just for comparing against other engines out there. Without considering third party libraries the engine and game codebase totals around 150K lines of code at the time of this writing. Compare that to the millions of lines of code engines like Unreal and Unity have just for the engine alone.</p>
<p>A lean codebase has several advantages. Keeping it small keeps the learning curve manageable, making it easier to bring other developers on board. Build times are considerably faster than, for example, building Unreal from source so we can make engine modifications without having to wait an excessive amount of time compiling and linking. This also means I don&rsquo;t need to have a beast of a computer to have fast compile times. I currently develop on an almost 5 year old laptop and iteration times are still fast. With that laptop, it would be horrible to compile Unreal from source.</p>
<p>Custom pipeline for everything. You decide how the content is cooked for your game, how the builds get made, shader compilation, etc. I can&rsquo;t stress enough how great it is to be able to make a new build and only have to wait seconds for it to finish. These days engines are taking a very long time to make even the simplest of builds. Take Unity, for example, where using URP and making a build of a simple scene takes a very long time.</p>
<p>There&rsquo;s plenty of other pros but I&rsquo;ll leave it at that and move on to some of the cons.</p>
<h2 id="cons">Cons</h2>
<p>Custom codebase means it is less mature than long standing engines. There will be problems other engines have already solved. The codebase will likely be lacking in features that others may be accustomed to. Things like editor workflows, keyboard shortcuts, etc. It is up to me to spend time on what is valuable as far as extending the engine feature set.</p>
<p>Currently the engine does not make it trivial to add new shaders. Adding a new shader will usually require adding new c++ code as well. This is in part by design at the moment as I tend to have fewer shaders that rely on dynamic branching for slightly different behaviors instead of doing what most developers do and make a new shader variant for a feature.</p>
<h2 id="conclusion">Conclusion</h2>
<p>All in all I&rsquo;m pretty happy with what the engine is capable of and where it&rsquo;s going. At this point it has many of the features I would expect out of an off the shelf engine and I&rsquo;m confident they will mature over time. There&rsquo;s lots of room for improvement and I&rsquo;ll definitely be talking more about the engine in later posts.</p>
]]></content>
		</item>
		
	</channel>
</rss>
